{
    "Acceleration": [
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        }
    ],
    "Access protocols": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Aho-Corasick": [
        {
            "title": "Commentz-walter: Any better than aho-corasick for peptide identification?",
            "venue": "International Journal of Research in Computer Science",
            "year": "2012",
            "abstract": "An algorithm for locating all occurrences of a finite number of keywords in an arbitrary string, also known as multiple strings matching, is commonly required in information retrieval (such as sequence analysis, evolutionary biological studies, gene/protein identification and network intrusion detection) and text editing applications. Although Aho-Corasick was one of the commonly used exact multiple strings matching algorithm, Commentz-Walter has been introduced as a better alternative in the recent past. Comments-Walter algorithm combines ideas from both Aho-Corasick and Boyer Moore. Large scale rapid and accurate peptide identification is critical in computational proteomics. In this paper, we have critically analyzed the time complexity of Aho-Corasick and Commentz-Walter for their suitability in large scale peptide identification. According to the results we obtained for our dataset, we conclude that Aho-Corasick is performing better than Commentz-Walter as opposed to the common beliefs.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "RG Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.7815/ijorcs.26.2012.053",
            "preprint": "https://www.academia.edu/download/73625856/Vol2-Issue-06-04-commentz-walter-any-better-than-aho-corasick-for-peptide-identification.pdf",
            "pdf": "https://www.academia.edu/download/73625856/Vol2-Issue-06-04-commentz-walter-any-better-than-aho-corasick-for-peptide-identification.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Aho-Corasick",
                "Commentz-Walter",
                "Peptide Identification"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7815/ijorcs.26.2012.053/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7815/ijorcs.26.2012.053/index.json"
        }
    ],
    "Algorithm design and analysis": [
        {
            "title": "Hardware software co-design of the Aho-Corasick algorithm: Scalable for protein identification?",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Pattern matching is commonly required in many application areas and bioinformatics is a major area of interest that requires both exact and approximate pattern matching. Much work has been done in this area, yet there is still a significant space for improvement in efficiency, flexibility, and throughput. This paper presents a hardware software co-design of Aho-Corasick algorithm in Nios II soft-processor and a study on its scalability for a pattern matching application. A software only approach is used to compare the throughput and the scalability of the hardware software co-design approach. According to the results we obtained, we conclude that the hardware software co-design implementation shows a maximum of 10 times speed up for pattern size of 1200 peptides compared to the software only implementation. The results also show that the hardware software co-design approach scales well for increasing data size compared to the software only approach.",
            "authors": [
                "S.M. Vidanagamachchi",
                "S.D. Dewasurendra",
                "",
                "R.G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732003",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.1317.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Proteins",
                "Peptides",
                "Software algorithms",
                "Program processors",
                "Algorithm design and analysis"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732003/index.json"
        },
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        },
        {
            "title": "Heterogeneous processor pipeline for a product cipher application",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "Processing data received as a stream is a task commonly performed by modern embedded devices, in a wide range of applications such as multimedia (encoding/decoding/ playing media), networking (switching and routing), digital security, scientific data processing, etc. Such processing normally tends to be calculation intensive and therefore requiring significant processing power. Therefore, hardware acceleration methods to increase the performance of such applications constitute an important area of study. In this paper, we present an evaluation of one such method to process streaming data, namely multi-processor pipeline architecture. The hardware is based on a Multiple-Processor System on Chip (MPSoC), using a data encryption algorithm as a case study. The algorithm is partitioned on a coarse grained level and mapped on to an MPSoC with five processor cores in a pipeline, using specifically configured Xtensa LX3 cores. The system is then selectively optimized by strengthening and pruning the resources of each processor core. The optimized system is evaluated and compared against an optimal single-processor System on Chip (SoC) for the same application. The multiple-processor pipeline system for data encryption algorithms used was observed to provide significant speed ups, up to 4.45 times that of the single-processor system, which is close to the ideal speed up from a five-stage pipeline.",
            "authors": [
                "Isuru B. Nawinne",
                "Mahanama S. Wickramasinghe",
                "Roshan G. Ragel",
                "Member",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038036",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7299.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pipelines",
                "Encryption",
                "Algorithm design and analysis",
                "Partitioning algorithms",
                "Streaming media",
                "Computer architecture"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038036/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038036/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "To use or not to use: Graphics processing units (GPUs) for pattern matching algorithms",
            "venue": "7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "String matching is an important part in today's computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069585",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms/links/54e48fc30cf2dbf60696ea10/To-Use-or-Not-to-Use-Graphics-Processing-Units-for-Pattern-Matching-Algorithms.pdf",
            "pdf": "https://ieeexplore.ieee.org/abstract/document/7069585",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Graphics processing units",
                "Central Processing Unit",
                "Pattern matching",
                "Parallel processing",
                "Algorithm design and analysis",
                "Performance evaluation",
                "Software algorithms"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069585/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069585/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        }
    ],
    "Amino acids": [
        {
            "title": "A structured hardware software architecture for peptide based diagnosis \u00e2\u0080\u0094 Sub-string matching problem with limited tolerance",
            "venue": "2014 7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "S. Devapriya Dewasurendra",
                "Roshan G. Ragel",
                "Mahesan Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069624",
            "preprint": "https://arxiv.org/pdf/1412.7811",
            "pdf": "https://arxiv.org/pdf/1412.7811",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Amino acids",
                "Software",
                "Automata",
                "Databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069624/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069624/index.json"
        }
    ],
    "Application specific processors": [
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Architectures": [
        {
            "title": "DRMA: dynamically reconfigurable MPSoC architecture",
            "venue": "GLSVLSI '13: Proceedings of the 23rd ACM international conference on Great lakes symposium on VLSI",
            "year": "2013",
            "abstract": "Embedded systems are ubiquitous and are deployed in a large range of applications. Designing and fabricating Integrated Circuits (ICs) targeting such different range of applications is expensive. Designers seek flexible processors which efficiently execute a multitude of applications. FPGAs are considered affordable, but design cost, high reconfiguration delay and power consumption are all prohibitive. In this paper, we propose a novel ASIC based flexible MPSoC architecture, which can execute separate tasks in parallel, and it can be configured to execute single task with wide data widths or execute multiple tasks with varying data widths. The architecture presented, called Dynamically Reconfigurable MPSoC Architecture (DRMA), can be rapidly reconfigured through instructions. We present applications as case studies to showcase the flexibility and efficacy of DRMA. Results show for an additional area overhead of about 5%, the system is capable of working as four 32-bit processors, a single 128 bit processor or as a pipelined processing system.",
            "authors": [
                "Lawrance Zhang",
                "Jude Angelo Ambrose",
                "Jorgen Peddersen",
                "Sri Parameswaran",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Kewal K. Saluja"
            ],
            "doi": "https://doi.org/10.1145/2483028.2483101",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Computer systems organization",
                "Architectures",
                "Serial architectures",
                "Pipeline computing",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2483028.2483101/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2483028.2483101/index.json"
        }
    ],
    "Arrays": [
        {
            "title": "To use or not to use: CPUs' cache optimization techniques on GPGPUs",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU's best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946534",
            "preprint": "https://arxiv.org/pdf/1810.04063",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Arrays",
                "Optimization",
                "Merging",
                "Cache memory",
                "Testing",
                "Kernel",
                "Throughput"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946534/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946534/index.json"
        }
    ],
    "Australia": [
        {
            "title": "Data Mining System for Predicting a Winning Cricket Team",
            "venue": "2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2021",
            "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u00e2\u0080\u0099 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
            "authors": [
                "Dinithi Hasanika",
                "Roshani Dilhara",
                "Dulanjali Liyanage",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Uncertainty",
                "Statistical analysis",
                "Conferences",
                "Games",
                "Machine learning",
                "Data mining",
                "Australia"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS53135.2021.9660702/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS53135.2021.9660702/index.json"
        }
    ],
    "Authentication": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        },
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        },
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Automata": [
        {
            "title": "Statechart based modeling and controller implementation of complex reactive systems",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Statechart formalism has been a preferred choice for modeling complex reactive systems (CRS) in recent years. It has inbuilt powerful features of orthogonality, hierarchy, intermodular communication and history. Once statechart based system modeling is done the next issues to be addressed are (1) modular verification of the system for failsafe operation under all possible working conditions (2) progressive controller implementation together with the supervisory control while maintaining traceability and re-configurability and (3) facilitation of controller adaptation for progressive incorporation of security features and supervisory specifications. An elevator system was designed and built to reflect exigencies of a typical CRS hardware/software platform. A controller was designed to meet the above requirements and tested on the platform to validate the feasibility of model-based control design/verification methodology for real scale systems. Modularity was achieved by developing the statechart model of the plant into a tree of communicating language generators. Progresively verified modules were then translated into sequential function charts (SFC) which were finally integrated to form a complete flat SFC. The SFC was then implemented on a PLC platform (Telemechanique). The program was first validated in simulation using Telemechanique \u00e2\u0080\u009cTwidosuite\u00e2\u0080\u009d for different operating conditions and finally tested on the elevator system.",
            "authors": [
                "AC Vidanapathirana",
                "SD Dewasurendra",
                "SG Abeyratne"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038120",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Generators",
                "Software",
                "Automata",
                "Process control",
                "Floors",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038120/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038120/index.json"
        },
        {
            "title": "A structured hardware software architecture for peptide based diagnosis \u00e2\u0080\u0094 Sub-string matching problem with limited tolerance",
            "venue": "2014 7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "S. Devapriya Dewasurendra",
                "Roshan G. Ragel",
                "Mahesan Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069624",
            "preprint": "https://arxiv.org/pdf/1412.7811",
            "pdf": "https://arxiv.org/pdf/1412.7811",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Amino acids",
                "Software",
                "Automata",
                "Databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069624/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069624/index.json"
        }
    ],
    "Bayesian networks": [
        {
            "title": "Model-based fault diagnosis and prognosis of dynamic systems: a review",
            "venue": "Procedia Manufacturing",
            "year": "2019",
            "abstract": "In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.",
            "authors": [
                "Thushara Ekanayakea",
                "Devapriya Dewasurendra",
                "Sunil Abeyratne",
                "Lin Ma",
                "Prasad Yarlagadda"
            ],
            "doi": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "preprint": "#",
            "pdf": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "model-based systems",
                "fault diagnosis",
                "fault prognosis",
                "automata",
                "Petri nets",
                "bond graphs",
                "Bayesian networks"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1016/j.promfg.2019.02.060/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1016/j.promfg.2019.02.060/index.json"
        }
    ],
    "Benchmark testing": [
        {
            "title": "A Study on Instruction-set Selection Using Multi-application Based Application Specific Instruction-set Processors",
            "venue": "2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems",
            "year": "2013",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analyzing the instructions for inter-domain and intra-domain designs. Metrics analyzed are the reusable instructions and the extra cost to add a certain application, together with the hardware synthesis numbers, such as area, timing and delay. A wide range of applications from various application benchmarks (BioPerf, CommBench, MediaBench, MiBench and SPEC2006) and domains are analyzed for three different architectures (LEON2, PISA and ARM-Thumb). Processors are generated for these architectures for different configurations to analyze and synthesize. Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless the kind of architecture (and therefore the ISA).",
            "authors": [
                "Roshan G. Ragel",
                "Swarnalatha Radhakrishnan",
                "Jude Angelo Ambrose",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/VLSID.2013.154",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/261501995_A_Study_on_Instruction-set_Selection_Using_Multi-application_Based_Application_Specific_Instruction-set_Processors/links/54e48faf0cf2dbf60696e9b4/A-Study-on-Instruction-set-Selection-Using-Multi-application-Based-Application-Specific-Instruction-set-Processors.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Thumb",
                "Embedded systems",
                "Benchmark testing",
                "Standards",
                "Instruction sets"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/VLSID.2013.154/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/VLSID.2013.154/index.json"
        }
    ],
    "Bio medical engineering": [
        {
            "title": "Non-contact Infant Sleep Apnea Detection",
            "venue": "IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2019",
            "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for the detection of sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
            "authors": [
                "Gihan Jayatilaka",
                "Harshana Weligampola",
                "Suren Sritharan",
                "Pankayaraj Pathmanathan",
                "Roshan Ragel",
                "Isuru Nawinne"
            ],
            "doi": "https://doi.org/10.1109/ICIIS47346.2019.9063269",
            "preprint": "https://arxiv.org/pdf/1910.04725.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering",
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Sleep apnea",
                "Video processing",
                "Bio medical engineering",
                "Pattern recognition"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS47346.2019.9063269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS47346.2019.9063269/index.json"
        }
    ],
    "Bioinformatics": [
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        }
    ],
    "Cache memory": [
        {
            "title": "To use or not to use: CPUs' cache optimization techniques on GPGPUs",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU's best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946534",
            "preprint": "https://arxiv.org/pdf/1810.04063",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Arrays",
                "Optimization",
                "Merging",
                "Cache memory",
                "Testing",
                "Kernel",
                "Throughput"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946534/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946534/index.json"
        }
    ],
    "Central Processing Unit": [
        {
            "title": "To use or not to use: Graphics processing units (GPUs) for pattern matching algorithms",
            "venue": "7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "String matching is an important part in today's computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069585",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms/links/54e48fc30cf2dbf60696ea10/To-Use-or-Not-to-Use-Graphics-Processing-Units-for-Pattern-Matching-Algorithms.pdf",
            "pdf": "https://ieeexplore.ieee.org/abstract/document/7069585",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Graphics processing units",
                "Central Processing Unit",
                "Pattern matching",
                "Parallel processing",
                "Algorithm design and analysis",
                "Performance evaluation",
                "Software algorithms"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069585/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069585/index.json"
        }
    ],
    "Clocks": [
        {
            "title": "Constant time encryption as a countermeasure against remote cache timing attacks",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Rijndael was standardized in 2001 by National Institute of Standard and Technology as the Advanced Encryption Standard (AES). AES is still being used to encrypt financial, military and even government confidential data. In 2005, Bernstein illustrated a remote cache timing attack on AES using the client-server architecture and therefore proved a side channel in its software implementation. Over the years, a number of countermeasures have been proposed against cache timing attacks both using hardware and software. Although the software based countermeasures are flexible and easy to deploy, most of such countermeasures are vulnerable to statistical analysis. In this paper, we propose a novel software based countermeasure against cache timing attacks, known as constant time encryption, which we believe is secure against statistical analysis. The countermeasure we proposed performs rescheduling of instructions such that the encryption rounds will consume constant time independent of the cache hits and misses. Through experiments, we prove that our countermeasure is secure against Bernstein's cache timing attack.",
            "authors": [
                "Darshana Jayasinghe",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419893",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7293.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Encryption",
                "Timing",
                "Software",
                "Hardware",
                "Clocks",
                "Computers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419893/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419893/index.json"
        }
    ],
    "Commentz-Walter": [
        {
            "title": "Commentz-walter: Any better than aho-corasick for peptide identification?",
            "venue": "International Journal of Research in Computer Science",
            "year": "2012",
            "abstract": "An algorithm for locating all occurrences of a finite number of keywords in an arbitrary string, also known as multiple strings matching, is commonly required in information retrieval (such as sequence analysis, evolutionary biological studies, gene/protein identification and network intrusion detection) and text editing applications. Although Aho-Corasick was one of the commonly used exact multiple strings matching algorithm, Commentz-Walter has been introduced as a better alternative in the recent past. Comments-Walter algorithm combines ideas from both Aho-Corasick and Boyer Moore. Large scale rapid and accurate peptide identification is critical in computational proteomics. In this paper, we have critically analyzed the time complexity of Aho-Corasick and Commentz-Walter for their suitability in large scale peptide identification. According to the results we obtained for our dataset, we conclude that Aho-Corasick is performing better than Commentz-Walter as opposed to the common beliefs.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "RG Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.7815/ijorcs.26.2012.053",
            "preprint": "https://www.academia.edu/download/73625856/Vol2-Issue-06-04-commentz-walter-any-better-than-aho-corasick-for-peptide-identification.pdf",
            "pdf": "https://www.academia.edu/download/73625856/Vol2-Issue-06-04-commentz-walter-any-better-than-aho-corasick-for-peptide-identification.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Aho-Corasick",
                "Commentz-Walter",
                "Peptide Identification"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7815/ijorcs.26.2012.053/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7815/ijorcs.26.2012.053/index.json"
        }
    ],
    "Communication system security": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Computer Vision": [
        {
            "title": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for Enhancing Low Light Images",
            "venue": "MERcon",
            "year": "2020",
            "abstract": "Low light image enhancement is an important challenge for the development of robust computer vision algorithms. The machine learning approaches to this have been either unsupervised, supervised based on paired dataset or supervised based on unpaired dataset. This paper presents a novel deep learning pipeline that can learn from both paired and unpaired datasets. Convolution Neural Networks (CNNs) that are optimized to minimize standard loss, and Generative Adversarial Networks (GANs) that are optimized to minimize the adversarial loss are used to achieve different steps of the low light image enhancement process. Cycle consistency loss and a patched discriminator are utilized to further improve the performance. The paper also analyses the functionality and the performance of different components, hidden layers, and the entire pipeline.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Roshan Goldaliyadda",
                "Parakrama Ekanayeka",
                "Roshan Ragel",
                "Vijitha Herath"
            ],
            "doi": "https://doi.org/10.1109/MERCon50084.2020.9185373",
            "preprint": "https://arxiv.org/pdf/2006.15304.pdf",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/mercon-2020-presentation.pdf",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Low-light image enhancement",
                "Retinex theory",
                "Generative adversarial networks",
                "Cycle consistency",
                "Computer Vision"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon50084.2020.9185373/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon50084.2020.9185373/index.json"
        }
    ],
    "Computer architecture": [
        {
            "title": "Offloading specific performance-related kernel functions into an FPGA",
            "venue": "2021 IEEE 30th International Symposium on Industrial Electronics (ISIE)",
            "year": "2021",
            "abstract": "Today's network transactions are usually handled using kernel-based network protocols residing on general-purpose processors (GPPs). Over time, network transmission speeds have developed rapidly without a corresponding increase in processing speeds of host processors. With devices featuring advanced connectivity and Internet functionality, protocol processing has created a heavy workload on the GPP and has become a limiting factor in high performance networking applications such as online High Frequency Trading Systems (HFTS). It encourages designers to increase processor performance or designing application specific processors for handling heavy network workloads. Then there is the choice of hardware/software implementations based on results from hardware acceleration. Offloading the whole network protocol stack implementation into hardware is not very attractive since handling large linked data structures inside the hardware is not as easy as in software. In this paper we claim that relieving the CPU from bulk processing by offloading selected, performance-related kernel code into hardware is a better option for such scenarios. Hence, we design a scalable system for offloading specific performance-related kernel functions into an FPGA. In this paper we discuss the logic behind our new architecture and the results up to now.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S. Devapriya Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ISIE45552.2021.9576256",
            "preprint": "https://www.academia.edu/download/75534730/KF_003255_ISIE2021paper.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Performance evaluation",
                "Protocols",
                "Profitability",
                "Linux",
                "Computer architecture",
                "Software",
                "Security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ISIE45552.2021.9576256/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ISIE45552.2021.9576256/index.json"
        },
        {
            "title": "A Novel FPGA Architecture of Commentz-Walter Algorithm using Bit-Split String-Matching Engines",
            "venue": "2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)",
            "year": "2021",
            "abstract": "This paper describes a reconfigurable hardware implementation of CommentzWalter algorithm with bit-split string matching engines to match multiple protein sequences. It is reported that multiple pattern matching using the most widely used Aho-Corasick algorithm for different applications has been carried out on graphics processing units and field programmable gate arrays to accelerate the matching process. Commentz-Walter algorithm, is a multiple pattern matching algorithm and more complex than Aho-Corasick. There are no reports of it being directly implemented in any hardware platform except as software implementations on general purpose processors. In this work, a specific architecture for our target application using CommentzWalter algorithm has been developed and tested with a simulator for hardware description languages. This architecture can match multiple patterns of proteins efficiently when implemented on a Field Programmable Gate Array. Finally, we compare a previously developed hardware architecture of bit-split Aho-Corasick with our bit-split Commentz-Walter architecture. Using the Intel Stratix IV GX EP4SGX230KF40C2 FPGA chip as the target device, the compilation results with Quartus II show that the synthesis logic utilization is 5% with 2203 total number of registers, 64896 FPGA block memory bits and 4 DSP block 18-bit elements. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the Commentz-Walter algorithm.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "Shirley D. Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICter53630.2021.9774805",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Software algorithms",
                "Computer architecture",
                "Logic gates",
                "Hardware",
                "Software",
                "Registers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICter53630.2021.9774805/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICter53630.2021.9774805/index.json"
        },
        {
            "title": "Heterogeneous processor pipeline for a product cipher application",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "Processing data received as a stream is a task commonly performed by modern embedded devices, in a wide range of applications such as multimedia (encoding/decoding/ playing media), networking (switching and routing), digital security, scientific data processing, etc. Such processing normally tends to be calculation intensive and therefore requiring significant processing power. Therefore, hardware acceleration methods to increase the performance of such applications constitute an important area of study. In this paper, we present an evaluation of one such method to process streaming data, namely multi-processor pipeline architecture. The hardware is based on a Multiple-Processor System on Chip (MPSoC), using a data encryption algorithm as a case study. The algorithm is partitioned on a coarse grained level and mapped on to an MPSoC with five processor cores in a pipeline, using specifically configured Xtensa LX3 cores. The system is then selectively optimized by strengthening and pruning the resources of each processor core. The optimized system is evaluated and compared against an optimal single-processor System on Chip (SoC) for the same application. The multiple-processor pipeline system for data encryption algorithms used was observed to provide significant speed ups, up to 4.45 times that of the single-processor system, which is close to the ideal speed up from a five-stage pipeline.",
            "authors": [
                "Isuru B. Nawinne",
                "Mahanama S. Wickramasinghe",
                "Roshan G. Ragel",
                "Member",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038036",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7299.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pipelines",
                "Encryption",
                "Algorithm design and analysis",
                "Partitioning algorithms",
                "Streaming media",
                "Computer architecture"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038036/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038036/index.json"
        }
    ],
    "Computer bugs": [
        {
            "title": "Using microkernel based virtualization for Byzantine fault tolerance",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "A Byzantine fault is a failure that cannot be identified by observing the output of a component; the component produces a wrong result as opposed to not producing a result at all or producing a result that can be identified as wrong. Such faults may be caused by a number of causes including software bugs and malicious attacks. Tolerating such faults is essential for a critical system. Isolated replication and majority voting is a well established technique to tolerate Byzantine faults. Current implementations of such systems either uses replicated hardware or software virtualization-using virtual machine monitors-to get the illusion of hardware replication to tolerate Byzantine faults. In this paper, we investigate the possibility of using microkernel technology to achieve the isolated replication and discuss the features of a microkernel API suitable for such a deployment. The advantage of our approach is that it reduces the cost of additional hardware or avoid the complexity of virtualization required to mimic hardware replication. We used a single machine, running the L4 microkernel to provide the isolation required for the replicas. All replicas run in parallel and majority voting is performed to obtain the correct result in the presence of Byzantine faults. We selected the AES encryption algorithms for our case study and faults were deliberately injected to replicas to mimic Byzantine behavior. Our experiments show that it is feasible to use microkernels technology for this purpose.",
            "authors": [
                "Asanka Senevirathna",
                "Bhathiya Wasala",
                "Buddhika Ranaweera",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038037",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Kernel",
                "Computer bugs",
                "Information systems",
                "USA Councils",
                "Fault tolerant systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038037/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038037/index.json"
        }
    ],
    "Computer crime": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        }
    ],
    "Computer hacking": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Computer industry": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        },
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Computer networks": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Computer science": [
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Computer security": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Computer systems organization": [
        {
            "title": "DeepLight: Robust & Unobtrusive Real-time Screen-Camera Communication for Real-World Displays",
            "venue": "2021 20th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)",
            "year": "2021",
            "abstract": "The paper introduces a novel, holistic approach for robust Screen-Camera Communication (SCC), where video content on a screen is visually encoded in a human-imperceptible fashion and decoded by a camera capturing images of such screen content. We first show that state-of-the-art SCC techniques have two key limitations for in-the-wild deployment: (a) the decoding accuracy drops rapidly under even modest screen extraction errors from the captured images, and (b) they generate perceptible flickers on common refresh rate screens even with minimal modulation of pixel intensity. To overcome these challenges, we introduce DeepLight, a system that incorporates machine learning (ML) models in the decoding pipeline to achieve humanly-imperceptible, moderately high SCC rates under diverse real-world conditions. DeepLight's key innovation is the design of a Deep Neural Network (DNN) based decoder that collectively decodes all the bits spatially encoded in a display frame, without attempting to precisely isolate the pixels associated with each encoded bit. In addition, DeepLight supports imperceptible encoding by selectively modulating the intensity of only the Blue channel, and provides reasonably accurate screen extraction (IoU values \u00e2\u0089\u00a5 83%) by using state-of-the-art object detection DNN pipelines. We show that a fully functional DeepLight system is able to robustly achieve high decoding accuracy (frame error rate < 0.2) and moderately-high data goodput (\u00e2\u0089\u00a50.95 Kbps) using a human-held smartphone camera, even over larger screen-camera distances (~ 2m).",
            "authors": [
                "Vu Tran",
                "Gihan Jayatilaka",
                "Ashwin Ashok",
                "Archan Misra"
            ],
            "doi": "https://doi.org/10.1145/3412382.3458269",
            "preprint": "https://arxiv.org/pdf/2105.05092",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/deeplight/presentation.pdf",
            "project": "#",
            "codebase": "https://github.com/gihanjayatilaka/deeplight",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Human-centered computing",
                "Ubiquitous and mobile computing",
                "Computer systems organization",
                "Embedded and cyber-physical systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/3412382.3458269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/3412382.3458269/index.json"
        },
        {
            "title": "DRMA: dynamically reconfigurable MPSoC architecture",
            "venue": "GLSVLSI '13: Proceedings of the 23rd ACM international conference on Great lakes symposium on VLSI",
            "year": "2013",
            "abstract": "Embedded systems are ubiquitous and are deployed in a large range of applications. Designing and fabricating Integrated Circuits (ICs) targeting such different range of applications is expensive. Designers seek flexible processors which efficiently execute a multitude of applications. FPGAs are considered affordable, but design cost, high reconfiguration delay and power consumption are all prohibitive. In this paper, we propose a novel ASIC based flexible MPSoC architecture, which can execute separate tasks in parallel, and it can be configured to execute single task with wide data widths or execute multiple tasks with varying data widths. The architecture presented, called Dynamically Reconfigurable MPSoC Architecture (DRMA), can be rapidly reconfigured through instructions. We present applications as case studies to showcase the flexibility and efficacy of DRMA. Results show for an additional area overhead of about 5%, the system is capable of working as four 32-bit processors, a single 128 bit processor or as a pipelined processing system.",
            "authors": [
                "Lawrance Zhang",
                "Jude Angelo Ambrose",
                "Jorgen Peddersen",
                "Sri Parameswaran",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Kewal K. Saluja"
            ],
            "doi": "https://doi.org/10.1145/2483028.2483101",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Computer systems organization",
                "Architectures",
                "Serial architectures",
                "Pipeline computing",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2483028.2483101/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2483028.2483101/index.json"
        }
    ],
    "Computers": [
        {
            "title": "Constant time encryption as a countermeasure against remote cache timing attacks",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Rijndael was standardized in 2001 by National Institute of Standard and Technology as the Advanced Encryption Standard (AES). AES is still being used to encrypt financial, military and even government confidential data. In 2005, Bernstein illustrated a remote cache timing attack on AES using the client-server architecture and therefore proved a side channel in its software implementation. Over the years, a number of countermeasures have been proposed against cache timing attacks both using hardware and software. Although the software based countermeasures are flexible and easy to deploy, most of such countermeasures are vulnerable to statistical analysis. In this paper, we propose a novel software based countermeasure against cache timing attacks, known as constant time encryption, which we believe is secure against statistical analysis. The countermeasure we proposed performs rescheduling of instructions such that the encryption rounds will consume constant time independent of the cache hits and misses. Through experiments, we prove that our countermeasure is secure against Bernstein's cache timing attack.",
            "authors": [
                "Darshana Jayasinghe",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419893",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7293.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Encryption",
                "Timing",
                "Software",
                "Hardware",
                "Clocks",
                "Computers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419893/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419893/index.json"
        }
    ],
    "Conferences": [
        {
            "title": "Data Mining System for Predicting a Winning Cricket Team",
            "venue": "2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2021",
            "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u00e2\u0080\u0099 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
            "authors": [
                "Dinithi Hasanika",
                "Roshani Dilhara",
                "Dulanjali Liyanage",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Uncertainty",
                "Statistical analysis",
                "Conferences",
                "Games",
                "Machine learning",
                "Data mining",
                "Australia"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS53135.2021.9660702/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS53135.2021.9660702/index.json"
        }
    ],
    "Control systems": [
        {
            "title": "Design and implementation of a statechart based reconfigurable elevator controller",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "This paper presents a simple and clear method to design and implement a reconfigurable elevator controller using an FPGA, which can be implemented for an elevator with any (N) number of floors, with specified inputs and outputs. A model based design approach was followed. We started from a state chart model developed for a prototype elevator with three floors. Extension of the model for a variable number of floors was considered. Controller for the prototype system was implemented in ladder logic on a PLC and the limitations of that approach with regard to re-configurability were identified: viz., in the extension of elevator controller for `N' no of floors. Next VHDL code was developed for a reconfigurable elevator controller where, by changing a variable corresponding to the required number of floors, the suitable code can be generated. The controller thus generated can be implemented in an FPGA. The method was successfully tested on a Xilinx Spartan 3AN FPGA.",
            "authors": [
                "HPAP Jayawardana",
                "HWKM Amarasekara",
                "PTS Peelikumbura",
                "WAKC Jayathilaka",
                "SG Abeyaratne",
                "SD Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038093",
            "preprint": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "pdf": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Floors",
                "Field programmable gate arrays",
                "Prototypes",
                "Sensors",
                "Mathematical model",
                "Control systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038093/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038093/index.json"
        }
    ],
    "Cryptography": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Cycle consistency": [
        {
            "title": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for Enhancing Low Light Images",
            "venue": "MERcon",
            "year": "2020",
            "abstract": "Low light image enhancement is an important challenge for the development of robust computer vision algorithms. The machine learning approaches to this have been either unsupervised, supervised based on paired dataset or supervised based on unpaired dataset. This paper presents a novel deep learning pipeline that can learn from both paired and unpaired datasets. Convolution Neural Networks (CNNs) that are optimized to minimize standard loss, and Generative Adversarial Networks (GANs) that are optimized to minimize the adversarial loss are used to achieve different steps of the low light image enhancement process. Cycle consistency loss and a patched discriminator are utilized to further improve the performance. The paper also analyses the functionality and the performance of different components, hidden layers, and the entire pipeline.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Roshan Goldaliyadda",
                "Parakrama Ekanayeka",
                "Roshan Ragel",
                "Vijitha Herath"
            ],
            "doi": "https://doi.org/10.1109/MERCon50084.2020.9185373",
            "preprint": "https://arxiv.org/pdf/2006.15304.pdf",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/mercon-2020-presentation.pdf",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Low-light image enhancement",
                "Retinex theory",
                "Generative adversarial networks",
                "Cycle consistency",
                "Computer Vision"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon50084.2020.9185373/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon50084.2020.9185373/index.json"
        }
    ],
    "DNA": [
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        }
    ],
    "Data communication": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Data mining": [
        {
            "title": " Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
            "authors": [
                "Pranavan Somaskandhan",
                "Gihan Wijesinghe",
                "Leshan Bashitha Wijegunawardana",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300399",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Sports equipment",
                "Data mining",
                "Measurement",
                "Support vector machines",
                "Statistical analysis",
                "Games",
                "Relational databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300399/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300399/index.json"
        },
        {
            "title": "Data Mining System for Predicting a Winning Cricket Team",
            "venue": "2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2021",
            "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u00e2\u0080\u0099 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
            "authors": [
                "Dinithi Hasanika",
                "Roshani Dilhara",
                "Dulanjali Liyanage",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Uncertainty",
                "Statistical analysis",
                "Conferences",
                "Games",
                "Machine learning",
                "Data mining",
                "Australia"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS53135.2021.9660702/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS53135.2021.9660702/index.json"
        }
    ],
    "Data security": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        },
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Databases": [
        {
            "title": "A structured hardware software architecture for peptide based diagnosis \u00e2\u0080\u0094 Sub-string matching problem with limited tolerance",
            "venue": "2014 7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "S. Devapriya Dewasurendra",
                "Roshan G. Ragel",
                "Mahesan Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069624",
            "preprint": "https://arxiv.org/pdf/1412.7811",
            "pdf": "https://arxiv.org/pdf/1412.7811",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Amino acids",
                "Software",
                "Automata",
                "Databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069624/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069624/index.json"
        },
        {
            "title": "Visual Design Platform for Wireless Sensor Network",
            "venue": "2018 Moratuwa Engineering Research Conference (MERCon)",
            "year": "2018",
            "abstract": "Wireless Sensor Networks (WSN) are being widely used for sensing physical parameters in a broad geographical area. The person who needs WSN will have a pictorial idea of the sensor network. The problem in the traditional method is that the person who needs the WSN should explain the pictorial view of the sensor network to a commercial vendor and buy it from them or they should design it from the scratch. What we proposed in our solution is to develop a platform so that the person who needs the WSN can directly draw the pictorial view on a canvas and then it can automatically generate all the required firmware for the microcontrollers and wiring diagrams. The user is then required only to follow a few instructions to complete the real world implementation of WSNs. This paper is about developing a visual platform to design WSNs. The WSN designing platform was built as a web application, so it can manage a large number of supported sensors and microcontrollers. This means that if one user adds the device driver for any sensor or a microcontroller the other users can directly use it from the WSN design platform without worrying about hardware programming. Further, if anyone needs a new sensor or microcontroller to be supported by this visual design platform, this design tool will have interfaces to directly add new sensors and microcontrollers. The proposed method is affordable for developing custom wireless sensor networks.",
            "authors": [
                "Rosen Silva",
                "Asela Dasanayaka",
                "Roshan Ragel",
                "Asitha Bandaranayake"
            ],
            "doi": "https://doi.org/10.1109/MERCon.2018.8421896",
            "preprint": "https://www.researchgate.net/profile/Asitha-Bandaranayake-3/publication/327517623_Visual_Design_Platform_for_Wireless_Sensor_Network/links/5f98da03458515b7cfa4013c/Visual-Design-Platform-for-Wireless-Sensor-Network.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Wireless sensor networks",
                "Microcontrollers",
                "Databases",
                "Skeleton",
                "Visualization",
                "Hardware",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon.2018.8421896/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon.2018.8421896/index.json"
        }
    ],
    "Diseases": [
        {
            "title": "Chronic kidney disease prediction using machine learning methods",
            "venue": "2020 Moratuwa Engineering Research Conference (MERCon) - IEEE",
            "year": "2020",
            "abstract": "Chronic Kidney Disease (CKD) or chronic renal disease has become a major issue with a steady growth rate. A person can only survive without kidneys for an average time of 18 days, which makes a huge demand for a kidney transplant and Dialysis. It is important to have effective methods for early prediction of CKD. Machine learning methods are effective in CKD prediction. This work proposes a workflow to predict CKD status based on clinical data, incorporating data prepossessing, a missing value handling method with collaborative filtering and attributes selection. Out of the 11 machine learning methods considered, the extra tree classifier and random forest classifier are shown to result in the highest accuracy and minimal bias to the attributes. The research also considers the practical aspects of data collection and highlights the importance of incorporating domain knowledge when using machine learning for CKD status prediction.",
            "authors": [
                "Imesh Udara Ekanayake; Damayanthi Herath"
            ],
            "doi": " https://doi.org/10.1109/MERCon50084.2020.9185249",
            "preprint": "#",
            "pdf": "https://www.researchgate.net/profile/Imesh-Ekanayake/publication/344319206_Chronic_Kidney_Disease_Prediction_Using_Machine_Learning_Methods/links/5f672571458515b7cf418d5b/Chronic-Kidney-Disease-Prediction-Using-Machine-Learning-Methods.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Machine Learning and Data Mining"
            ],
            "funding": "",
            "tags": [
                "Kidney",
                "Diseases",
                "Machine learning",
                "Red blood cells",
                "Hypertension"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/ 10.1109/MERCon50084.2020.9185249/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/ 10.1109/MERCon50084.2020.9185249/index.json"
        }
    ],
    "Elevators": [
        {
            "title": "Design and implementation of a statechart based reconfigurable elevator controller",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "This paper presents a simple and clear method to design and implement a reconfigurable elevator controller using an FPGA, which can be implemented for an elevator with any (N) number of floors, with specified inputs and outputs. A model based design approach was followed. We started from a state chart model developed for a prototype elevator with three floors. Extension of the model for a variable number of floors was considered. Controller for the prototype system was implemented in ladder logic on a PLC and the limitations of that approach with regard to re-configurability were identified: viz., in the extension of elevator controller for `N' no of floors. Next VHDL code was developed for a reconfigurable elevator controller where, by changing a variable corresponding to the required number of floors, the suitable code can be generated. The controller thus generated can be implemented in an FPGA. The method was successfully tested on a Xilinx Spartan 3AN FPGA.",
            "authors": [
                "HPAP Jayawardana",
                "HWKM Amarasekara",
                "PTS Peelikumbura",
                "WAKC Jayathilaka",
                "SG Abeyaratne",
                "SD Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038093",
            "preprint": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "pdf": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Floors",
                "Field programmable gate arrays",
                "Prototypes",
                "Sensors",
                "Mathematical model",
                "Control systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038093/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038093/index.json"
        },
        {
            "title": "Statechart based modeling and controller implementation of complex reactive systems",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Statechart formalism has been a preferred choice for modeling complex reactive systems (CRS) in recent years. It has inbuilt powerful features of orthogonality, hierarchy, intermodular communication and history. Once statechart based system modeling is done the next issues to be addressed are (1) modular verification of the system for failsafe operation under all possible working conditions (2) progressive controller implementation together with the supervisory control while maintaining traceability and re-configurability and (3) facilitation of controller adaptation for progressive incorporation of security features and supervisory specifications. An elevator system was designed and built to reflect exigencies of a typical CRS hardware/software platform. A controller was designed to meet the above requirements and tested on the platform to validate the feasibility of model-based control design/verification methodology for real scale systems. Modularity was achieved by developing the statechart model of the plant into a tree of communicating language generators. Progresively verified modules were then translated into sequential function charts (SFC) which were finally integrated to form a complete flat SFC. The SFC was then implemented on a PLC platform (Telemechanique). The program was first validated in simulation using Telemechanique \u00e2\u0080\u009cTwidosuite\u00e2\u0080\u009d for different operating conditions and finally tested on the elevator system.",
            "authors": [
                "AC Vidanapathirana",
                "SD Dewasurendra",
                "SG Abeyratne"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038120",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Generators",
                "Software",
                "Automata",
                "Process control",
                "Floors",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038120/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038120/index.json"
        },
        {
            "title": "Model in the loop testing of complex reactive systems",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Currently there is a new trend in the design of Complex Reactive Systems (CRS) towards model based development. Software components are no longer hard written in C or Assembler code but modeled with MATLAB/Simulink, Statemate or similar tools. Model based designs allow development of high level models that can be used for simulations in very early stages of the design process. However the quality assurance of model based developments, specially testing is still poorly supported [1]. In this paper we discuss the characteristics of model based design process and the need of quality assurance methods throughout the design process. We have selected a fully functional prototype passenger elevator as the CRS. A model based design approach is followed throughout the design phase. Model-in-the loop (MiL) testing is carried out as the quality assurance technique and the results are presented. Then the translation of the MiL test into a Hardware-in the-loop (HiL) test is presented.",
            "authors": [
                "A. Vidanapathirana",
                "S. D. Dewasurendra",
                "S. G. Abeyaratne"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6731950",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mathematical model",
                "Induction motors",
                "Testing",
                "MATLAB",
                "Elevators",
                "Floors"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6731950/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6731950/index.json"
        }
    ],
    "Embedded and cyber-physical systems": [
        {
            "title": "DeepLight: Robust & Unobtrusive Real-time Screen-Camera Communication for Real-World Displays",
            "venue": "2021 20th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)",
            "year": "2021",
            "abstract": "The paper introduces a novel, holistic approach for robust Screen-Camera Communication (SCC), where video content on a screen is visually encoded in a human-imperceptible fashion and decoded by a camera capturing images of such screen content. We first show that state-of-the-art SCC techniques have two key limitations for in-the-wild deployment: (a) the decoding accuracy drops rapidly under even modest screen extraction errors from the captured images, and (b) they generate perceptible flickers on common refresh rate screens even with minimal modulation of pixel intensity. To overcome these challenges, we introduce DeepLight, a system that incorporates machine learning (ML) models in the decoding pipeline to achieve humanly-imperceptible, moderately high SCC rates under diverse real-world conditions. DeepLight's key innovation is the design of a Deep Neural Network (DNN) based decoder that collectively decodes all the bits spatially encoded in a display frame, without attempting to precisely isolate the pixels associated with each encoded bit. In addition, DeepLight supports imperceptible encoding by selectively modulating the intensity of only the Blue channel, and provides reasonably accurate screen extraction (IoU values \u00e2\u0089\u00a5 83%) by using state-of-the-art object detection DNN pipelines. We show that a fully functional DeepLight system is able to robustly achieve high decoding accuracy (frame error rate < 0.2) and moderately-high data goodput (\u00e2\u0089\u00a50.95 Kbps) using a human-held smartphone camera, even over larger screen-camera distances (~ 2m).",
            "authors": [
                "Vu Tran",
                "Gihan Jayatilaka",
                "Ashwin Ashok",
                "Archan Misra"
            ],
            "doi": "https://doi.org/10.1145/3412382.3458269",
            "preprint": "https://arxiv.org/pdf/2105.05092",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/deeplight/presentation.pdf",
            "project": "#",
            "codebase": "https://github.com/gihanjayatilaka/deeplight",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Human-centered computing",
                "Ubiquitous and mobile computing",
                "Computer systems organization",
                "Embedded and cyber-physical systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/3412382.3458269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/3412382.3458269/index.json"
        }
    ],
    "Embedded systems": [
        {
            "title": "A Study on Instruction-set Selection Using Multi-application Based Application Specific Instruction-set Processors",
            "venue": "2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems",
            "year": "2013",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analyzing the instructions for inter-domain and intra-domain designs. Metrics analyzed are the reusable instructions and the extra cost to add a certain application, together with the hardware synthesis numbers, such as area, timing and delay. A wide range of applications from various application benchmarks (BioPerf, CommBench, MediaBench, MiBench and SPEC2006) and domains are analyzed for three different architectures (LEON2, PISA and ARM-Thumb). Processors are generated for these architectures for different configurations to analyze and synthesize. Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless the kind of architecture (and therefore the ISA).",
            "authors": [
                "Roshan G. Ragel",
                "Swarnalatha Radhakrishnan",
                "Jude Angelo Ambrose",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/VLSID.2013.154",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/261501995_A_Study_on_Instruction-set_Selection_Using_Multi-application_Based_Application_Specific_Instruction-set_Processors/links/54e48faf0cf2dbf60696e9b4/A-Study-on-Instruction-set-Selection-Using-Multi-application-Based-Application-Specific-Instruction-set-Processors.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Thumb",
                "Embedded systems",
                "Benchmark testing",
                "Standards",
                "Instruction sets"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/VLSID.2013.154/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/VLSID.2013.154/index.json"
        }
    ],
    "Encryption": [
        {
            "title": "Heterogeneous processor pipeline for a product cipher application",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "Processing data received as a stream is a task commonly performed by modern embedded devices, in a wide range of applications such as multimedia (encoding/decoding/ playing media), networking (switching and routing), digital security, scientific data processing, etc. Such processing normally tends to be calculation intensive and therefore requiring significant processing power. Therefore, hardware acceleration methods to increase the performance of such applications constitute an important area of study. In this paper, we present an evaluation of one such method to process streaming data, namely multi-processor pipeline architecture. The hardware is based on a Multiple-Processor System on Chip (MPSoC), using a data encryption algorithm as a case study. The algorithm is partitioned on a coarse grained level and mapped on to an MPSoC with five processor cores in a pipeline, using specifically configured Xtensa LX3 cores. The system is then selectively optimized by strengthening and pruning the resources of each processor core. The optimized system is evaluated and compared against an optimal single-processor System on Chip (SoC) for the same application. The multiple-processor pipeline system for data encryption algorithms used was observed to provide significant speed ups, up to 4.45 times that of the single-processor system, which is close to the ideal speed up from a five-stage pipeline.",
            "authors": [
                "Isuru B. Nawinne",
                "Mahanama S. Wickramasinghe",
                "Roshan G. Ragel",
                "Member",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038036",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7299.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pipelines",
                "Encryption",
                "Algorithm design and analysis",
                "Partitioning algorithms",
                "Streaming media",
                "Computer architecture"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038036/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038036/index.json"
        },
        {
            "title": "Constant time encryption as a countermeasure against remote cache timing attacks",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Rijndael was standardized in 2001 by National Institute of Standard and Technology as the Advanced Encryption Standard (AES). AES is still being used to encrypt financial, military and even government confidential data. In 2005, Bernstein illustrated a remote cache timing attack on AES using the client-server architecture and therefore proved a side channel in its software implementation. Over the years, a number of countermeasures have been proposed against cache timing attacks both using hardware and software. Although the software based countermeasures are flexible and easy to deploy, most of such countermeasures are vulnerable to statistical analysis. In this paper, we propose a novel software based countermeasure against cache timing attacks, known as constant time encryption, which we believe is secure against statistical analysis. The countermeasure we proposed performs rescheduling of instructions such that the encryption rounds will consume constant time independent of the cache hits and misses. Through experiments, we prove that our countermeasure is secure against Bernstein's cache timing attack.",
            "authors": [
                "Darshana Jayasinghe",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419893",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7293.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Encryption",
                "Timing",
                "Software",
                "Hardware",
                "Clocks",
                "Computers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419893/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419893/index.json"
        }
    ],
    "Engines": [
        {
            "title": "Instruction-set selection for multi-application based ASIP design: An instruction-level study",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analysing the instructions for inter-domain and intra-domain designs. Metrics analysed are the reusable instructions and the extra cost to add a certain application. A wide range of applications from various application benchmarks (MiBench, MediaBench and SPEC2006) and domains are analysed for two different architectures (ARM-Thumb and PISA). Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless of the architecture (and therefore the ISA).",
            "authors": [
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Angelo Ambrose"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419895",
            "preprint": "https://arxiv.org/pdf/1403.7291.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "GSM",
                "Engines",
                "Integrated circuits",
                "Transform coding"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419895/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419895/index.json"
        }
    ],
    "Entropy": [
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Event alignment": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Fault tolerant systems": [
        {
            "title": "Using microkernel based virtualization for Byzantine fault tolerance",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "A Byzantine fault is a failure that cannot be identified by observing the output of a component; the component produces a wrong result as opposed to not producing a result at all or producing a result that can be identified as wrong. Such faults may be caused by a number of causes including software bugs and malicious attacks. Tolerating such faults is essential for a critical system. Isolated replication and majority voting is a well established technique to tolerate Byzantine faults. Current implementations of such systems either uses replicated hardware or software virtualization-using virtual machine monitors-to get the illusion of hardware replication to tolerate Byzantine faults. In this paper, we investigate the possibility of using microkernel technology to achieve the isolated replication and discuss the features of a microkernel API suitable for such a deployment. The advantage of our approach is that it reduces the cost of additional hardware or avoid the complexity of virtualization required to mimic hardware replication. We used a single machine, running the L4 microkernel to provide the isolation required for the replicas. All replicas run in parallel and majority voting is performed to obtain the correct result in the presence of Byzantine faults. We selected the AES encryption algorithms for our case study and faults were deliberately injected to replicas to mimic Byzantine behavior. Our experiments show that it is feasible to use microkernels technology for this purpose.",
            "authors": [
                "Asanka Senevirathna",
                "Bhathiya Wasala",
                "Buddhika Ranaweera",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038037",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Kernel",
                "Computer bugs",
                "Information systems",
                "USA Councils",
                "Fault tolerant systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038037/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038037/index.json"
        }
    ],
    "Field programmable gate arrays": [
        {
            "title": "Tile optimization for area in FPGA based hardware acceleration of peptide identification",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Advances in life sciences over the last few decades have lead to the generation of a huge amount of biological data. Computing research has become a vital part in driving biological discovery where analysis and categorization of biological data are involved. String matching algorithms can be applied for protein/gene sequence matching and with the phenomenal increase in the size of string databases to be analyzed, software implementations of these algorithms seems to have hit a hard limit and hardware acceleration is increasingly being sought. Several hardware platforms such as Field Programmable Gate Arrays (FPGA), Graphics Processing Units (GPU) and Chip Multi Processors (CMP) are being explored as hardware platforms. In this paper, we give a comprehensive overview of the literature on hardware acceleration of string matching algorithms, we take an FPGA hardware exploration and expedite the design time by a design automation technique. Further, our design automation is also optimized for better hardware utilization through optimizing the number of peptides that can be represented in an FPGA tile. The results indicate significant improvements in design time and hardware utilization which are reported in this paper.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "Roshan G Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038056",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7296.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Peptides",
                "Field programmable gate arrays",
                "Tiles",
                "Hardware",
                "Software algorithms",
                "Proteins",
                "Software"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038056/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038056/index.json"
        },
        {
            "title": "Design and implementation of a statechart based reconfigurable elevator controller",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "This paper presents a simple and clear method to design and implement a reconfigurable elevator controller using an FPGA, which can be implemented for an elevator with any (N) number of floors, with specified inputs and outputs. A model based design approach was followed. We started from a state chart model developed for a prototype elevator with three floors. Extension of the model for a variable number of floors was considered. Controller for the prototype system was implemented in ladder logic on a PLC and the limitations of that approach with regard to re-configurability were identified: viz., in the extension of elevator controller for `N' no of floors. Next VHDL code was developed for a reconfigurable elevator controller where, by changing a variable corresponding to the required number of floors, the suitable code can be generated. The controller thus generated can be implemented in an FPGA. The method was successfully tested on a Xilinx Spartan 3AN FPGA.",
            "authors": [
                "HPAP Jayawardana",
                "HWKM Amarasekara",
                "PTS Peelikumbura",
                "WAKC Jayathilaka",
                "SG Abeyaratne",
                "SD Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038093",
            "preprint": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "pdf": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Floors",
                "Field programmable gate arrays",
                "Prototypes",
                "Sensors",
                "Mathematical model",
                "Control systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038093/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038093/index.json"
        },
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        }
    ],
    "Floors": [
        {
            "title": "Design and implementation of a statechart based reconfigurable elevator controller",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "This paper presents a simple and clear method to design and implement a reconfigurable elevator controller using an FPGA, which can be implemented for an elevator with any (N) number of floors, with specified inputs and outputs. A model based design approach was followed. We started from a state chart model developed for a prototype elevator with three floors. Extension of the model for a variable number of floors was considered. Controller for the prototype system was implemented in ladder logic on a PLC and the limitations of that approach with regard to re-configurability were identified: viz., in the extension of elevator controller for `N' no of floors. Next VHDL code was developed for a reconfigurable elevator controller where, by changing a variable corresponding to the required number of floors, the suitable code can be generated. The controller thus generated can be implemented in an FPGA. The method was successfully tested on a Xilinx Spartan 3AN FPGA.",
            "authors": [
                "HPAP Jayawardana",
                "HWKM Amarasekara",
                "PTS Peelikumbura",
                "WAKC Jayathilaka",
                "SG Abeyaratne",
                "SD Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038093",
            "preprint": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "pdf": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Floors",
                "Field programmable gate arrays",
                "Prototypes",
                "Sensors",
                "Mathematical model",
                "Control systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038093/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038093/index.json"
        },
        {
            "title": "Statechart based modeling and controller implementation of complex reactive systems",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Statechart formalism has been a preferred choice for modeling complex reactive systems (CRS) in recent years. It has inbuilt powerful features of orthogonality, hierarchy, intermodular communication and history. Once statechart based system modeling is done the next issues to be addressed are (1) modular verification of the system for failsafe operation under all possible working conditions (2) progressive controller implementation together with the supervisory control while maintaining traceability and re-configurability and (3) facilitation of controller adaptation for progressive incorporation of security features and supervisory specifications. An elevator system was designed and built to reflect exigencies of a typical CRS hardware/software platform. A controller was designed to meet the above requirements and tested on the platform to validate the feasibility of model-based control design/verification methodology for real scale systems. Modularity was achieved by developing the statechart model of the plant into a tree of communicating language generators. Progresively verified modules were then translated into sequential function charts (SFC) which were finally integrated to form a complete flat SFC. The SFC was then implemented on a PLC platform (Telemechanique). The program was first validated in simulation using Telemechanique \u00e2\u0080\u009cTwidosuite\u00e2\u0080\u009d for different operating conditions and finally tested on the elevator system.",
            "authors": [
                "AC Vidanapathirana",
                "SD Dewasurendra",
                "SG Abeyratne"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038120",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Generators",
                "Software",
                "Automata",
                "Process control",
                "Floors",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038120/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038120/index.json"
        },
        {
            "title": "Model in the loop testing of complex reactive systems",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Currently there is a new trend in the design of Complex Reactive Systems (CRS) towards model based development. Software components are no longer hard written in C or Assembler code but modeled with MATLAB/Simulink, Statemate or similar tools. Model based designs allow development of high level models that can be used for simulations in very early stages of the design process. However the quality assurance of model based developments, specially testing is still poorly supported [1]. In this paper we discuss the characteristics of model based design process and the need of quality assurance methods throughout the design process. We have selected a fully functional prototype passenger elevator as the CRS. A model based design approach is followed throughout the design phase. Model-in-the loop (MiL) testing is carried out as the quality assurance technique and the results are presented. Then the translation of the MiL test into a Hardware-in the-loop (HiL) test is presented.",
            "authors": [
                "A. Vidanapathirana",
                "S. D. Dewasurendra",
                "S. G. Abeyaratne"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6731950",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mathematical model",
                "Induction motors",
                "Testing",
                "MATLAB",
                "Elevators",
                "Floors"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6731950/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6731950/index.json"
        }
    ],
    "GPU": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "GPU acceleration": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "GSM": [
        {
            "title": "Instruction-set selection for multi-application based ASIP design: An instruction-level study",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analysing the instructions for inter-domain and intra-domain designs. Metrics analysed are the reusable instructions and the extra cost to add a certain application. A wide range of applications from various application benchmarks (MiBench, MediaBench and SPEC2006) and domains are analysed for two different architectures (ARM-Thumb and PISA). Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless of the architecture (and therefore the ISA).",
            "authors": [
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Angelo Ambrose"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419895",
            "preprint": "https://arxiv.org/pdf/1403.7291.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "GSM",
                "Engines",
                "Integrated circuits",
                "Transform coding"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419895/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419895/index.json"
        }
    ],
    "Games": [
        {
            "title": " Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
            "authors": [
                "Pranavan Somaskandhan",
                "Gihan Wijesinghe",
                "Leshan Bashitha Wijegunawardana",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300399",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Sports equipment",
                "Data mining",
                "Measurement",
                "Support vector machines",
                "Statistical analysis",
                "Games",
                "Relational databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300399/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300399/index.json"
        },
        {
            "title": "Data Mining System for Predicting a Winning Cricket Team",
            "venue": "2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2021",
            "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u00e2\u0080\u0099 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
            "authors": [
                "Dinithi Hasanika",
                "Roshani Dilhara",
                "Dulanjali Liyanage",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Uncertainty",
                "Statistical analysis",
                "Conferences",
                "Games",
                "Machine learning",
                "Data mining",
                "Australia"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS53135.2021.9660702/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS53135.2021.9660702/index.json"
        }
    ],
    "Generative adversarial networks": [
        {
            "title": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for Enhancing Low Light Images",
            "venue": "MERcon",
            "year": "2020",
            "abstract": "Low light image enhancement is an important challenge for the development of robust computer vision algorithms. The machine learning approaches to this have been either unsupervised, supervised based on paired dataset or supervised based on unpaired dataset. This paper presents a novel deep learning pipeline that can learn from both paired and unpaired datasets. Convolution Neural Networks (CNNs) that are optimized to minimize standard loss, and Generative Adversarial Networks (GANs) that are optimized to minimize the adversarial loss are used to achieve different steps of the low light image enhancement process. Cycle consistency loss and a patched discriminator are utilized to further improve the performance. The paper also analyses the functionality and the performance of different components, hidden layers, and the entire pipeline.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Roshan Goldaliyadda",
                "Parakrama Ekanayeka",
                "Roshan Ragel",
                "Vijitha Herath"
            ],
            "doi": "https://doi.org/10.1109/MERCon50084.2020.9185373",
            "preprint": "https://arxiv.org/pdf/2006.15304.pdf",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/mercon-2020-presentation.pdf",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Low-light image enhancement",
                "Retinex theory",
                "Generative adversarial networks",
                "Cycle consistency",
                "Computer Vision"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon50084.2020.9185373/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon50084.2020.9185373/index.json"
        }
    ],
    "Generators": [
        {
            "title": "Statechart based modeling and controller implementation of complex reactive systems",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Statechart formalism has been a preferred choice for modeling complex reactive systems (CRS) in recent years. It has inbuilt powerful features of orthogonality, hierarchy, intermodular communication and history. Once statechart based system modeling is done the next issues to be addressed are (1) modular verification of the system for failsafe operation under all possible working conditions (2) progressive controller implementation together with the supervisory control while maintaining traceability and re-configurability and (3) facilitation of controller adaptation for progressive incorporation of security features and supervisory specifications. An elevator system was designed and built to reflect exigencies of a typical CRS hardware/software platform. A controller was designed to meet the above requirements and tested on the platform to validate the feasibility of model-based control design/verification methodology for real scale systems. Modularity was achieved by developing the statechart model of the plant into a tree of communicating language generators. Progresively verified modules were then translated into sequential function charts (SFC) which were finally integrated to form a complete flat SFC. The SFC was then implemented on a PLC platform (Telemechanique). The program was first validated in simulation using Telemechanique \u00e2\u0080\u009cTwidosuite\u00e2\u0080\u009d for different operating conditions and finally tested on the elevator system.",
            "authors": [
                "AC Vidanapathirana",
                "SD Dewasurendra",
                "SG Abeyratne"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038120",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Generators",
                "Software",
                "Automata",
                "Process control",
                "Floors",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038120/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038120/index.json"
        }
    ],
    "Genetic algorithms": [
        {
            "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
            "authors": [
                "AH Wijethunge",
                "JV Wijekulasooriya",
                "Janaka B Ekanayake",
                "KB Samarakoon",
                "A Polpitiya"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300374",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Schedules",
                "Genetic algorithms",
                "Optimization",
                "Wind power generation",
                "Power demand",
                "Wind turbines",
                "Mathematical model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300374/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300374/index.json"
        }
    ],
    "Genopo": [
        {
            "title": "Genopo: a nanopore sequencing analysis toolkit for portable Android devices",
            "venue": "Communications Biology",
            "year": "2020",
            "abstract": "The advent of portable nanopore sequencing devices has enabled DNA and RNA sequencing to be performed in the field or the clinic. However, advances in in situ genomics require parallel development of portable, offline solutions for the computational analysis of sequencing data. Here we introduce Genopo, a mobile toolkit for nanopore sequencing analysis. Genopo compacts popular bioinformatics tools to an Android application, enabling fully portable computation. To demonstrate its utility for in situ genome analysis, we use Genopo to determine the complete genome sequence of the human coronavirus SARS-CoV-2 in nine patient isolates sequenced on a nanopore device, with Genopo executing this workflow in less than 30\u00e2\u0080\u0089min per sample on a range of popular smartphones. We further show how Genopo can be used to profile DNA methylation in a human genome sample, illustrating a flexible, efficient architecture that is suitable to run many popular bioinformatics tools and accommodate small or large genomes. As the first ever smartphone application for nanopore sequencing analysis, Genopo enables the genomics community to harness this cheap, ubiquitous computational resource.",
            "authors": [
                "Hiruna Samarakoon",
                "Sanoj Punchihewa",
                "Anjana Senanayake",
                "Jillian M. Hammond",
                "Igor Stevanovski",
                "James M. Ferguson",
                "Roshan Ragel",
                "Hasindu Gamaarachchi",
                "Ira W. Deveson"
            ],
            "doi": "https://doi.org/10.1038/s42003-020-01270-z",
            "preprint": "#",
            "pdf": "https://www.nature.com/articles/s42003-020-01270-z.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering"
            ],
            "funding": "MRFF grant APP1173594 (to I.W.D.), Cancer Institute NSW Early Career Fellowship 2018/ECF013 (to I.W.D.) and philanthropic support from The Kinghorn Foundation (to I.W.D. and H.G.).",
            "tags": [
                "Genopo",
                "Nanopore Sequencing"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1038/s42003-020-01270-z/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1038/s42003-020-01270-z/index.json"
        }
    ],
    "Graphics processing units": [
        {
            "title": "To use or not to use: Graphics processing units (GPUs) for pattern matching algorithms",
            "venue": "7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "String matching is an important part in today's computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069585",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms/links/54e48fc30cf2dbf60696ea10/To-Use-or-Not-to-Use-Graphics-Processing-Units-for-Pattern-Matching-Algorithms.pdf",
            "pdf": "https://ieeexplore.ieee.org/abstract/document/7069585",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Graphics processing units",
                "Central Processing Unit",
                "Pattern matching",
                "Parallel processing",
                "Algorithm design and analysis",
                "Performance evaluation",
                "Software algorithms"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069585/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069585/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        }
    ],
    "Greenhouses": [
        {
            "title": "Affordable real-time environment monitoring system for greenhouses",
            "venue": "2016 Manufacturing & Industrial Engineering Symposium (MIES)",
            "year": "2016",
            "abstract": "Greenhouse has been the best alternative solution to get a better crop production compared to the traditional agricultural industry. Greenhouses are used to increase harvest by controlling key factors which will aect the planet growth. Real-time monitoring of the greenhouse environment and taking necessary control decisions will result in improvement of yields and economic performance. In this Research paper, we propose an environmental monitoring and controlling system that have the ability to collect the information related to greenhouse environment using various sensors. This system provides the ability to monitor and control the greenhouse remotely via a web interface and a mobile application. Using a low-cost wireless sensor network, environment data on greenhouse are sent to the centralized server. It will store all this data and show the latest environment details of the greenhouse using the web interface. The web interface will provide a real-time graphical display of data using charts and gauges and ability to send control decisions to the central node which is necessary to increase harvest and improve the quality of crops.",
            "authors": [
                "Supun Athukorala",
                "Irunika Weeraratne",
                "Dumindu Jayathilaka",
                "Asitha Bandaranayake",
                "Roshan Ragel"
            ],
            "doi": "https://doi.org/10.1109/MIES.2016.7780261",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Servers",
                "Greenhouses",
                "Sensor systems",
                "Relays",
                "Monitoring",
                "Sensor phenomena and characterization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MIES.2016.7780261/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MIES.2016.7780261/index.json"
        }
    ],
    "Hardware": [
        {
            "title": "Tile optimization for area in FPGA based hardware acceleration of peptide identification",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Advances in life sciences over the last few decades have lead to the generation of a huge amount of biological data. Computing research has become a vital part in driving biological discovery where analysis and categorization of biological data are involved. String matching algorithms can be applied for protein/gene sequence matching and with the phenomenal increase in the size of string databases to be analyzed, software implementations of these algorithms seems to have hit a hard limit and hardware acceleration is increasingly being sought. Several hardware platforms such as Field Programmable Gate Arrays (FPGA), Graphics Processing Units (GPU) and Chip Multi Processors (CMP) are being explored as hardware platforms. In this paper, we give a comprehensive overview of the literature on hardware acceleration of string matching algorithms, we take an FPGA hardware exploration and expedite the design time by a design automation technique. Further, our design automation is also optimized for better hardware utilization through optimizing the number of peptides that can be represented in an FPGA tile. The results indicate significant improvements in design time and hardware utilization which are reported in this paper.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "Roshan G Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038056",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7296.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Peptides",
                "Field programmable gate arrays",
                "Tiles",
                "Hardware",
                "Software algorithms",
                "Proteins",
                "Software"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038056/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038056/index.json"
        },
        {
            "title": "Statechart based modeling and controller implementation of complex reactive systems",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Statechart formalism has been a preferred choice for modeling complex reactive systems (CRS) in recent years. It has inbuilt powerful features of orthogonality, hierarchy, intermodular communication and history. Once statechart based system modeling is done the next issues to be addressed are (1) modular verification of the system for failsafe operation under all possible working conditions (2) progressive controller implementation together with the supervisory control while maintaining traceability and re-configurability and (3) facilitation of controller adaptation for progressive incorporation of security features and supervisory specifications. An elevator system was designed and built to reflect exigencies of a typical CRS hardware/software platform. A controller was designed to meet the above requirements and tested on the platform to validate the feasibility of model-based control design/verification methodology for real scale systems. Modularity was achieved by developing the statechart model of the plant into a tree of communicating language generators. Progresively verified modules were then translated into sequential function charts (SFC) which were finally integrated to form a complete flat SFC. The SFC was then implemented on a PLC platform (Telemechanique). The program was first validated in simulation using Telemechanique \u00e2\u0080\u009cTwidosuite\u00e2\u0080\u009d for different operating conditions and finally tested on the elevator system.",
            "authors": [
                "AC Vidanapathirana",
                "SD Dewasurendra",
                "SG Abeyratne"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038120",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Generators",
                "Software",
                "Automata",
                "Process control",
                "Floors",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038120/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038120/index.json"
        },
        {
            "title": "Hardware software co-design of the Aho-Corasick algorithm: Scalable for protein identification?",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Pattern matching is commonly required in many application areas and bioinformatics is a major area of interest that requires both exact and approximate pattern matching. Much work has been done in this area, yet there is still a significant space for improvement in efficiency, flexibility, and throughput. This paper presents a hardware software co-design of Aho-Corasick algorithm in Nios II soft-processor and a study on its scalability for a pattern matching application. A software only approach is used to compare the throughput and the scalability of the hardware software co-design approach. According to the results we obtained, we conclude that the hardware software co-design implementation shows a maximum of 10 times speed up for pattern size of 1200 peptides compared to the software only implementation. The results also show that the hardware software co-design approach scales well for increasing data size compared to the software only approach.",
            "authors": [
                "S.M. Vidanagamachchi",
                "S.D. Dewasurendra",
                "",
                "R.G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732003",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.1317.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Proteins",
                "Peptides",
                "Software algorithms",
                "Program processors",
                "Algorithm design and analysis"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732003/index.json"
        },
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        },
        {
            "title": "A structured hardware software architecture for peptide based diagnosis \u00e2\u0080\u0094 Sub-string matching problem with limited tolerance",
            "venue": "2014 7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "S. Devapriya Dewasurendra",
                "Roshan G. Ragel",
                "Mahesan Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069624",
            "preprint": "https://arxiv.org/pdf/1412.7811",
            "pdf": "https://arxiv.org/pdf/1412.7811",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Amino acids",
                "Software",
                "Automata",
                "Databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069624/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069624/index.json"
        },
        {
            "title": "A Novel FPGA Architecture of Commentz-Walter Algorithm using Bit-Split String-Matching Engines",
            "venue": "2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)",
            "year": "2021",
            "abstract": "This paper describes a reconfigurable hardware implementation of CommentzWalter algorithm with bit-split string matching engines to match multiple protein sequences. It is reported that multiple pattern matching using the most widely used Aho-Corasick algorithm for different applications has been carried out on graphics processing units and field programmable gate arrays to accelerate the matching process. Commentz-Walter algorithm, is a multiple pattern matching algorithm and more complex than Aho-Corasick. There are no reports of it being directly implemented in any hardware platform except as software implementations on general purpose processors. In this work, a specific architecture for our target application using CommentzWalter algorithm has been developed and tested with a simulator for hardware description languages. This architecture can match multiple patterns of proteins efficiently when implemented on a Field Programmable Gate Array. Finally, we compare a previously developed hardware architecture of bit-split Aho-Corasick with our bit-split Commentz-Walter architecture. Using the Intel Stratix IV GX EP4SGX230KF40C2 FPGA chip as the target device, the compilation results with Quartus II show that the synthesis logic utilization is 5% with 2203 total number of registers, 64896 FPGA block memory bits and 4 DSP block 18-bit elements. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the Commentz-Walter algorithm.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "Shirley D. Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICter53630.2021.9774805",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Software algorithms",
                "Computer architecture",
                "Logic gates",
                "Hardware",
                "Software",
                "Registers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICter53630.2021.9774805/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICter53630.2021.9774805/index.json"
        },
        {
            "title": "DIMSim: A rapid two-level cache simulation approach for deadline-based MPSoCs",
            "venue": "8th IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis",
            "year": "2012",
            "abstract": "It is of critical importance to satisfy deadline requirements for an embedded application to avoid undesired outcomes. Multiprocessor System-on-Chips (MPSoCs) play a vital role in contemporary embedded devices to satisfy timing deadlines. Such MPSoCs include two-level cache hierarchies which have to be dimensioned carefully to support timing deadlines of the application(s) while consuming minimum area and therefore minimum power. Given the deadline of an application, it is possible to systematically derive the maximum time that could be spent on memory accesses which can then be used to dimension the suitable cache sizes. As the dimensioning has to be done rapidly to satisfy the time to market requirement, we choose a well acclaimed rapid cache simulation strategy, the single-pass trace driven simulation, for estimating the cache dimensions. Therefore, for the first time, we address the two main challenges, coherency and scalability, in adapting a single-pass simulator to a MPSoC with two-level cache hierarchy. The challenges are addressed through a modular bottom-up simulation technique where L1 and L2 simulations are handled in independent communicating modules. In this paper, we present how the dimensioning is performed for a two-level inclusive data cache hierarchy in an MPSoC. With the rapid simulation proposed, the estimations are suggested within an hour (worst case on considered application benchmarks). We experimented our approach with task based MPSoC implementations of JPEG and H264 benchmarks and achieved timing deviations of 16.1% and 7.2% respectively on average against the requested data access times. The deviation numbers are always positive meaning our simulator guarantees to satisfy the requested data access time. In addition, we generated a set of synthetic memory traces and used them to extensively analyse our simulator. For the synthetic traces, our simulator provides cache sizes to always guarantee the requested data access time, deviating below 14.5% on average.",
            "authors": [
                "Mohammad Shihabul Haque",
                "Roshan Ragel",
                "Angelo Ambrose",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1145/2380445.2380473",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Hardware validation"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2380445.2380473/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2380445.2380473/index.json"
        },
        {
            "title": "A Study on Instruction-set Selection Using Multi-application Based Application Specific Instruction-set Processors",
            "venue": "2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems",
            "year": "2013",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analyzing the instructions for inter-domain and intra-domain designs. Metrics analyzed are the reusable instructions and the extra cost to add a certain application, together with the hardware synthesis numbers, such as area, timing and delay. A wide range of applications from various application benchmarks (BioPerf, CommBench, MediaBench, MiBench and SPEC2006) and domains are analyzed for three different architectures (LEON2, PISA and ARM-Thumb). Processors are generated for these architectures for different configurations to analyze and synthesize. Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless the kind of architecture (and therefore the ISA).",
            "authors": [
                "Roshan G. Ragel",
                "Swarnalatha Radhakrishnan",
                "Jude Angelo Ambrose",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/VLSID.2013.154",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/261501995_A_Study_on_Instruction-set_Selection_Using_Multi-application_Based_Application_Specific_Instruction-set_Processors/links/54e48faf0cf2dbf60696e9b4/A-Study-on-Instruction-set-Selection-Using-Multi-application-Based-Application-Specific-Instruction-set-Processors.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Thumb",
                "Embedded systems",
                "Benchmark testing",
                "Standards",
                "Instruction sets"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/VLSID.2013.154/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/VLSID.2013.154/index.json"
        },
        {
            "title": "DRMA: dynamically reconfigurable MPSoC architecture",
            "venue": "GLSVLSI '13: Proceedings of the 23rd ACM international conference on Great lakes symposium on VLSI",
            "year": "2013",
            "abstract": "Embedded systems are ubiquitous and are deployed in a large range of applications. Designing and fabricating Integrated Circuits (ICs) targeting such different range of applications is expensive. Designers seek flexible processors which efficiently execute a multitude of applications. FPGAs are considered affordable, but design cost, high reconfiguration delay and power consumption are all prohibitive. In this paper, we propose a novel ASIC based flexible MPSoC architecture, which can execute separate tasks in parallel, and it can be configured to execute single task with wide data widths or execute multiple tasks with varying data widths. The architecture presented, called Dynamically Reconfigurable MPSoC Architecture (DRMA), can be rapidly reconfigured through instructions. We present applications as case studies to showcase the flexibility and efficacy of DRMA. Results show for an additional area overhead of about 5%, the system is capable of working as four 32-bit processors, a single 128 bit processor or as a pipelined processing system.",
            "authors": [
                "Lawrance Zhang",
                "Jude Angelo Ambrose",
                "Jorgen Peddersen",
                "Sri Parameswaran",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Kewal K. Saluja"
            ],
            "doi": "https://doi.org/10.1145/2483028.2483101",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Computer systems organization",
                "Architectures",
                "Serial architectures",
                "Pipeline computing",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2483028.2483101/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2483028.2483101/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Visual Design Platform for Wireless Sensor Network",
            "venue": "2018 Moratuwa Engineering Research Conference (MERCon)",
            "year": "2018",
            "abstract": "Wireless Sensor Networks (WSN) are being widely used for sensing physical parameters in a broad geographical area. The person who needs WSN will have a pictorial idea of the sensor network. The problem in the traditional method is that the person who needs the WSN should explain the pictorial view of the sensor network to a commercial vendor and buy it from them or they should design it from the scratch. What we proposed in our solution is to develop a platform so that the person who needs the WSN can directly draw the pictorial view on a canvas and then it can automatically generate all the required firmware for the microcontrollers and wiring diagrams. The user is then required only to follow a few instructions to complete the real world implementation of WSNs. This paper is about developing a visual platform to design WSNs. The WSN designing platform was built as a web application, so it can manage a large number of supported sensors and microcontrollers. This means that if one user adds the device driver for any sensor or a microcontroller the other users can directly use it from the WSN design platform without worrying about hardware programming. Further, if anyone needs a new sensor or microcontroller to be supported by this visual design platform, this design tool will have interfaces to directly add new sensors and microcontrollers. The proposed method is affordable for developing custom wireless sensor networks.",
            "authors": [
                "Rosen Silva",
                "Asela Dasanayaka",
                "Roshan Ragel",
                "Asitha Bandaranayake"
            ],
            "doi": "https://doi.org/10.1109/MERCon.2018.8421896",
            "preprint": "https://www.researchgate.net/profile/Asitha-Bandaranayake-3/publication/327517623_Visual_Design_Platform_for_Wireless_Sensor_Network/links/5f98da03458515b7cfa4013c/Visual-Design-Platform-for-Wireless-Sensor-Network.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Wireless sensor networks",
                "Microcontrollers",
                "Databases",
                "Skeleton",
                "Visualization",
                "Hardware",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon.2018.8421896/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon.2018.8421896/index.json"
        },
        {
            "title": "Using microkernel based virtualization for Byzantine fault tolerance",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "A Byzantine fault is a failure that cannot be identified by observing the output of a component; the component produces a wrong result as opposed to not producing a result at all or producing a result that can be identified as wrong. Such faults may be caused by a number of causes including software bugs and malicious attacks. Tolerating such faults is essential for a critical system. Isolated replication and majority voting is a well established technique to tolerate Byzantine faults. Current implementations of such systems either uses replicated hardware or software virtualization-using virtual machine monitors-to get the illusion of hardware replication to tolerate Byzantine faults. In this paper, we investigate the possibility of using microkernel technology to achieve the isolated replication and discuss the features of a microkernel API suitable for such a deployment. The advantage of our approach is that it reduces the cost of additional hardware or avoid the complexity of virtualization required to mimic hardware replication. We used a single machine, running the L4 microkernel to provide the isolation required for the replicas. All replicas run in parallel and majority voting is performed to obtain the correct result in the presence of Byzantine faults. We selected the AES encryption algorithms for our case study and faults were deliberately injected to replicas to mimic Byzantine behavior. Our experiments show that it is feasible to use microkernels technology for this purpose.",
            "authors": [
                "Asanka Senevirathna",
                "Bhathiya Wasala",
                "Buddhika Ranaweera",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038037",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Kernel",
                "Computer bugs",
                "Information systems",
                "USA Councils",
                "Fault tolerant systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038037/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038037/index.json"
        },
        {
            "title": "Constant time encryption as a countermeasure against remote cache timing attacks",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Rijndael was standardized in 2001 by National Institute of Standard and Technology as the Advanced Encryption Standard (AES). AES is still being used to encrypt financial, military and even government confidential data. In 2005, Bernstein illustrated a remote cache timing attack on AES using the client-server architecture and therefore proved a side channel in its software implementation. Over the years, a number of countermeasures have been proposed against cache timing attacks both using hardware and software. Although the software based countermeasures are flexible and easy to deploy, most of such countermeasures are vulnerable to statistical analysis. In this paper, we propose a novel software based countermeasure against cache timing attacks, known as constant time encryption, which we believe is secure against statistical analysis. The countermeasure we proposed performs rescheduling of instructions such that the encryption rounds will consume constant time independent of the cache hits and misses. Through experiments, we prove that our countermeasure is secure against Bernstein's cache timing attack.",
            "authors": [
                "Darshana Jayasinghe",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419893",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7293.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Encryption",
                "Timing",
                "Software",
                "Hardware",
                "Clocks",
                "Computers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419893/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419893/index.json"
        }
    ],
    "Hardware validation": [
        {
            "title": "DIMSim: A rapid two-level cache simulation approach for deadline-based MPSoCs",
            "venue": "8th IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis",
            "year": "2012",
            "abstract": "It is of critical importance to satisfy deadline requirements for an embedded application to avoid undesired outcomes. Multiprocessor System-on-Chips (MPSoCs) play a vital role in contemporary embedded devices to satisfy timing deadlines. Such MPSoCs include two-level cache hierarchies which have to be dimensioned carefully to support timing deadlines of the application(s) while consuming minimum area and therefore minimum power. Given the deadline of an application, it is possible to systematically derive the maximum time that could be spent on memory accesses which can then be used to dimension the suitable cache sizes. As the dimensioning has to be done rapidly to satisfy the time to market requirement, we choose a well acclaimed rapid cache simulation strategy, the single-pass trace driven simulation, for estimating the cache dimensions. Therefore, for the first time, we address the two main challenges, coherency and scalability, in adapting a single-pass simulator to a MPSoC with two-level cache hierarchy. The challenges are addressed through a modular bottom-up simulation technique where L1 and L2 simulations are handled in independent communicating modules. In this paper, we present how the dimensioning is performed for a two-level inclusive data cache hierarchy in an MPSoC. With the rapid simulation proposed, the estimations are suggested within an hour (worst case on considered application benchmarks). We experimented our approach with task based MPSoC implementations of JPEG and H264 benchmarks and achieved timing deviations of 16.1% and 7.2% respectively on average against the requested data access times. The deviation numbers are always positive meaning our simulator guarantees to satisfy the requested data access time. In addition, we generated a set of synthetic memory traces and used them to extensively analyse our simulator. For the synthetic traces, our simulator provides cache sizes to always guarantee the requested data access time, deviating below 14.5% on average.",
            "authors": [
                "Mohammad Shihabul Haque",
                "Roshan Ragel",
                "Angelo Ambrose",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1145/2380445.2380473",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Hardware validation"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2380445.2380473/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2380445.2380473/index.json"
        }
    ],
    "Human-centered computing": [
        {
            "title": "DeepLight: Robust & Unobtrusive Real-time Screen-Camera Communication for Real-World Displays",
            "venue": "2021 20th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)",
            "year": "2021",
            "abstract": "The paper introduces a novel, holistic approach for robust Screen-Camera Communication (SCC), where video content on a screen is visually encoded in a human-imperceptible fashion and decoded by a camera capturing images of such screen content. We first show that state-of-the-art SCC techniques have two key limitations for in-the-wild deployment: (a) the decoding accuracy drops rapidly under even modest screen extraction errors from the captured images, and (b) they generate perceptible flickers on common refresh rate screens even with minimal modulation of pixel intensity. To overcome these challenges, we introduce DeepLight, a system that incorporates machine learning (ML) models in the decoding pipeline to achieve humanly-imperceptible, moderately high SCC rates under diverse real-world conditions. DeepLight's key innovation is the design of a Deep Neural Network (DNN) based decoder that collectively decodes all the bits spatially encoded in a display frame, without attempting to precisely isolate the pixels associated with each encoded bit. In addition, DeepLight supports imperceptible encoding by selectively modulating the intensity of only the Blue channel, and provides reasonably accurate screen extraction (IoU values \u00e2\u0089\u00a5 83%) by using state-of-the-art object detection DNN pipelines. We show that a fully functional DeepLight system is able to robustly achieve high decoding accuracy (frame error rate < 0.2) and moderately-high data goodput (\u00e2\u0089\u00a50.95 Kbps) using a human-held smartphone camera, even over larger screen-camera distances (~ 2m).",
            "authors": [
                "Vu Tran",
                "Gihan Jayatilaka",
                "Ashwin Ashok",
                "Archan Misra"
            ],
            "doi": "https://doi.org/10.1145/3412382.3458269",
            "preprint": "https://arxiv.org/pdf/2105.05092",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/deeplight/presentation.pdf",
            "project": "#",
            "codebase": "https://github.com/gihanjayatilaka/deeplight",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Human-centered computing",
                "Ubiquitous and mobile computing",
                "Computer systems organization",
                "Embedded and cyber-physical systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/3412382.3458269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/3412382.3458269/index.json"
        }
    ],
    "Hypertension": [
        {
            "title": "Chronic kidney disease prediction using machine learning methods",
            "venue": "2020 Moratuwa Engineering Research Conference (MERCon) - IEEE",
            "year": "2020",
            "abstract": "Chronic Kidney Disease (CKD) or chronic renal disease has become a major issue with a steady growth rate. A person can only survive without kidneys for an average time of 18 days, which makes a huge demand for a kidney transplant and Dialysis. It is important to have effective methods for early prediction of CKD. Machine learning methods are effective in CKD prediction. This work proposes a workflow to predict CKD status based on clinical data, incorporating data prepossessing, a missing value handling method with collaborative filtering and attributes selection. Out of the 11 machine learning methods considered, the extra tree classifier and random forest classifier are shown to result in the highest accuracy and minimal bias to the attributes. The research also considers the practical aspects of data collection and highlights the importance of incorporating domain knowledge when using machine learning for CKD status prediction.",
            "authors": [
                "Imesh Udara Ekanayake; Damayanthi Herath"
            ],
            "doi": " https://doi.org/10.1109/MERCon50084.2020.9185249",
            "preprint": "#",
            "pdf": "https://www.researchgate.net/profile/Imesh-Ekanayake/publication/344319206_Chronic_Kidney_Disease_Prediction_Using_Machine_Learning_Methods/links/5f672571458515b7cf418d5b/Chronic-Kidney-Disease-Prediction-Using-Machine-Learning-Methods.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Machine Learning and Data Mining"
            ],
            "funding": "",
            "tags": [
                "Kidney",
                "Diseases",
                "Machine learning",
                "Red blood cells",
                "Hypertension"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/ 10.1109/MERCon50084.2020.9185249/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/ 10.1109/MERCon50084.2020.9185249/index.json"
        }
    ],
    "Image analysis": [
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Image decomposition": [
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        }
    ],
    "Induction motors": [
        {
            "title": "Model in the loop testing of complex reactive systems",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Currently there is a new trend in the design of Complex Reactive Systems (CRS) towards model based development. Software components are no longer hard written in C or Assembler code but modeled with MATLAB/Simulink, Statemate or similar tools. Model based designs allow development of high level models that can be used for simulations in very early stages of the design process. However the quality assurance of model based developments, specially testing is still poorly supported [1]. In this paper we discuss the characteristics of model based design process and the need of quality assurance methods throughout the design process. We have selected a fully functional prototype passenger elevator as the CRS. A model based design approach is followed throughout the design phase. Model-in-the loop (MiL) testing is carried out as the quality assurance technique and the results are presented. Then the translation of the MiL test into a Hardware-in the-loop (HiL) test is presented.",
            "authors": [
                "A. Vidanapathirana",
                "S. D. Dewasurendra",
                "S. G. Abeyaratne"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6731950",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mathematical model",
                "Induction motors",
                "Testing",
                "MATLAB",
                "Elevators",
                "Floors"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6731950/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6731950/index.json"
        }
    ],
    "Information security": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Information systems": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        },
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        },
        {
            "title": "Using microkernel based virtualization for Byzantine fault tolerance",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "A Byzantine fault is a failure that cannot be identified by observing the output of a component; the component produces a wrong result as opposed to not producing a result at all or producing a result that can be identified as wrong. Such faults may be caused by a number of causes including software bugs and malicious attacks. Tolerating such faults is essential for a critical system. Isolated replication and majority voting is a well established technique to tolerate Byzantine faults. Current implementations of such systems either uses replicated hardware or software virtualization-using virtual machine monitors-to get the illusion of hardware replication to tolerate Byzantine faults. In this paper, we investigate the possibility of using microkernel technology to achieve the isolated replication and discuss the features of a microkernel API suitable for such a deployment. The advantage of our approach is that it reduces the cost of additional hardware or avoid the complexity of virtualization required to mimic hardware replication. We used a single machine, running the L4 microkernel to provide the isolation required for the replicas. All replicas run in parallel and majority voting is performed to obtain the correct result in the presence of Byzantine faults. We selected the AES encryption algorithms for our case study and faults were deliberately injected to replicas to mimic Byzantine behavior. Our experiments show that it is feasible to use microkernels technology for this purpose.",
            "authors": [
                "Asanka Senevirathna",
                "Bhathiya Wasala",
                "Buddhika Ranaweera",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038037",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Kernel",
                "Computer bugs",
                "Information systems",
                "USA Councils",
                "Fault tolerant systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038037/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038037/index.json"
        }
    ],
    "Information technology": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Instruction sets": [
        {
            "title": "A Study on Instruction-set Selection Using Multi-application Based Application Specific Instruction-set Processors",
            "venue": "2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems",
            "year": "2013",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analyzing the instructions for inter-domain and intra-domain designs. Metrics analyzed are the reusable instructions and the extra cost to add a certain application, together with the hardware synthesis numbers, such as area, timing and delay. A wide range of applications from various application benchmarks (BioPerf, CommBench, MediaBench, MiBench and SPEC2006) and domains are analyzed for three different architectures (LEON2, PISA and ARM-Thumb). Processors are generated for these architectures for different configurations to analyze and synthesize. Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless the kind of architecture (and therefore the ISA).",
            "authors": [
                "Roshan G. Ragel",
                "Swarnalatha Radhakrishnan",
                "Jude Angelo Ambrose",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/VLSID.2013.154",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/261501995_A_Study_on_Instruction-set_Selection_Using_Multi-application_Based_Application_Specific_Instruction-set_Processors/links/54e48faf0cf2dbf60696e9b4/A-Study-on-Instruction-set-Selection-Using-Multi-application-Based-Application-Specific-Instruction-set-Processors.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Thumb",
                "Embedded systems",
                "Benchmark testing",
                "Standards",
                "Instruction sets"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/VLSID.2013.154/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/VLSID.2013.154/index.json"
        }
    ],
    "Integrated circuit modeling": [
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        }
    ],
    "Integrated circuits": [
        {
            "title": "Instruction-set selection for multi-application based ASIP design: An instruction-level study",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analysing the instructions for inter-domain and intra-domain designs. Metrics analysed are the reusable instructions and the extra cost to add a certain application. A wide range of applications from various application benchmarks (MiBench, MediaBench and SPEC2006) and domains are analysed for two different architectures (ARM-Thumb and PISA). Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless of the architecture (and therefore the ISA).",
            "authors": [
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Angelo Ambrose"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419895",
            "preprint": "https://arxiv.org/pdf/1403.7291.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "GSM",
                "Engines",
                "Integrated circuits",
                "Transform coding"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419895/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419895/index.json"
        },
        {
            "title": "CSER: HW/SW configurable soft-error resiliency for application specific instruction-set processors",
            "venue": "2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)",
            "year": "2013",
            "abstract": "Soft error has been identified as one of the major challenges to CMOS technology based computing systems. To mitigate this problem, error recovery is a key component, which usually accounts for a substantial cost, since they must introduce redundancies in either time or space. Consequently, using state-of-art recovery techniques could heavily worsen the design constraint, which is fairly stringent for embedded system design. In this paper, we propose a HW/SW methodology that generates the processor, which performs finely configured error recovery functionality targeting the given design constraints (e.g., performance, area and power). Our methodology employs three application-specific optimization heuristics, which generate the optimized composition and configuration based on the two primitive error recovery techniques. The resultant processor is composed of selected primitive techniques at corresponding instruction execution, and configured to perform error recovery at run-time accordingly to the scheme determined at design time. The experiment results have shown that our methodology can at best achieve nine times reliability while maintaining the given constraints, in comparison to the state of the art.",
            "authors": [
                "Tuo Li",
                "Muhammad Shafique",
                "Semeen Rehman",
                "Swarnalatha Radhakrishnan",
                "Roshan Ragel",
                "Jude Angelo Ambrose",
                "J\u00c3\u00b6rg Henkel",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.7873/DATE.2013.152",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Redundancy",
                "Time factors",
                "Runtime",
                "Integrated circuits",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7873/DATE.2013.152/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7873/DATE.2013.152/index.json"
        }
    ],
    "Internet": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        }
    ],
    "Intrusion detection": [
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        }
    ],
    "Java": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Kernel": [
        {
            "title": "Using microkernel based virtualization for Byzantine fault tolerance",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "A Byzantine fault is a failure that cannot be identified by observing the output of a component; the component produces a wrong result as opposed to not producing a result at all or producing a result that can be identified as wrong. Such faults may be caused by a number of causes including software bugs and malicious attacks. Tolerating such faults is essential for a critical system. Isolated replication and majority voting is a well established technique to tolerate Byzantine faults. Current implementations of such systems either uses replicated hardware or software virtualization-using virtual machine monitors-to get the illusion of hardware replication to tolerate Byzantine faults. In this paper, we investigate the possibility of using microkernel technology to achieve the isolated replication and discuss the features of a microkernel API suitable for such a deployment. The advantage of our approach is that it reduces the cost of additional hardware or avoid the complexity of virtualization required to mimic hardware replication. We used a single machine, running the L4 microkernel to provide the isolation required for the replicas. All replicas run in parallel and majority voting is performed to obtain the correct result in the presence of Byzantine faults. We selected the AES encryption algorithms for our case study and faults were deliberately injected to replicas to mimic Byzantine behavior. Our experiments show that it is feasible to use microkernels technology for this purpose.",
            "authors": [
                "Asanka Senevirathna",
                "Bhathiya Wasala",
                "Buddhika Ranaweera",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038037",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Kernel",
                "Computer bugs",
                "Information systems",
                "USA Councils",
                "Fault tolerant systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038037/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038037/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "To use or not to use: CPUs' cache optimization techniques on GPGPUs",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU's best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946534",
            "preprint": "https://arxiv.org/pdf/1810.04063",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Arrays",
                "Optimization",
                "Merging",
                "Cache memory",
                "Testing",
                "Kernel",
                "Throughput"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946534/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946534/index.json"
        }
    ],
    "Kidney": [
        {
            "title": "Chronic kidney disease prediction using machine learning methods",
            "venue": "2020 Moratuwa Engineering Research Conference (MERCon) - IEEE",
            "year": "2020",
            "abstract": "Chronic Kidney Disease (CKD) or chronic renal disease has become a major issue with a steady growth rate. A person can only survive without kidneys for an average time of 18 days, which makes a huge demand for a kidney transplant and Dialysis. It is important to have effective methods for early prediction of CKD. Machine learning methods are effective in CKD prediction. This work proposes a workflow to predict CKD status based on clinical data, incorporating data prepossessing, a missing value handling method with collaborative filtering and attributes selection. Out of the 11 machine learning methods considered, the extra tree classifier and random forest classifier are shown to result in the highest accuracy and minimal bias to the attributes. The research also considers the practical aspects of data collection and highlights the importance of incorporating domain knowledge when using machine learning for CKD status prediction.",
            "authors": [
                "Imesh Udara Ekanayake; Damayanthi Herath"
            ],
            "doi": " https://doi.org/10.1109/MERCon50084.2020.9185249",
            "preprint": "#",
            "pdf": "https://www.researchgate.net/profile/Imesh-Ekanayake/publication/344319206_Chronic_Kidney_Disease_Prediction_Using_Machine_Learning_Methods/links/5f672571458515b7cf418d5b/Chronic-Kidney-Disease-Prediction-Using-Machine-Learning-Methods.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Machine Learning and Data Mining"
            ],
            "funding": "",
            "tags": [
                "Kidney",
                "Diseases",
                "Machine learning",
                "Red blood cells",
                "Hypertension"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/ 10.1109/MERCon50084.2020.9185249/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/ 10.1109/MERCon50084.2020.9185249/index.json"
        }
    ],
    "Linux": [
        {
            "title": "Offloading specific performance-related kernel functions into an FPGA",
            "venue": "2021 IEEE 30th International Symposium on Industrial Electronics (ISIE)",
            "year": "2021",
            "abstract": "Today's network transactions are usually handled using kernel-based network protocols residing on general-purpose processors (GPPs). Over time, network transmission speeds have developed rapidly without a corresponding increase in processing speeds of host processors. With devices featuring advanced connectivity and Internet functionality, protocol processing has created a heavy workload on the GPP and has become a limiting factor in high performance networking applications such as online High Frequency Trading Systems (HFTS). It encourages designers to increase processor performance or designing application specific processors for handling heavy network workloads. Then there is the choice of hardware/software implementations based on results from hardware acceleration. Offloading the whole network protocol stack implementation into hardware is not very attractive since handling large linked data structures inside the hardware is not as easy as in software. In this paper we claim that relieving the CPU from bulk processing by offloading selected, performance-related kernel code into hardware is a better option for such scenarios. Hence, we design a scalable system for offloading specific performance-related kernel functions into an FPGA. In this paper we discuss the logic behind our new architecture and the results up to now.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S. Devapriya Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ISIE45552.2021.9576256",
            "preprint": "https://www.academia.edu/download/75534730/KF_003255_ISIE2021paper.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Performance evaluation",
                "Protocols",
                "Profitability",
                "Linux",
                "Computer architecture",
                "Software",
                "Security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ISIE45552.2021.9576256/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ISIE45552.2021.9576256/index.json"
        }
    ],
    "Logic gates": [
        {
            "title": "A Novel FPGA Architecture of Commentz-Walter Algorithm using Bit-Split String-Matching Engines",
            "venue": "2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)",
            "year": "2021",
            "abstract": "This paper describes a reconfigurable hardware implementation of CommentzWalter algorithm with bit-split string matching engines to match multiple protein sequences. It is reported that multiple pattern matching using the most widely used Aho-Corasick algorithm for different applications has been carried out on graphics processing units and field programmable gate arrays to accelerate the matching process. Commentz-Walter algorithm, is a multiple pattern matching algorithm and more complex than Aho-Corasick. There are no reports of it being directly implemented in any hardware platform except as software implementations on general purpose processors. In this work, a specific architecture for our target application using CommentzWalter algorithm has been developed and tested with a simulator for hardware description languages. This architecture can match multiple patterns of proteins efficiently when implemented on a Field Programmable Gate Array. Finally, we compare a previously developed hardware architecture of bit-split Aho-Corasick with our bit-split Commentz-Walter architecture. Using the Intel Stratix IV GX EP4SGX230KF40C2 FPGA chip as the target device, the compilation results with Quartus II show that the synthesis logic utilization is 5% with 2203 total number of registers, 64896 FPGA block memory bits and 4 DSP block 18-bit elements. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the Commentz-Walter algorithm.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "Shirley D. Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICter53630.2021.9774805",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Software algorithms",
                "Computer architecture",
                "Logic gates",
                "Hardware",
                "Software",
                "Registers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICter53630.2021.9774805/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICter53630.2021.9774805/index.json"
        }
    ],
    "Low-light image enhancement": [
        {
            "title": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for Enhancing Low Light Images",
            "venue": "MERcon",
            "year": "2020",
            "abstract": "Low light image enhancement is an important challenge for the development of robust computer vision algorithms. The machine learning approaches to this have been either unsupervised, supervised based on paired dataset or supervised based on unpaired dataset. This paper presents a novel deep learning pipeline that can learn from both paired and unpaired datasets. Convolution Neural Networks (CNNs) that are optimized to minimize standard loss, and Generative Adversarial Networks (GANs) that are optimized to minimize the adversarial loss are used to achieve different steps of the low light image enhancement process. Cycle consistency loss and a patched discriminator are utilized to further improve the performance. The paper also analyses the functionality and the performance of different components, hidden layers, and the entire pipeline.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Roshan Goldaliyadda",
                "Parakrama Ekanayeka",
                "Roshan Ragel",
                "Vijitha Herath"
            ],
            "doi": "https://doi.org/10.1109/MERCon50084.2020.9185373",
            "preprint": "https://arxiv.org/pdf/2006.15304.pdf",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/mercon-2020-presentation.pdf",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Low-light image enhancement",
                "Retinex theory",
                "Generative adversarial networks",
                "Cycle consistency",
                "Computer Vision"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon50084.2020.9185373/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon50084.2020.9185373/index.json"
        }
    ],
    "MATLAB": [
        {
            "title": "Model in the loop testing of complex reactive systems",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Currently there is a new trend in the design of Complex Reactive Systems (CRS) towards model based development. Software components are no longer hard written in C or Assembler code but modeled with MATLAB/Simulink, Statemate or similar tools. Model based designs allow development of high level models that can be used for simulations in very early stages of the design process. However the quality assurance of model based developments, specially testing is still poorly supported [1]. In this paper we discuss the characteristics of model based design process and the need of quality assurance methods throughout the design process. We have selected a fully functional prototype passenger elevator as the CRS. A model based design approach is followed throughout the design phase. Model-in-the loop (MiL) testing is carried out as the quality assurance technique and the results are presented. Then the translation of the MiL test into a Hardware-in the-loop (HiL) test is presented.",
            "authors": [
                "A. Vidanapathirana",
                "S. D. Dewasurendra",
                "S. G. Abeyaratne"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6731950",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mathematical model",
                "Induction motors",
                "Testing",
                "MATLAB",
                "Elevators",
                "Floors"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6731950/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6731950/index.json"
        }
    ],
    "Machine learning": [
        {
            "title": "Chronic kidney disease prediction using machine learning methods",
            "venue": "2020 Moratuwa Engineering Research Conference (MERCon) - IEEE",
            "year": "2020",
            "abstract": "Chronic Kidney Disease (CKD) or chronic renal disease has become a major issue with a steady growth rate. A person can only survive without kidneys for an average time of 18 days, which makes a huge demand for a kidney transplant and Dialysis. It is important to have effective methods for early prediction of CKD. Machine learning methods are effective in CKD prediction. This work proposes a workflow to predict CKD status based on clinical data, incorporating data prepossessing, a missing value handling method with collaborative filtering and attributes selection. Out of the 11 machine learning methods considered, the extra tree classifier and random forest classifier are shown to result in the highest accuracy and minimal bias to the attributes. The research also considers the practical aspects of data collection and highlights the importance of incorporating domain knowledge when using machine learning for CKD status prediction.",
            "authors": [
                "Imesh Udara Ekanayake; Damayanthi Herath"
            ],
            "doi": " https://doi.org/10.1109/MERCon50084.2020.9185249",
            "preprint": "#",
            "pdf": "https://www.researchgate.net/profile/Imesh-Ekanayake/publication/344319206_Chronic_Kidney_Disease_Prediction_Using_Machine_Learning_Methods/links/5f672571458515b7cf418d5b/Chronic-Kidney-Disease-Prediction-Using-Machine-Learning-Methods.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Machine Learning and Data Mining"
            ],
            "funding": "",
            "tags": [
                "Kidney",
                "Diseases",
                "Machine learning",
                "Red blood cells",
                "Hypertension"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/ 10.1109/MERCon50084.2020.9185249/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/ 10.1109/MERCon50084.2020.9185249/index.json"
        },
        {
            "title": "Data Mining System for Predicting a Winning Cricket Team",
            "venue": "2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2021",
            "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u00e2\u0080\u0099 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
            "authors": [
                "Dinithi Hasanika",
                "Roshani Dilhara",
                "Dulanjali Liyanage",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Uncertainty",
                "Statistical analysis",
                "Conferences",
                "Games",
                "Machine learning",
                "Data mining",
                "Australia"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS53135.2021.9660702/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS53135.2021.9660702/index.json"
        }
    ],
    "Maintenance engineering": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Mathematical model": [
        {
            "title": "Design and implementation of a statechart based reconfigurable elevator controller",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "This paper presents a simple and clear method to design and implement a reconfigurable elevator controller using an FPGA, which can be implemented for an elevator with any (N) number of floors, with specified inputs and outputs. A model based design approach was followed. We started from a state chart model developed for a prototype elevator with three floors. Extension of the model for a variable number of floors was considered. Controller for the prototype system was implemented in ladder logic on a PLC and the limitations of that approach with regard to re-configurability were identified: viz., in the extension of elevator controller for `N' no of floors. Next VHDL code was developed for a reconfigurable elevator controller where, by changing a variable corresponding to the required number of floors, the suitable code can be generated. The controller thus generated can be implemented in an FPGA. The method was successfully tested on a Xilinx Spartan 3AN FPGA.",
            "authors": [
                "HPAP Jayawardana",
                "HWKM Amarasekara",
                "PTS Peelikumbura",
                "WAKC Jayathilaka",
                "SG Abeyaratne",
                "SD Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038093",
            "preprint": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "pdf": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Floors",
                "Field programmable gate arrays",
                "Prototypes",
                "Sensors",
                "Mathematical model",
                "Control systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038093/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038093/index.json"
        },
        {
            "title": "Model in the loop testing of complex reactive systems",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Currently there is a new trend in the design of Complex Reactive Systems (CRS) towards model based development. Software components are no longer hard written in C or Assembler code but modeled with MATLAB/Simulink, Statemate or similar tools. Model based designs allow development of high level models that can be used for simulations in very early stages of the design process. However the quality assurance of model based developments, specially testing is still poorly supported [1]. In this paper we discuss the characteristics of model based design process and the need of quality assurance methods throughout the design process. We have selected a fully functional prototype passenger elevator as the CRS. A model based design approach is followed throughout the design phase. Model-in-the loop (MiL) testing is carried out as the quality assurance technique and the results are presented. Then the translation of the MiL test into a Hardware-in the-loop (HiL) test is presented.",
            "authors": [
                "A. Vidanapathirana",
                "S. D. Dewasurendra",
                "S. G. Abeyaratne"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6731950",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mathematical model",
                "Induction motors",
                "Testing",
                "MATLAB",
                "Elevators",
                "Floors"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6731950/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6731950/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
            "authors": [
                "AH Wijethunge",
                "JV Wijekulasooriya",
                "Janaka B Ekanayake",
                "KB Samarakoon",
                "A Polpitiya"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300374",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Schedules",
                "Genetic algorithms",
                "Optimization",
                "Wind power generation",
                "Power demand",
                "Wind turbines",
                "Mathematical model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300374/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300374/index.json"
        }
    ],
    "Measurement": [
        {
            "title": " Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
            "authors": [
                "Pranavan Somaskandhan",
                "Gihan Wijesinghe",
                "Leshan Bashitha Wijegunawardana",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300399",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Sports equipment",
                "Data mining",
                "Measurement",
                "Support vector machines",
                "Statistical analysis",
                "Games",
                "Relational databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300399/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300399/index.json"
        }
    ],
    "Merging": [
        {
            "title": "To use or not to use: CPUs' cache optimization techniques on GPGPUs",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU's best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946534",
            "preprint": "https://arxiv.org/pdf/1810.04063",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Arrays",
                "Optimization",
                "Merging",
                "Cache memory",
                "Testing",
                "Kernel",
                "Throughput"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946534/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946534/index.json"
        }
    ],
    "Methylation": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Microcontrollers": [
        {
            "title": "Visual Design Platform for Wireless Sensor Network",
            "venue": "2018 Moratuwa Engineering Research Conference (MERCon)",
            "year": "2018",
            "abstract": "Wireless Sensor Networks (WSN) are being widely used for sensing physical parameters in a broad geographical area. The person who needs WSN will have a pictorial idea of the sensor network. The problem in the traditional method is that the person who needs the WSN should explain the pictorial view of the sensor network to a commercial vendor and buy it from them or they should design it from the scratch. What we proposed in our solution is to develop a platform so that the person who needs the WSN can directly draw the pictorial view on a canvas and then it can automatically generate all the required firmware for the microcontrollers and wiring diagrams. The user is then required only to follow a few instructions to complete the real world implementation of WSNs. This paper is about developing a visual platform to design WSNs. The WSN designing platform was built as a web application, so it can manage a large number of supported sensors and microcontrollers. This means that if one user adds the device driver for any sensor or a microcontroller the other users can directly use it from the WSN design platform without worrying about hardware programming. Further, if anyone needs a new sensor or microcontroller to be supported by this visual design platform, this design tool will have interfaces to directly add new sensors and microcontrollers. The proposed method is affordable for developing custom wireless sensor networks.",
            "authors": [
                "Rosen Silva",
                "Asela Dasanayaka",
                "Roshan Ragel",
                "Asitha Bandaranayake"
            ],
            "doi": "https://doi.org/10.1109/MERCon.2018.8421896",
            "preprint": "https://www.researchgate.net/profile/Asitha-Bandaranayake-3/publication/327517623_Visual_Design_Platform_for_Wireless_Sensor_Network/links/5f98da03458515b7cfa4013c/Visual-Design-Platform-for-Wireless-Sensor-Network.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Wireless sensor networks",
                "Microcontrollers",
                "Databases",
                "Skeleton",
                "Visualization",
                "Hardware",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon.2018.8421896/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon.2018.8421896/index.json"
        }
    ],
    "Mobile communication": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        }
    ],
    "Mobile learning": [
        {
            "title": "Support of Mobile Phones in a Private Network for Science Teaching",
            "venue": "International Journal of Interactive Mobile Technologies",
            "year": "2016",
            "abstract": "The potential of mobile phones to facilitate students\u00e2\u0080\u0099 science learning, when they are engaging in group activities, was investigated. To minimize the disciplinary issues emerged from the previous research on mobile devices and to enhance the quality of learning, a set of mobile phones that are connected to a private network was used. The lesson planning and implementation through these mobile phones were facilitated by a web based Application. A purposively selected group of teachers developed three lessons while integrating mobile phones in a private network into learning activities. Then the lessons were implemented in real classroom settings. This paper is based on one of the lessons \u00e2\u0080\u0098Waves and their Characteristics\u00e2\u0080\u0099 that was implemented for Grade 11 students. The data were collected through observations using audio, video and field notes and were analyzed using thematic analysis technique with the help of NVivo10 qualitative data analysis software. Based on the thematic analysis, two assertions were derived. Notably teachers appreciated the support of the private network in enhancing the quality of group learning activity while minimizing the students\u00e2\u0080\u0099 misuse of mobile phones.",
            "authors": [
                "Sakunthala Yatigammana Ekanayake",
                "Kamalanath Samarakoon"
            ],
            "doi": "https://doi.org/10.3991/ijim.v10i2.4817",
            "preprint": "#",
            "pdf": "https://online-journals.org/index.php/i-jim/article/view/4817",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mobile learning",
                "Science education"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.3991/ijim.v10i2.4817/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.3991/ijim.v10i2.4817/index.json"
        }
    ],
    "Monitoring": [
        {
            "title": "Affordable real-time environment monitoring system for greenhouses",
            "venue": "2016 Manufacturing & Industrial Engineering Symposium (MIES)",
            "year": "2016",
            "abstract": "Greenhouse has been the best alternative solution to get a better crop production compared to the traditional agricultural industry. Greenhouses are used to increase harvest by controlling key factors which will aect the planet growth. Real-time monitoring of the greenhouse environment and taking necessary control decisions will result in improvement of yields and economic performance. In this Research paper, we propose an environmental monitoring and controlling system that have the ability to collect the information related to greenhouse environment using various sensors. This system provides the ability to monitor and control the greenhouse remotely via a web interface and a mobile application. Using a low-cost wireless sensor network, environment data on greenhouse are sent to the centralized server. It will store all this data and show the latest environment details of the greenhouse using the web interface. The web interface will provide a real-time graphical display of data using charts and gauges and ability to send control decisions to the central node which is necessary to increase harvest and improve the quality of crops.",
            "authors": [
                "Supun Athukorala",
                "Irunika Weeraratne",
                "Dumindu Jayathilaka",
                "Asitha Bandaranayake",
                "Roshan Ragel"
            ],
            "doi": "https://doi.org/10.1109/MIES.2016.7780261",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Servers",
                "Greenhouses",
                "Sensor systems",
                "Relays",
                "Monitoring",
                "Sensor phenomena and characterization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MIES.2016.7780261/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MIES.2016.7780261/index.json"
        }
    ],
    "Nanopolish": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Nanopore": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Nanopore Sequencing": [
        {
            "title": "Genopo: a nanopore sequencing analysis toolkit for portable Android devices",
            "venue": "Communications Biology",
            "year": "2020",
            "abstract": "The advent of portable nanopore sequencing devices has enabled DNA and RNA sequencing to be performed in the field or the clinic. However, advances in in situ genomics require parallel development of portable, offline solutions for the computational analysis of sequencing data. Here we introduce Genopo, a mobile toolkit for nanopore sequencing analysis. Genopo compacts popular bioinformatics tools to an Android application, enabling fully portable computation. To demonstrate its utility for in situ genome analysis, we use Genopo to determine the complete genome sequence of the human coronavirus SARS-CoV-2 in nine patient isolates sequenced on a nanopore device, with Genopo executing this workflow in less than 30\u00e2\u0080\u0089min per sample on a range of popular smartphones. We further show how Genopo can be used to profile DNA methylation in a human genome sample, illustrating a flexible, efficient architecture that is suitable to run many popular bioinformatics tools and accommodate small or large genomes. As the first ever smartphone application for nanopore sequencing analysis, Genopo enables the genomics community to harness this cheap, ubiquitous computational resource.",
            "authors": [
                "Hiruna Samarakoon",
                "Sanoj Punchihewa",
                "Anjana Senanayake",
                "Jillian M. Hammond",
                "Igor Stevanovski",
                "James M. Ferguson",
                "Roshan Ragel",
                "Hasindu Gamaarachchi",
                "Ira W. Deveson"
            ],
            "doi": "https://doi.org/10.1038/s42003-020-01270-z",
            "preprint": "#",
            "pdf": "https://www.nature.com/articles/s42003-020-01270-z.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering"
            ],
            "funding": "MRFF grant APP1173594 (to I.W.D.), Cancer Institute NSW Early Career Fellowship 2018/ECF013 (to I.W.D.) and philanthropic support from The Kinghorn Foundation (to I.W.D. and H.G.).",
            "tags": [
                "Genopo",
                "Nanopore Sequencing"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1038/s42003-020-01270-z/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1038/s42003-020-01270-z/index.json"
        }
    ],
    "Neural networks": [
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        }
    ],
    "Numerical models": [
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        }
    ],
    "Office automation": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Optical fiber networks": [
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        }
    ],
    "Optical imaging": [
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        }
    ],
    "Optical reflection": [
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        }
    ],
    "Optimisation": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Optimization": [
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "To use or not to use: CPUs' cache optimization techniques on GPGPUs",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU's best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946534",
            "preprint": "https://arxiv.org/pdf/1810.04063",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Arrays",
                "Optimization",
                "Merging",
                "Cache memory",
                "Testing",
                "Kernel",
                "Throughput"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946534/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946534/index.json"
        },
        {
            "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
            "authors": [
                "AH Wijethunge",
                "JV Wijekulasooriya",
                "Janaka B Ekanayake",
                "KB Samarakoon",
                "A Polpitiya"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300374",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Schedules",
                "Genetic algorithms",
                "Optimization",
                "Wind power generation",
                "Power demand",
                "Wind turbines",
                "Mathematical model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300374/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300374/index.json"
        }
    ],
    "Packaging": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Parallel processing": [
        {
            "title": "To use or not to use: Graphics processing units (GPUs) for pattern matching algorithms",
            "venue": "7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "String matching is an important part in today's computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069585",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms/links/54e48fc30cf2dbf60696ea10/To-Use-or-Not-to-Use-Graphics-Processing-Units-for-Pattern-Matching-Algorithms.pdf",
            "pdf": "https://ieeexplore.ieee.org/abstract/document/7069585",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Graphics processing units",
                "Central Processing Unit",
                "Pattern matching",
                "Parallel processing",
                "Algorithm design and analysis",
                "Performance evaluation",
                "Software algorithms"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069585/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069585/index.json"
        }
    ],
    "Partitioning algorithms": [
        {
            "title": "Heterogeneous processor pipeline for a product cipher application",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "Processing data received as a stream is a task commonly performed by modern embedded devices, in a wide range of applications such as multimedia (encoding/decoding/ playing media), networking (switching and routing), digital security, scientific data processing, etc. Such processing normally tends to be calculation intensive and therefore requiring significant processing power. Therefore, hardware acceleration methods to increase the performance of such applications constitute an important area of study. In this paper, we present an evaluation of one such method to process streaming data, namely multi-processor pipeline architecture. The hardware is based on a Multiple-Processor System on Chip (MPSoC), using a data encryption algorithm as a case study. The algorithm is partitioned on a coarse grained level and mapped on to an MPSoC with five processor cores in a pipeline, using specifically configured Xtensa LX3 cores. The system is then selectively optimized by strengthening and pruning the resources of each processor core. The optimized system is evaluated and compared against an optimal single-processor System on Chip (SoC) for the same application. The multiple-processor pipeline system for data encryption algorithms used was observed to provide significant speed ups, up to 4.45 times that of the single-processor system, which is close to the ideal speed up from a five-stage pipeline.",
            "authors": [
                "Isuru B. Nawinne",
                "Mahanama S. Wickramasinghe",
                "Roshan G. Ragel",
                "Member",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038036",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7299.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pipelines",
                "Encryption",
                "Algorithm design and analysis",
                "Partitioning algorithms",
                "Streaming media",
                "Computer architecture"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038036/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038036/index.json"
        }
    ],
    "Pattern matching": [
        {
            "title": "To use or not to use: Graphics processing units (GPUs) for pattern matching algorithms",
            "venue": "7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "String matching is an important part in today's computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069585",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms/links/54e48fc30cf2dbf60696ea10/To-Use-or-Not-to-Use-Graphics-Processing-Units-for-Pattern-Matching-Algorithms.pdf",
            "pdf": "https://ieeexplore.ieee.org/abstract/document/7069585",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Graphics processing units",
                "Central Processing Unit",
                "Pattern matching",
                "Parallel processing",
                "Algorithm design and analysis",
                "Performance evaluation",
                "Software algorithms"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069585/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069585/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        },
        {
            "title": "An optimized Parallel Failure-less Aho-Corasick algorithm for DNA sequence matching",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "The Aho-Corasick algorithm is a multiple patterns searching algorithm running sequentially in various applications like network intrusion detection and bioinformatics for finding several input strings within a given large input string. The parallel version of the Aho-Corasick algorithm is called as Parallel Failure-less Aho-Corasick algorithm because it doesnt need failure links like in the original Aho-Corasick algorithm. In this research, we implemented an application specific parallel failureless Aho-Corasick algorithm on the general purpose graphic processing unit by applying several cache optimization techniques for matching DNA sequences. Our parallel Aho-Corasick algorithm shows better performance than the available parallel Aho-Corasick algorithm library due to its simplicity and optimized cache memory usage of graphic processing units for matching DNA sequences.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946533",
            "preprint": "https://arxiv.org/pdf/1811.10498.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pattern matching",
                "DNA",
                "Algorithm design and analysis",
                "Kernel",
                "Bioinformatics",
                "Intrusion detection",
                "Graphics processing units"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946533/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946533/index.json"
        }
    ],
    "Pattern recognition": [
        {
            "title": "Non-contact Infant Sleep Apnea Detection",
            "venue": "IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2019",
            "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for the detection of sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
            "authors": [
                "Gihan Jayatilaka",
                "Harshana Weligampola",
                "Suren Sritharan",
                "Pankayaraj Pathmanathan",
                "Roshan Ragel",
                "Isuru Nawinne"
            ],
            "doi": "https://doi.org/10.1109/ICIIS47346.2019.9063269",
            "preprint": "https://arxiv.org/pdf/1910.04725.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering",
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Sleep apnea",
                "Video processing",
                "Bio medical engineering",
                "Pattern recognition"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS47346.2019.9063269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS47346.2019.9063269/index.json"
        }
    ],
    "Peptide Identification": [
        {
            "title": "Commentz-walter: Any better than aho-corasick for peptide identification?",
            "venue": "International Journal of Research in Computer Science",
            "year": "2012",
            "abstract": "An algorithm for locating all occurrences of a finite number of keywords in an arbitrary string, also known as multiple strings matching, is commonly required in information retrieval (such as sequence analysis, evolutionary biological studies, gene/protein identification and network intrusion detection) and text editing applications. Although Aho-Corasick was one of the commonly used exact multiple strings matching algorithm, Commentz-Walter has been introduced as a better alternative in the recent past. Comments-Walter algorithm combines ideas from both Aho-Corasick and Boyer Moore. Large scale rapid and accurate peptide identification is critical in computational proteomics. In this paper, we have critically analyzed the time complexity of Aho-Corasick and Commentz-Walter for their suitability in large scale peptide identification. According to the results we obtained for our dataset, we conclude that Aho-Corasick is performing better than Commentz-Walter as opposed to the common beliefs.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "RG Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.7815/ijorcs.26.2012.053",
            "preprint": "https://www.academia.edu/download/73625856/Vol2-Issue-06-04-commentz-walter-any-better-than-aho-corasick-for-peptide-identification.pdf",
            "pdf": "https://www.academia.edu/download/73625856/Vol2-Issue-06-04-commentz-walter-any-better-than-aho-corasick-for-peptide-identification.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Aho-Corasick",
                "Commentz-Walter",
                "Peptide Identification"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7815/ijorcs.26.2012.053/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7815/ijorcs.26.2012.053/index.json"
        }
    ],
    "Peptides": [
        {
            "title": "Tile optimization for area in FPGA based hardware acceleration of peptide identification",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Advances in life sciences over the last few decades have lead to the generation of a huge amount of biological data. Computing research has become a vital part in driving biological discovery where analysis and categorization of biological data are involved. String matching algorithms can be applied for protein/gene sequence matching and with the phenomenal increase in the size of string databases to be analyzed, software implementations of these algorithms seems to have hit a hard limit and hardware acceleration is increasingly being sought. Several hardware platforms such as Field Programmable Gate Arrays (FPGA), Graphics Processing Units (GPU) and Chip Multi Processors (CMP) are being explored as hardware platforms. In this paper, we give a comprehensive overview of the literature on hardware acceleration of string matching algorithms, we take an FPGA hardware exploration and expedite the design time by a design automation technique. Further, our design automation is also optimized for better hardware utilization through optimizing the number of peptides that can be represented in an FPGA tile. The results indicate significant improvements in design time and hardware utilization which are reported in this paper.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "Roshan G Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038056",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7296.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Peptides",
                "Field programmable gate arrays",
                "Tiles",
                "Hardware",
                "Software algorithms",
                "Proteins",
                "Software"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038056/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038056/index.json"
        },
        {
            "title": "Hardware software co-design of the Aho-Corasick algorithm: Scalable for protein identification?",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Pattern matching is commonly required in many application areas and bioinformatics is a major area of interest that requires both exact and approximate pattern matching. Much work has been done in this area, yet there is still a significant space for improvement in efficiency, flexibility, and throughput. This paper presents a hardware software co-design of Aho-Corasick algorithm in Nios II soft-processor and a study on its scalability for a pattern matching application. A software only approach is used to compare the throughput and the scalability of the hardware software co-design approach. According to the results we obtained, we conclude that the hardware software co-design implementation shows a maximum of 10 times speed up for pattern size of 1200 peptides compared to the software only implementation. The results also show that the hardware software co-design approach scales well for increasing data size compared to the software only approach.",
            "authors": [
                "S.M. Vidanagamachchi",
                "S.D. Dewasurendra",
                "",
                "R.G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732003",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.1317.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Proteins",
                "Peptides",
                "Software algorithms",
                "Program processors",
                "Algorithm design and analysis"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732003/index.json"
        },
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        },
        {
            "title": "A structured hardware software architecture for peptide based diagnosis \u00e2\u0080\u0094 Sub-string matching problem with limited tolerance",
            "venue": "2014 7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "S. Devapriya Dewasurendra",
                "Roshan G. Ragel",
                "Mahesan Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069624",
            "preprint": "https://arxiv.org/pdf/1412.7811",
            "pdf": "https://arxiv.org/pdf/1412.7811",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Amino acids",
                "Software",
                "Automata",
                "Databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069624/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069624/index.json"
        }
    ],
    "Performance evaluation": [
        {
            "title": "Offloading specific performance-related kernel functions into an FPGA",
            "venue": "2021 IEEE 30th International Symposium on Industrial Electronics (ISIE)",
            "year": "2021",
            "abstract": "Today's network transactions are usually handled using kernel-based network protocols residing on general-purpose processors (GPPs). Over time, network transmission speeds have developed rapidly without a corresponding increase in processing speeds of host processors. With devices featuring advanced connectivity and Internet functionality, protocol processing has created a heavy workload on the GPP and has become a limiting factor in high performance networking applications such as online High Frequency Trading Systems (HFTS). It encourages designers to increase processor performance or designing application specific processors for handling heavy network workloads. Then there is the choice of hardware/software implementations based on results from hardware acceleration. Offloading the whole network protocol stack implementation into hardware is not very attractive since handling large linked data structures inside the hardware is not as easy as in software. In this paper we claim that relieving the CPU from bulk processing by offloading selected, performance-related kernel code into hardware is a better option for such scenarios. Hence, we design a scalable system for offloading specific performance-related kernel functions into an FPGA. In this paper we discuss the logic behind our new architecture and the results up to now.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S. Devapriya Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ISIE45552.2021.9576256",
            "preprint": "https://www.academia.edu/download/75534730/KF_003255_ISIE2021paper.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Performance evaluation",
                "Protocols",
                "Profitability",
                "Linux",
                "Computer architecture",
                "Software",
                "Security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ISIE45552.2021.9576256/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ISIE45552.2021.9576256/index.json"
        },
        {
            "title": "To use or not to use: Graphics processing units (GPUs) for pattern matching algorithms",
            "venue": "7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "String matching is an important part in today's computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069585",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms/links/54e48fc30cf2dbf60696ea10/To-Use-or-Not-to-Use-Graphics-Processing-Units-for-Pattern-Matching-Algorithms.pdf",
            "pdf": "https://ieeexplore.ieee.org/abstract/document/7069585",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Graphics processing units",
                "Central Processing Unit",
                "Pattern matching",
                "Parallel processing",
                "Algorithm design and analysis",
                "Performance evaluation",
                "Software algorithms"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069585/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069585/index.json"
        }
    ],
    "Petri nets": [
        {
            "title": "Model-based fault diagnosis and prognosis of dynamic systems: a review",
            "venue": "Procedia Manufacturing",
            "year": "2019",
            "abstract": "In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.",
            "authors": [
                "Thushara Ekanayakea",
                "Devapriya Dewasurendra",
                "Sunil Abeyratne",
                "Lin Ma",
                "Prasad Yarlagadda"
            ],
            "doi": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "preprint": "#",
            "pdf": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "model-based systems",
                "fault diagnosis",
                "fault prognosis",
                "automata",
                "Petri nets",
                "bond graphs",
                "Bayesian networks"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1016/j.promfg.2019.02.060/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1016/j.promfg.2019.02.060/index.json"
        }
    ],
    "Pipeline computing": [
        {
            "title": "DRMA: dynamically reconfigurable MPSoC architecture",
            "venue": "GLSVLSI '13: Proceedings of the 23rd ACM international conference on Great lakes symposium on VLSI",
            "year": "2013",
            "abstract": "Embedded systems are ubiquitous and are deployed in a large range of applications. Designing and fabricating Integrated Circuits (ICs) targeting such different range of applications is expensive. Designers seek flexible processors which efficiently execute a multitude of applications. FPGAs are considered affordable, but design cost, high reconfiguration delay and power consumption are all prohibitive. In this paper, we propose a novel ASIC based flexible MPSoC architecture, which can execute separate tasks in parallel, and it can be configured to execute single task with wide data widths or execute multiple tasks with varying data widths. The architecture presented, called Dynamically Reconfigurable MPSoC Architecture (DRMA), can be rapidly reconfigured through instructions. We present applications as case studies to showcase the flexibility and efficacy of DRMA. Results show for an additional area overhead of about 5%, the system is capable of working as four 32-bit processors, a single 128 bit processor or as a pipelined processing system.",
            "authors": [
                "Lawrance Zhang",
                "Jude Angelo Ambrose",
                "Jorgen Peddersen",
                "Sri Parameswaran",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Kewal K. Saluja"
            ],
            "doi": "https://doi.org/10.1145/2483028.2483101",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Computer systems organization",
                "Architectures",
                "Serial architectures",
                "Pipeline computing",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2483028.2483101/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2483028.2483101/index.json"
        }
    ],
    "Pipelines": [
        {
            "title": "Heterogeneous processor pipeline for a product cipher application",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "Processing data received as a stream is a task commonly performed by modern embedded devices, in a wide range of applications such as multimedia (encoding/decoding/ playing media), networking (switching and routing), digital security, scientific data processing, etc. Such processing normally tends to be calculation intensive and therefore requiring significant processing power. Therefore, hardware acceleration methods to increase the performance of such applications constitute an important area of study. In this paper, we present an evaluation of one such method to process streaming data, namely multi-processor pipeline architecture. The hardware is based on a Multiple-Processor System on Chip (MPSoC), using a data encryption algorithm as a case study. The algorithm is partitioned on a coarse grained level and mapped on to an MPSoC with five processor cores in a pipeline, using specifically configured Xtensa LX3 cores. The system is then selectively optimized by strengthening and pruning the resources of each processor core. The optimized system is evaluated and compared against an optimal single-processor System on Chip (SoC) for the same application. The multiple-processor pipeline system for data encryption algorithms used was observed to provide significant speed ups, up to 4.45 times that of the single-processor system, which is close to the ideal speed up from a five-stage pipeline.",
            "authors": [
                "Isuru B. Nawinne",
                "Mahanama S. Wickramasinghe",
                "Roshan G. Ragel",
                "Member",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038036",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7299.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pipelines",
                "Encryption",
                "Algorithm design and analysis",
                "Partitioning algorithms",
                "Streaming media",
                "Computer architecture"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038036/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038036/index.json"
        }
    ],
    "Polynomials": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        }
    ],
    "Postal services": [
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Power demand": [
        {
            "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
            "authors": [
                "AH Wijethunge",
                "JV Wijekulasooriya",
                "Janaka B Ekanayake",
                "KB Samarakoon",
                "A Polpitiya"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300374",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Schedules",
                "Genetic algorithms",
                "Optimization",
                "Wind power generation",
                "Power demand",
                "Wind turbines",
                "Mathematical model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300374/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300374/index.json"
        }
    ],
    "Process control": [
        {
            "title": "Statechart based modeling and controller implementation of complex reactive systems",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Statechart formalism has been a preferred choice for modeling complex reactive systems (CRS) in recent years. It has inbuilt powerful features of orthogonality, hierarchy, intermodular communication and history. Once statechart based system modeling is done the next issues to be addressed are (1) modular verification of the system for failsafe operation under all possible working conditions (2) progressive controller implementation together with the supervisory control while maintaining traceability and re-configurability and (3) facilitation of controller adaptation for progressive incorporation of security features and supervisory specifications. An elevator system was designed and built to reflect exigencies of a typical CRS hardware/software platform. A controller was designed to meet the above requirements and tested on the platform to validate the feasibility of model-based control design/verification methodology for real scale systems. Modularity was achieved by developing the statechart model of the plant into a tree of communicating language generators. Progresively verified modules were then translated into sequential function charts (SFC) which were finally integrated to form a complete flat SFC. The SFC was then implemented on a PLC platform (Telemechanique). The program was first validated in simulation using Telemechanique \u00e2\u0080\u009cTwidosuite\u00e2\u0080\u009d for different operating conditions and finally tested on the elevator system.",
            "authors": [
                "AC Vidanapathirana",
                "SD Dewasurendra",
                "SG Abeyratne"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038120",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Generators",
                "Software",
                "Automata",
                "Process control",
                "Floors",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038120/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038120/index.json"
        }
    ],
    "Profitability": [
        {
            "title": "Offloading specific performance-related kernel functions into an FPGA",
            "venue": "2021 IEEE 30th International Symposium on Industrial Electronics (ISIE)",
            "year": "2021",
            "abstract": "Today's network transactions are usually handled using kernel-based network protocols residing on general-purpose processors (GPPs). Over time, network transmission speeds have developed rapidly without a corresponding increase in processing speeds of host processors. With devices featuring advanced connectivity and Internet functionality, protocol processing has created a heavy workload on the GPP and has become a limiting factor in high performance networking applications such as online High Frequency Trading Systems (HFTS). It encourages designers to increase processor performance or designing application specific processors for handling heavy network workloads. Then there is the choice of hardware/software implementations based on results from hardware acceleration. Offloading the whole network protocol stack implementation into hardware is not very attractive since handling large linked data structures inside the hardware is not as easy as in software. In this paper we claim that relieving the CPU from bulk processing by offloading selected, performance-related kernel code into hardware is a better option for such scenarios. Hence, we design a scalable system for offloading specific performance-related kernel functions into an FPGA. In this paper we discuss the logic behind our new architecture and the results up to now.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S. Devapriya Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ISIE45552.2021.9576256",
            "preprint": "https://www.academia.edu/download/75534730/KF_003255_ISIE2021paper.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Performance evaluation",
                "Protocols",
                "Profitability",
                "Linux",
                "Computer architecture",
                "Software",
                "Security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ISIE45552.2021.9576256/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ISIE45552.2021.9576256/index.json"
        }
    ],
    "Program processors": [
        {
            "title": "Hardware software co-design of the Aho-Corasick algorithm: Scalable for protein identification?",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Pattern matching is commonly required in many application areas and bioinformatics is a major area of interest that requires both exact and approximate pattern matching. Much work has been done in this area, yet there is still a significant space for improvement in efficiency, flexibility, and throughput. This paper presents a hardware software co-design of Aho-Corasick algorithm in Nios II soft-processor and a study on its scalability for a pattern matching application. A software only approach is used to compare the throughput and the scalability of the hardware software co-design approach. According to the results we obtained, we conclude that the hardware software co-design implementation shows a maximum of 10 times speed up for pattern size of 1200 peptides compared to the software only implementation. The results also show that the hardware software co-design approach scales well for increasing data size compared to the software only approach.",
            "authors": [
                "S.M. Vidanagamachchi",
                "S.D. Dewasurendra",
                "",
                "R.G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732003",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.1317.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Proteins",
                "Peptides",
                "Software algorithms",
                "Program processors",
                "Algorithm design and analysis"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732003/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        }
    ],
    "Programming": [
        {
            "title": "CSER: HW/SW configurable soft-error resiliency for application specific instruction-set processors",
            "venue": "2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)",
            "year": "2013",
            "abstract": "Soft error has been identified as one of the major challenges to CMOS technology based computing systems. To mitigate this problem, error recovery is a key component, which usually accounts for a substantial cost, since they must introduce redundancies in either time or space. Consequently, using state-of-art recovery techniques could heavily worsen the design constraint, which is fairly stringent for embedded system design. In this paper, we propose a HW/SW methodology that generates the processor, which performs finely configured error recovery functionality targeting the given design constraints (e.g., performance, area and power). Our methodology employs three application-specific optimization heuristics, which generate the optimized composition and configuration based on the two primitive error recovery techniques. The resultant processor is composed of selected primitive techniques at corresponding instruction execution, and configured to perform error recovery at run-time accordingly to the scheme determined at design time. The experiment results have shown that our methodology can at best achieve nine times reliability while maintaining the given constraints, in comparison to the state of the art.",
            "authors": [
                "Tuo Li",
                "Muhammad Shafique",
                "Semeen Rehman",
                "Swarnalatha Radhakrishnan",
                "Roshan Ragel",
                "Jude Angelo Ambrose",
                "J\u00c3\u00b6rg Henkel",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.7873/DATE.2013.152",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Redundancy",
                "Time factors",
                "Runtime",
                "Integrated circuits",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7873/DATE.2013.152/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7873/DATE.2013.152/index.json"
        },
        {
            "title": "Visual Design Platform for Wireless Sensor Network",
            "venue": "2018 Moratuwa Engineering Research Conference (MERCon)",
            "year": "2018",
            "abstract": "Wireless Sensor Networks (WSN) are being widely used for sensing physical parameters in a broad geographical area. The person who needs WSN will have a pictorial idea of the sensor network. The problem in the traditional method is that the person who needs the WSN should explain the pictorial view of the sensor network to a commercial vendor and buy it from them or they should design it from the scratch. What we proposed in our solution is to develop a platform so that the person who needs the WSN can directly draw the pictorial view on a canvas and then it can automatically generate all the required firmware for the microcontrollers and wiring diagrams. The user is then required only to follow a few instructions to complete the real world implementation of WSNs. This paper is about developing a visual platform to design WSNs. The WSN designing platform was built as a web application, so it can manage a large number of supported sensors and microcontrollers. This means that if one user adds the device driver for any sensor or a microcontroller the other users can directly use it from the WSN design platform without worrying about hardware programming. Further, if anyone needs a new sensor or microcontroller to be supported by this visual design platform, this design tool will have interfaces to directly add new sensors and microcontrollers. The proposed method is affordable for developing custom wireless sensor networks.",
            "authors": [
                "Rosen Silva",
                "Asela Dasanayaka",
                "Roshan Ragel",
                "Asitha Bandaranayake"
            ],
            "doi": "https://doi.org/10.1109/MERCon.2018.8421896",
            "preprint": "https://www.researchgate.net/profile/Asitha-Bandaranayake-3/publication/327517623_Visual_Design_Platform_for_Wireless_Sensor_Network/links/5f98da03458515b7cfa4013c/Visual-Design-Platform-for-Wireless-Sensor-Network.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Wireless sensor networks",
                "Microcontrollers",
                "Databases",
                "Skeleton",
                "Visualization",
                "Hardware",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon.2018.8421896/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon.2018.8421896/index.json"
        }
    ],
    "Proteins": [
        {
            "title": "Tile optimization for area in FPGA based hardware acceleration of peptide identification",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Advances in life sciences over the last few decades have lead to the generation of a huge amount of biological data. Computing research has become a vital part in driving biological discovery where analysis and categorization of biological data are involved. String matching algorithms can be applied for protein/gene sequence matching and with the phenomenal increase in the size of string databases to be analyzed, software implementations of these algorithms seems to have hit a hard limit and hardware acceleration is increasingly being sought. Several hardware platforms such as Field Programmable Gate Arrays (FPGA), Graphics Processing Units (GPU) and Chip Multi Processors (CMP) are being explored as hardware platforms. In this paper, we give a comprehensive overview of the literature on hardware acceleration of string matching algorithms, we take an FPGA hardware exploration and expedite the design time by a design automation technique. Further, our design automation is also optimized for better hardware utilization through optimizing the number of peptides that can be represented in an FPGA tile. The results indicate significant improvements in design time and hardware utilization which are reported in this paper.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "Roshan G Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038056",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7296.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Peptides",
                "Field programmable gate arrays",
                "Tiles",
                "Hardware",
                "Software algorithms",
                "Proteins",
                "Software"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038056/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038056/index.json"
        },
        {
            "title": "Hardware software co-design of the Aho-Corasick algorithm: Scalable for protein identification?",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Pattern matching is commonly required in many application areas and bioinformatics is a major area of interest that requires both exact and approximate pattern matching. Much work has been done in this area, yet there is still a significant space for improvement in efficiency, flexibility, and throughput. This paper presents a hardware software co-design of Aho-Corasick algorithm in Nios II soft-processor and a study on its scalability for a pattern matching application. A software only approach is used to compare the throughput and the scalability of the hardware software co-design approach. According to the results we obtained, we conclude that the hardware software co-design implementation shows a maximum of 10 times speed up for pattern size of 1200 peptides compared to the software only implementation. The results also show that the hardware software co-design approach scales well for increasing data size compared to the software only approach.",
            "authors": [
                "S.M. Vidanagamachchi",
                "S.D. Dewasurendra",
                "",
                "R.G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732003",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.1317.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Proteins",
                "Peptides",
                "Software algorithms",
                "Program processors",
                "Algorithm design and analysis"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732003/index.json"
        },
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        },
        {
            "title": "A structured hardware software architecture for peptide based diagnosis \u00e2\u0080\u0094 Sub-string matching problem with limited tolerance",
            "venue": "2014 7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "S. Devapriya Dewasurendra",
                "Roshan G. Ragel",
                "Mahesan Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069624",
            "preprint": "https://arxiv.org/pdf/1412.7811",
            "pdf": "https://arxiv.org/pdf/1412.7811",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Amino acids",
                "Software",
                "Automata",
                "Databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069624/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069624/index.json"
        },
        {
            "title": "A Novel FPGA Architecture of Commentz-Walter Algorithm using Bit-Split String-Matching Engines",
            "venue": "2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)",
            "year": "2021",
            "abstract": "This paper describes a reconfigurable hardware implementation of CommentzWalter algorithm with bit-split string matching engines to match multiple protein sequences. It is reported that multiple pattern matching using the most widely used Aho-Corasick algorithm for different applications has been carried out on graphics processing units and field programmable gate arrays to accelerate the matching process. Commentz-Walter algorithm, is a multiple pattern matching algorithm and more complex than Aho-Corasick. There are no reports of it being directly implemented in any hardware platform except as software implementations on general purpose processors. In this work, a specific architecture for our target application using CommentzWalter algorithm has been developed and tested with a simulator for hardware description languages. This architecture can match multiple patterns of proteins efficiently when implemented on a Field Programmable Gate Array. Finally, we compare a previously developed hardware architecture of bit-split Aho-Corasick with our bit-split Commentz-Walter architecture. Using the Intel Stratix IV GX EP4SGX230KF40C2 FPGA chip as the target device, the compilation results with Quartus II show that the synthesis logic utilization is 5% with 2203 total number of registers, 64896 FPGA block memory bits and 4 DSP block 18-bit elements. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the Commentz-Walter algorithm.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "Shirley D. Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICter53630.2021.9774805",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Software algorithms",
                "Computer architecture",
                "Logic gates",
                "Hardware",
                "Software",
                "Registers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICter53630.2021.9774805/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICter53630.2021.9774805/index.json"
        }
    ],
    "Protocols": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        },
        {
            "title": "Offloading specific performance-related kernel functions into an FPGA",
            "venue": "2021 IEEE 30th International Symposium on Industrial Electronics (ISIE)",
            "year": "2021",
            "abstract": "Today's network transactions are usually handled using kernel-based network protocols residing on general-purpose processors (GPPs). Over time, network transmission speeds have developed rapidly without a corresponding increase in processing speeds of host processors. With devices featuring advanced connectivity and Internet functionality, protocol processing has created a heavy workload on the GPP and has become a limiting factor in high performance networking applications such as online High Frequency Trading Systems (HFTS). It encourages designers to increase processor performance or designing application specific processors for handling heavy network workloads. Then there is the choice of hardware/software implementations based on results from hardware acceleration. Offloading the whole network protocol stack implementation into hardware is not very attractive since handling large linked data structures inside the hardware is not as easy as in software. In this paper we claim that relieving the CPU from bulk processing by offloading selected, performance-related kernel code into hardware is a better option for such scenarios. Hence, we design a scalable system for offloading specific performance-related kernel functions into an FPGA. In this paper we discuss the logic behind our new architecture and the results up to now.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S. Devapriya Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ISIE45552.2021.9576256",
            "preprint": "https://www.academia.edu/download/75534730/KF_003255_ISIE2021paper.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Performance evaluation",
                "Protocols",
                "Profitability",
                "Linux",
                "Computer architecture",
                "Software",
                "Security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ISIE45552.2021.9576256/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ISIE45552.2021.9576256/index.json"
        }
    ],
    "Prototypes": [
        {
            "title": "Design and implementation of a statechart based reconfigurable elevator controller",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "This paper presents a simple and clear method to design and implement a reconfigurable elevator controller using an FPGA, which can be implemented for an elevator with any (N) number of floors, with specified inputs and outputs. A model based design approach was followed. We started from a state chart model developed for a prototype elevator with three floors. Extension of the model for a variable number of floors was considered. Controller for the prototype system was implemented in ladder logic on a PLC and the limitations of that approach with regard to re-configurability were identified: viz., in the extension of elevator controller for `N' no of floors. Next VHDL code was developed for a reconfigurable elevator controller where, by changing a variable corresponding to the required number of floors, the suitable code can be generated. The controller thus generated can be implemented in an FPGA. The method was successfully tested on a Xilinx Spartan 3AN FPGA.",
            "authors": [
                "HPAP Jayawardana",
                "HWKM Amarasekara",
                "PTS Peelikumbura",
                "WAKC Jayathilaka",
                "SG Abeyaratne",
                "SD Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038093",
            "preprint": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "pdf": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Floors",
                "Field programmable gate arrays",
                "Prototypes",
                "Sensors",
                "Mathematical model",
                "Control systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038093/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038093/index.json"
        }
    ],
    "Random number generation": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Red blood cells": [
        {
            "title": "Chronic kidney disease prediction using machine learning methods",
            "venue": "2020 Moratuwa Engineering Research Conference (MERCon) - IEEE",
            "year": "2020",
            "abstract": "Chronic Kidney Disease (CKD) or chronic renal disease has become a major issue with a steady growth rate. A person can only survive without kidneys for an average time of 18 days, which makes a huge demand for a kidney transplant and Dialysis. It is important to have effective methods for early prediction of CKD. Machine learning methods are effective in CKD prediction. This work proposes a workflow to predict CKD status based on clinical data, incorporating data prepossessing, a missing value handling method with collaborative filtering and attributes selection. Out of the 11 machine learning methods considered, the extra tree classifier and random forest classifier are shown to result in the highest accuracy and minimal bias to the attributes. The research also considers the practical aspects of data collection and highlights the importance of incorporating domain knowledge when using machine learning for CKD status prediction.",
            "authors": [
                "Imesh Udara Ekanayake; Damayanthi Herath"
            ],
            "doi": " https://doi.org/10.1109/MERCon50084.2020.9185249",
            "preprint": "#",
            "pdf": "https://www.researchgate.net/profile/Imesh-Ekanayake/publication/344319206_Chronic_Kidney_Disease_Prediction_Using_Machine_Learning_Methods/links/5f672571458515b7cf418d5b/Chronic-Kidney-Disease-Prediction-Using-Machine-Learning-Methods.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Machine Learning and Data Mining"
            ],
            "funding": "",
            "tags": [
                "Kidney",
                "Diseases",
                "Machine learning",
                "Red blood cells",
                "Hypertension"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/ 10.1109/MERCon50084.2020.9185249/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/ 10.1109/MERCon50084.2020.9185249/index.json"
        }
    ],
    "Redundancy": [
        {
            "title": "CSER: HW/SW configurable soft-error resiliency for application specific instruction-set processors",
            "venue": "2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)",
            "year": "2013",
            "abstract": "Soft error has been identified as one of the major challenges to CMOS technology based computing systems. To mitigate this problem, error recovery is a key component, which usually accounts for a substantial cost, since they must introduce redundancies in either time or space. Consequently, using state-of-art recovery techniques could heavily worsen the design constraint, which is fairly stringent for embedded system design. In this paper, we propose a HW/SW methodology that generates the processor, which performs finely configured error recovery functionality targeting the given design constraints (e.g., performance, area and power). Our methodology employs three application-specific optimization heuristics, which generate the optimized composition and configuration based on the two primitive error recovery techniques. The resultant processor is composed of selected primitive techniques at corresponding instruction execution, and configured to perform error recovery at run-time accordingly to the scheme determined at design time. The experiment results have shown that our methodology can at best achieve nine times reliability while maintaining the given constraints, in comparison to the state of the art.",
            "authors": [
                "Tuo Li",
                "Muhammad Shafique",
                "Semeen Rehman",
                "Swarnalatha Radhakrishnan",
                "Roshan Ragel",
                "Jude Angelo Ambrose",
                "J\u00c3\u00b6rg Henkel",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.7873/DATE.2013.152",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Redundancy",
                "Time factors",
                "Runtime",
                "Integrated circuits",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7873/DATE.2013.152/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7873/DATE.2013.152/index.json"
        }
    ],
    "Reflectivity": [
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        }
    ],
    "Registers": [
        {
            "title": "A Novel FPGA Architecture of Commentz-Walter Algorithm using Bit-Split String-Matching Engines",
            "venue": "2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)",
            "year": "2021",
            "abstract": "This paper describes a reconfigurable hardware implementation of CommentzWalter algorithm with bit-split string matching engines to match multiple protein sequences. It is reported that multiple pattern matching using the most widely used Aho-Corasick algorithm for different applications has been carried out on graphics processing units and field programmable gate arrays to accelerate the matching process. Commentz-Walter algorithm, is a multiple pattern matching algorithm and more complex than Aho-Corasick. There are no reports of it being directly implemented in any hardware platform except as software implementations on general purpose processors. In this work, a specific architecture for our target application using CommentzWalter algorithm has been developed and tested with a simulator for hardware description languages. This architecture can match multiple patterns of proteins efficiently when implemented on a Field Programmable Gate Array. Finally, we compare a previously developed hardware architecture of bit-split Aho-Corasick with our bit-split Commentz-Walter architecture. Using the Intel Stratix IV GX EP4SGX230KF40C2 FPGA chip as the target device, the compilation results with Quartus II show that the synthesis logic utilization is 5% with 2203 total number of registers, 64896 FPGA block memory bits and 4 DSP block 18-bit elements. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the Commentz-Walter algorithm.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "Shirley D. Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICter53630.2021.9774805",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Software algorithms",
                "Computer architecture",
                "Logic gates",
                "Hardware",
                "Software",
                "Registers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICter53630.2021.9774805/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICter53630.2021.9774805/index.json"
        }
    ],
    "Relational databases": [
        {
            "title": " Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
            "authors": [
                "Pranavan Somaskandhan",
                "Gihan Wijesinghe",
                "Leshan Bashitha Wijegunawardana",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300399",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Sports equipment",
                "Data mining",
                "Measurement",
                "Support vector machines",
                "Statistical analysis",
                "Games",
                "Relational databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300399/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300399/index.json"
        }
    ],
    "Relays": [
        {
            "title": "Affordable real-time environment monitoring system for greenhouses",
            "venue": "2016 Manufacturing & Industrial Engineering Symposium (MIES)",
            "year": "2016",
            "abstract": "Greenhouse has been the best alternative solution to get a better crop production compared to the traditional agricultural industry. Greenhouses are used to increase harvest by controlling key factors which will aect the planet growth. Real-time monitoring of the greenhouse environment and taking necessary control decisions will result in improvement of yields and economic performance. In this Research paper, we propose an environmental monitoring and controlling system that have the ability to collect the information related to greenhouse environment using various sensors. This system provides the ability to monitor and control the greenhouse remotely via a web interface and a mobile application. Using a low-cost wireless sensor network, environment data on greenhouse are sent to the centralized server. It will store all this data and show the latest environment details of the greenhouse using the web interface. The web interface will provide a real-time graphical display of data using charts and gauges and ability to send control decisions to the central node which is necessary to increase harvest and improve the quality of crops.",
            "authors": [
                "Supun Athukorala",
                "Irunika Weeraratne",
                "Dumindu Jayathilaka",
                "Asitha Bandaranayake",
                "Roshan Ragel"
            ],
            "doi": "https://doi.org/10.1109/MIES.2016.7780261",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Servers",
                "Greenhouses",
                "Sensor systems",
                "Relays",
                "Monitoring",
                "Sensor phenomena and characterization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MIES.2016.7780261/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MIES.2016.7780261/index.json"
        }
    ],
    "Resource management": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Retinex theory": [
        {
            "title": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for Enhancing Low Light Images",
            "venue": "MERcon",
            "year": "2020",
            "abstract": "Low light image enhancement is an important challenge for the development of robust computer vision algorithms. The machine learning approaches to this have been either unsupervised, supervised based on paired dataset or supervised based on unpaired dataset. This paper presents a novel deep learning pipeline that can learn from both paired and unpaired datasets. Convolution Neural Networks (CNNs) that are optimized to minimize standard loss, and Generative Adversarial Networks (GANs) that are optimized to minimize the adversarial loss are used to achieve different steps of the low light image enhancement process. Cycle consistency loss and a patched discriminator are utilized to further improve the performance. The paper also analyses the functionality and the performance of different components, hidden layers, and the entire pipeline.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Roshan Goldaliyadda",
                "Parakrama Ekanayeka",
                "Roshan Ragel",
                "Vijitha Herath"
            ],
            "doi": "https://doi.org/10.1109/MERCon50084.2020.9185373",
            "preprint": "https://arxiv.org/pdf/2006.15304.pdf",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/mercon-2020-presentation.pdf",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Low-light image enhancement",
                "Retinex theory",
                "Generative adversarial networks",
                "Cycle consistency",
                "Computer Vision"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon50084.2020.9185373/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon50084.2020.9185373/index.json"
        }
    ],
    "Runtime": [
        {
            "title": "CSER: HW/SW configurable soft-error resiliency for application specific instruction-set processors",
            "venue": "2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)",
            "year": "2013",
            "abstract": "Soft error has been identified as one of the major challenges to CMOS technology based computing systems. To mitigate this problem, error recovery is a key component, which usually accounts for a substantial cost, since they must introduce redundancies in either time or space. Consequently, using state-of-art recovery techniques could heavily worsen the design constraint, which is fairly stringent for embedded system design. In this paper, we propose a HW/SW methodology that generates the processor, which performs finely configured error recovery functionality targeting the given design constraints (e.g., performance, area and power). Our methodology employs three application-specific optimization heuristics, which generate the optimized composition and configuration based on the two primitive error recovery techniques. The resultant processor is composed of selected primitive techniques at corresponding instruction execution, and configured to perform error recovery at run-time accordingly to the scheme determined at design time. The experiment results have shown that our methodology can at best achieve nine times reliability while maintaining the given constraints, in comparison to the state of the art.",
            "authors": [
                "Tuo Li",
                "Muhammad Shafique",
                "Semeen Rehman",
                "Swarnalatha Radhakrishnan",
                "Roshan Ragel",
                "Jude Angelo Ambrose",
                "J\u00c3\u00b6rg Henkel",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.7873/DATE.2013.152",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Redundancy",
                "Time factors",
                "Runtime",
                "Integrated circuits",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7873/DATE.2013.152/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7873/DATE.2013.152/index.json"
        }
    ],
    "Schedules": [
        {
            "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
            "authors": [
                "AH Wijethunge",
                "JV Wijekulasooriya",
                "Janaka B Ekanayake",
                "KB Samarakoon",
                "A Polpitiya"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300374",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Schedules",
                "Genetic algorithms",
                "Optimization",
                "Wind power generation",
                "Power demand",
                "Wind turbines",
                "Mathematical model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300374/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300374/index.json"
        }
    ],
    "Science education": [
        {
            "title": "Support of Mobile Phones in a Private Network for Science Teaching",
            "venue": "International Journal of Interactive Mobile Technologies",
            "year": "2016",
            "abstract": "The potential of mobile phones to facilitate students\u00e2\u0080\u0099 science learning, when they are engaging in group activities, was investigated. To minimize the disciplinary issues emerged from the previous research on mobile devices and to enhance the quality of learning, a set of mobile phones that are connected to a private network was used. The lesson planning and implementation through these mobile phones were facilitated by a web based Application. A purposively selected group of teachers developed three lessons while integrating mobile phones in a private network into learning activities. Then the lessons were implemented in real classroom settings. This paper is based on one of the lessons \u00e2\u0080\u0098Waves and their Characteristics\u00e2\u0080\u0099 that was implemented for Grade 11 students. The data were collected through observations using audio, video and field notes and were analyzed using thematic analysis technique with the help of NVivo10 qualitative data analysis software. Based on the thematic analysis, two assertions were derived. Notably teachers appreciated the support of the private network in enhancing the quality of group learning activity while minimizing the students\u00e2\u0080\u0099 misuse of mobile phones.",
            "authors": [
                "Sakunthala Yatigammana Ekanayake",
                "Kamalanath Samarakoon"
            ],
            "doi": "https://doi.org/10.3991/ijim.v10i2.4817",
            "preprint": "#",
            "pdf": "https://online-journals.org/index.php/i-jim/article/view/4817",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mobile learning",
                "Science education"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.3991/ijim.v10i2.4817/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.3991/ijim.v10i2.4817/index.json"
        }
    ],
    "Search engines": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Security": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        },
        {
            "title": "Offloading specific performance-related kernel functions into an FPGA",
            "venue": "2021 IEEE 30th International Symposium on Industrial Electronics (ISIE)",
            "year": "2021",
            "abstract": "Today's network transactions are usually handled using kernel-based network protocols residing on general-purpose processors (GPPs). Over time, network transmission speeds have developed rapidly without a corresponding increase in processing speeds of host processors. With devices featuring advanced connectivity and Internet functionality, protocol processing has created a heavy workload on the GPP and has become a limiting factor in high performance networking applications such as online High Frequency Trading Systems (HFTS). It encourages designers to increase processor performance or designing application specific processors for handling heavy network workloads. Then there is the choice of hardware/software implementations based on results from hardware acceleration. Offloading the whole network protocol stack implementation into hardware is not very attractive since handling large linked data structures inside the hardware is not as easy as in software. In this paper we claim that relieving the CPU from bulk processing by offloading selected, performance-related kernel code into hardware is a better option for such scenarios. Hence, we design a scalable system for offloading specific performance-related kernel functions into an FPGA. In this paper we discuss the logic behind our new architecture and the results up to now.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S. Devapriya Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ISIE45552.2021.9576256",
            "preprint": "https://www.academia.edu/download/75534730/KF_003255_ISIE2021paper.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Performance evaluation",
                "Protocols",
                "Profitability",
                "Linux",
                "Computer architecture",
                "Software",
                "Security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ISIE45552.2021.9576256/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ISIE45552.2021.9576256/index.json"
        }
    ],
    "Sensor phenomena and characterization": [
        {
            "title": "Affordable real-time environment monitoring system for greenhouses",
            "venue": "2016 Manufacturing & Industrial Engineering Symposium (MIES)",
            "year": "2016",
            "abstract": "Greenhouse has been the best alternative solution to get a better crop production compared to the traditional agricultural industry. Greenhouses are used to increase harvest by controlling key factors which will aect the planet growth. Real-time monitoring of the greenhouse environment and taking necessary control decisions will result in improvement of yields and economic performance. In this Research paper, we propose an environmental monitoring and controlling system that have the ability to collect the information related to greenhouse environment using various sensors. This system provides the ability to monitor and control the greenhouse remotely via a web interface and a mobile application. Using a low-cost wireless sensor network, environment data on greenhouse are sent to the centralized server. It will store all this data and show the latest environment details of the greenhouse using the web interface. The web interface will provide a real-time graphical display of data using charts and gauges and ability to send control decisions to the central node which is necessary to increase harvest and improve the quality of crops.",
            "authors": [
                "Supun Athukorala",
                "Irunika Weeraratne",
                "Dumindu Jayathilaka",
                "Asitha Bandaranayake",
                "Roshan Ragel"
            ],
            "doi": "https://doi.org/10.1109/MIES.2016.7780261",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Servers",
                "Greenhouses",
                "Sensor systems",
                "Relays",
                "Monitoring",
                "Sensor phenomena and characterization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MIES.2016.7780261/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MIES.2016.7780261/index.json"
        }
    ],
    "Sensor systems": [
        {
            "title": "Affordable real-time environment monitoring system for greenhouses",
            "venue": "2016 Manufacturing & Industrial Engineering Symposium (MIES)",
            "year": "2016",
            "abstract": "Greenhouse has been the best alternative solution to get a better crop production compared to the traditional agricultural industry. Greenhouses are used to increase harvest by controlling key factors which will aect the planet growth. Real-time monitoring of the greenhouse environment and taking necessary control decisions will result in improvement of yields and economic performance. In this Research paper, we propose an environmental monitoring and controlling system that have the ability to collect the information related to greenhouse environment using various sensors. This system provides the ability to monitor and control the greenhouse remotely via a web interface and a mobile application. Using a low-cost wireless sensor network, environment data on greenhouse are sent to the centralized server. It will store all this data and show the latest environment details of the greenhouse using the web interface. The web interface will provide a real-time graphical display of data using charts and gauges and ability to send control decisions to the central node which is necessary to increase harvest and improve the quality of crops.",
            "authors": [
                "Supun Athukorala",
                "Irunika Weeraratne",
                "Dumindu Jayathilaka",
                "Asitha Bandaranayake",
                "Roshan Ragel"
            ],
            "doi": "https://doi.org/10.1109/MIES.2016.7780261",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Servers",
                "Greenhouses",
                "Sensor systems",
                "Relays",
                "Monitoring",
                "Sensor phenomena and characterization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MIES.2016.7780261/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MIES.2016.7780261/index.json"
        }
    ],
    "Sensors": [
        {
            "title": "Design and implementation of a statechart based reconfigurable elevator controller",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "This paper presents a simple and clear method to design and implement a reconfigurable elevator controller using an FPGA, which can be implemented for an elevator with any (N) number of floors, with specified inputs and outputs. A model based design approach was followed. We started from a state chart model developed for a prototype elevator with three floors. Extension of the model for a variable number of floors was considered. Controller for the prototype system was implemented in ladder logic on a PLC and the limitations of that approach with regard to re-configurability were identified: viz., in the extension of elevator controller for `N' no of floors. Next VHDL code was developed for a reconfigurable elevator controller where, by changing a variable corresponding to the required number of floors, the suitable code can be generated. The controller thus generated can be implemented in an FPGA. The method was successfully tested on a Xilinx Spartan 3AN FPGA.",
            "authors": [
                "HPAP Jayawardana",
                "HWKM Amarasekara",
                "PTS Peelikumbura",
                "WAKC Jayathilaka",
                "SG Abeyaratne",
                "SD Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038093",
            "preprint": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "pdf": "https://d1wqtxts1xzle7.cloudfront.net/50495911/Statechart_Based_Modeling_and_Controller20161123-13291-x6486x-with-cover-page-v2.pdf?Expires=1655316738&Signature=J87I1-hyT7c4dZMcZFbVzExNgXZan8pPdpf-tAbTr80ahZDXcN~FV3gELQzG0thDbQQzIWw8NO7EXdXyX8QOacT1vJF5k04SF7MiO~Hl5H9A22rQ92fq-zua3GQrPRZUcJw629dQfP7Nbxn8tks6AGF6Z3fkFkLMeOpVqI2yHydXmCL5kHYOwKTiMYMS-eJ~OI3JQ18eVsSvJ530OxjoFisczkUiU-ZxqohOWx00L~JgJCvLZxAwtrPpxvA8ROEOx2VA7xCFgfINIqFIuMTVMz7aghtL0oOuEFrJovRbisPfrVL6aQx-Q9HdpP5CeZCDXcJTH2sh8FZr2nDLpuC5VQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Floors",
                "Field programmable gate arrays",
                "Prototypes",
                "Sensors",
                "Mathematical model",
                "Control systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038093/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038093/index.json"
        }
    ],
    "Serial architectures": [
        {
            "title": "DRMA: dynamically reconfigurable MPSoC architecture",
            "venue": "GLSVLSI '13: Proceedings of the 23rd ACM international conference on Great lakes symposium on VLSI",
            "year": "2013",
            "abstract": "Embedded systems are ubiquitous and are deployed in a large range of applications. Designing and fabricating Integrated Circuits (ICs) targeting such different range of applications is expensive. Designers seek flexible processors which efficiently execute a multitude of applications. FPGAs are considered affordable, but design cost, high reconfiguration delay and power consumption are all prohibitive. In this paper, we propose a novel ASIC based flexible MPSoC architecture, which can execute separate tasks in parallel, and it can be configured to execute single task with wide data widths or execute multiple tasks with varying data widths. The architecture presented, called Dynamically Reconfigurable MPSoC Architecture (DRMA), can be rapidly reconfigured through instructions. We present applications as case studies to showcase the flexibility and efficacy of DRMA. Results show for an additional area overhead of about 5%, the system is capable of working as four 32-bit processors, a single 128 bit processor or as a pipelined processing system.",
            "authors": [
                "Lawrance Zhang",
                "Jude Angelo Ambrose",
                "Jorgen Peddersen",
                "Sri Parameswaran",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Kewal K. Saluja"
            ],
            "doi": "https://doi.org/10.1145/2483028.2483101",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Computer systems organization",
                "Architectures",
                "Serial architectures",
                "Pipeline computing",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2483028.2483101/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2483028.2483101/index.json"
        }
    ],
    "Servers": [
        {
            "title": "Affordable real-time environment monitoring system for greenhouses",
            "venue": "2016 Manufacturing & Industrial Engineering Symposium (MIES)",
            "year": "2016",
            "abstract": "Greenhouse has been the best alternative solution to get a better crop production compared to the traditional agricultural industry. Greenhouses are used to increase harvest by controlling key factors which will aect the planet growth. Real-time monitoring of the greenhouse environment and taking necessary control decisions will result in improvement of yields and economic performance. In this Research paper, we propose an environmental monitoring and controlling system that have the ability to collect the information related to greenhouse environment using various sensors. This system provides the ability to monitor and control the greenhouse remotely via a web interface and a mobile application. Using a low-cost wireless sensor network, environment data on greenhouse are sent to the centralized server. It will store all this data and show the latest environment details of the greenhouse using the web interface. The web interface will provide a real-time graphical display of data using charts and gauges and ability to send control decisions to the central node which is necessary to increase harvest and improve the quality of crops.",
            "authors": [
                "Supun Athukorala",
                "Irunika Weeraratne",
                "Dumindu Jayathilaka",
                "Asitha Bandaranayake",
                "Roshan Ragel"
            ],
            "doi": "https://doi.org/10.1109/MIES.2016.7780261",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Servers",
                "Greenhouses",
                "Sensor systems",
                "Relays",
                "Monitoring",
                "Sensor phenomena and characterization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MIES.2016.7780261/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MIES.2016.7780261/index.json"
        }
    ],
    "Signal alignment": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Skeleton": [
        {
            "title": "Visual Design Platform for Wireless Sensor Network",
            "venue": "2018 Moratuwa Engineering Research Conference (MERCon)",
            "year": "2018",
            "abstract": "Wireless Sensor Networks (WSN) are being widely used for sensing physical parameters in a broad geographical area. The person who needs WSN will have a pictorial idea of the sensor network. The problem in the traditional method is that the person who needs the WSN should explain the pictorial view of the sensor network to a commercial vendor and buy it from them or they should design it from the scratch. What we proposed in our solution is to develop a platform so that the person who needs the WSN can directly draw the pictorial view on a canvas and then it can automatically generate all the required firmware for the microcontrollers and wiring diagrams. The user is then required only to follow a few instructions to complete the real world implementation of WSNs. This paper is about developing a visual platform to design WSNs. The WSN designing platform was built as a web application, so it can manage a large number of supported sensors and microcontrollers. This means that if one user adds the device driver for any sensor or a microcontroller the other users can directly use it from the WSN design platform without worrying about hardware programming. Further, if anyone needs a new sensor or microcontroller to be supported by this visual design platform, this design tool will have interfaces to directly add new sensors and microcontrollers. The proposed method is affordable for developing custom wireless sensor networks.",
            "authors": [
                "Rosen Silva",
                "Asela Dasanayaka",
                "Roshan Ragel",
                "Asitha Bandaranayake"
            ],
            "doi": "https://doi.org/10.1109/MERCon.2018.8421896",
            "preprint": "https://www.researchgate.net/profile/Asitha-Bandaranayake-3/publication/327517623_Visual_Design_Platform_for_Wireless_Sensor_Network/links/5f98da03458515b7cfa4013c/Visual-Design-Platform-for-Wireless-Sensor-Network.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Wireless sensor networks",
                "Microcontrollers",
                "Databases",
                "Skeleton",
                "Visualization",
                "Hardware",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon.2018.8421896/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon.2018.8421896/index.json"
        }
    ],
    "Sleep apnea": [
        {
            "title": "Non-contact Infant Sleep Apnea Detection",
            "venue": "IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2019",
            "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for the detection of sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
            "authors": [
                "Gihan Jayatilaka",
                "Harshana Weligampola",
                "Suren Sritharan",
                "Pankayaraj Pathmanathan",
                "Roshan Ragel",
                "Isuru Nawinne"
            ],
            "doi": "https://doi.org/10.1109/ICIIS47346.2019.9063269",
            "preprint": "https://arxiv.org/pdf/1910.04725.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering",
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Sleep apnea",
                "Video processing",
                "Bio medical engineering",
                "Pattern recognition"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS47346.2019.9063269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS47346.2019.9063269/index.json"
        }
    ],
    "SoC": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Software": [
        {
            "title": "Tile optimization for area in FPGA based hardware acceleration of peptide identification",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Advances in life sciences over the last few decades have lead to the generation of a huge amount of biological data. Computing research has become a vital part in driving biological discovery where analysis and categorization of biological data are involved. String matching algorithms can be applied for protein/gene sequence matching and with the phenomenal increase in the size of string databases to be analyzed, software implementations of these algorithms seems to have hit a hard limit and hardware acceleration is increasingly being sought. Several hardware platforms such as Field Programmable Gate Arrays (FPGA), Graphics Processing Units (GPU) and Chip Multi Processors (CMP) are being explored as hardware platforms. In this paper, we give a comprehensive overview of the literature on hardware acceleration of string matching algorithms, we take an FPGA hardware exploration and expedite the design time by a design automation technique. Further, our design automation is also optimized for better hardware utilization through optimizing the number of peptides that can be represented in an FPGA tile. The results indicate significant improvements in design time and hardware utilization which are reported in this paper.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "Roshan G Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038056",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7296.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Peptides",
                "Field programmable gate arrays",
                "Tiles",
                "Hardware",
                "Software algorithms",
                "Proteins",
                "Software"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038056/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038056/index.json"
        },
        {
            "title": "Statechart based modeling and controller implementation of complex reactive systems",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Statechart formalism has been a preferred choice for modeling complex reactive systems (CRS) in recent years. It has inbuilt powerful features of orthogonality, hierarchy, intermodular communication and history. Once statechart based system modeling is done the next issues to be addressed are (1) modular verification of the system for failsafe operation under all possible working conditions (2) progressive controller implementation together with the supervisory control while maintaining traceability and re-configurability and (3) facilitation of controller adaptation for progressive incorporation of security features and supervisory specifications. An elevator system was designed and built to reflect exigencies of a typical CRS hardware/software platform. A controller was designed to meet the above requirements and tested on the platform to validate the feasibility of model-based control design/verification methodology for real scale systems. Modularity was achieved by developing the statechart model of the plant into a tree of communicating language generators. Progresively verified modules were then translated into sequential function charts (SFC) which were finally integrated to form a complete flat SFC. The SFC was then implemented on a PLC platform (Telemechanique). The program was first validated in simulation using Telemechanique \u00e2\u0080\u009cTwidosuite\u00e2\u0080\u009d for different operating conditions and finally tested on the elevator system.",
            "authors": [
                "AC Vidanapathirana",
                "SD Dewasurendra",
                "SG Abeyratne"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038120",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Elevators",
                "Generators",
                "Software",
                "Automata",
                "Process control",
                "Floors",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038120/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038120/index.json"
        },
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        },
        {
            "title": "A structured hardware software architecture for peptide based diagnosis \u00e2\u0080\u0094 Sub-string matching problem with limited tolerance",
            "venue": "2014 7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "S. Devapriya Dewasurendra",
                "Roshan G. Ragel",
                "Mahesan Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069624",
            "preprint": "https://arxiv.org/pdf/1412.7811",
            "pdf": "https://arxiv.org/pdf/1412.7811",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Amino acids",
                "Software",
                "Automata",
                "Databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069624/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069624/index.json"
        },
        {
            "title": "Offloading specific performance-related kernel functions into an FPGA",
            "venue": "2021 IEEE 30th International Symposium on Industrial Electronics (ISIE)",
            "year": "2021",
            "abstract": "Today's network transactions are usually handled using kernel-based network protocols residing on general-purpose processors (GPPs). Over time, network transmission speeds have developed rapidly without a corresponding increase in processing speeds of host processors. With devices featuring advanced connectivity and Internet functionality, protocol processing has created a heavy workload on the GPP and has become a limiting factor in high performance networking applications such as online High Frequency Trading Systems (HFTS). It encourages designers to increase processor performance or designing application specific processors for handling heavy network workloads. Then there is the choice of hardware/software implementations based on results from hardware acceleration. Offloading the whole network protocol stack implementation into hardware is not very attractive since handling large linked data structures inside the hardware is not as easy as in software. In this paper we claim that relieving the CPU from bulk processing by offloading selected, performance-related kernel code into hardware is a better option for such scenarios. Hence, we design a scalable system for offloading specific performance-related kernel functions into an FPGA. In this paper we discuss the logic behind our new architecture and the results up to now.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S. Devapriya Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ISIE45552.2021.9576256",
            "preprint": "https://www.academia.edu/download/75534730/KF_003255_ISIE2021paper.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Performance evaluation",
                "Protocols",
                "Profitability",
                "Linux",
                "Computer architecture",
                "Software",
                "Security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ISIE45552.2021.9576256/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ISIE45552.2021.9576256/index.json"
        },
        {
            "title": "A Novel FPGA Architecture of Commentz-Walter Algorithm using Bit-Split String-Matching Engines",
            "venue": "2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)",
            "year": "2021",
            "abstract": "This paper describes a reconfigurable hardware implementation of CommentzWalter algorithm with bit-split string matching engines to match multiple protein sequences. It is reported that multiple pattern matching using the most widely used Aho-Corasick algorithm for different applications has been carried out on graphics processing units and field programmable gate arrays to accelerate the matching process. Commentz-Walter algorithm, is a multiple pattern matching algorithm and more complex than Aho-Corasick. There are no reports of it being directly implemented in any hardware platform except as software implementations on general purpose processors. In this work, a specific architecture for our target application using CommentzWalter algorithm has been developed and tested with a simulator for hardware description languages. This architecture can match multiple patterns of proteins efficiently when implemented on a Field Programmable Gate Array. Finally, we compare a previously developed hardware architecture of bit-split Aho-Corasick with our bit-split Commentz-Walter architecture. Using the Intel Stratix IV GX EP4SGX230KF40C2 FPGA chip as the target device, the compilation results with Quartus II show that the synthesis logic utilization is 5% with 2203 total number of registers, 64896 FPGA block memory bits and 4 DSP block 18-bit elements. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the Commentz-Walter algorithm.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "Shirley D. Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICter53630.2021.9774805",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Software algorithms",
                "Computer architecture",
                "Logic gates",
                "Hardware",
                "Software",
                "Registers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICter53630.2021.9774805/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICter53630.2021.9774805/index.json"
        },
        {
            "title": "Constant time encryption as a countermeasure against remote cache timing attacks",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Rijndael was standardized in 2001 by National Institute of Standard and Technology as the Advanced Encryption Standard (AES). AES is still being used to encrypt financial, military and even government confidential data. In 2005, Bernstein illustrated a remote cache timing attack on AES using the client-server architecture and therefore proved a side channel in its software implementation. Over the years, a number of countermeasures have been proposed against cache timing attacks both using hardware and software. Although the software based countermeasures are flexible and easy to deploy, most of such countermeasures are vulnerable to statistical analysis. In this paper, we propose a novel software based countermeasure against cache timing attacks, known as constant time encryption, which we believe is secure against statistical analysis. The countermeasure we proposed performs rescheduling of instructions such that the encryption rounds will consume constant time independent of the cache hits and misses. Through experiments, we prove that our countermeasure is secure against Bernstein's cache timing attack.",
            "authors": [
                "Darshana Jayasinghe",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419893",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7293.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Encryption",
                "Timing",
                "Software",
                "Hardware",
                "Clocks",
                "Computers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419893/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419893/index.json"
        }
    ],
    "Software algorithms": [
        {
            "title": "Tile optimization for area in FPGA based hardware acceleration of peptide identification",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Advances in life sciences over the last few decades have lead to the generation of a huge amount of biological data. Computing research has become a vital part in driving biological discovery where analysis and categorization of biological data are involved. String matching algorithms can be applied for protein/gene sequence matching and with the phenomenal increase in the size of string databases to be analyzed, software implementations of these algorithms seems to have hit a hard limit and hardware acceleration is increasingly being sought. Several hardware platforms such as Field Programmable Gate Arrays (FPGA), Graphics Processing Units (GPU) and Chip Multi Processors (CMP) are being explored as hardware platforms. In this paper, we give a comprehensive overview of the literature on hardware acceleration of string matching algorithms, we take an FPGA hardware exploration and expedite the design time by a design automation technique. Further, our design automation is also optimized for better hardware utilization through optimizing the number of peptides that can be represented in an FPGA tile. The results indicate significant improvements in design time and hardware utilization which are reported in this paper.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "Roshan G Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038056",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7296.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Peptides",
                "Field programmable gate arrays",
                "Tiles",
                "Hardware",
                "Software algorithms",
                "Proteins",
                "Software"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038056/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038056/index.json"
        },
        {
            "title": "Hardware software co-design of the Aho-Corasick algorithm: Scalable for protein identification?",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Pattern matching is commonly required in many application areas and bioinformatics is a major area of interest that requires both exact and approximate pattern matching. Much work has been done in this area, yet there is still a significant space for improvement in efficiency, flexibility, and throughput. This paper presents a hardware software co-design of Aho-Corasick algorithm in Nios II soft-processor and a study on its scalability for a pattern matching application. A software only approach is used to compare the throughput and the scalability of the hardware software co-design approach. According to the results we obtained, we conclude that the hardware software co-design implementation shows a maximum of 10 times speed up for pattern size of 1200 peptides compared to the software only implementation. The results also show that the hardware software co-design approach scales well for increasing data size compared to the software only approach.",
            "authors": [
                "S.M. Vidanagamachchi",
                "S.D. Dewasurendra",
                "",
                "R.G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732003",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.1317.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Proteins",
                "Peptides",
                "Software algorithms",
                "Program processors",
                "Algorithm design and analysis"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732003/index.json"
        },
        {
            "title": "A Novel FPGA Architecture of Commentz-Walter Algorithm using Bit-Split String-Matching Engines",
            "venue": "2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)",
            "year": "2021",
            "abstract": "This paper describes a reconfigurable hardware implementation of CommentzWalter algorithm with bit-split string matching engines to match multiple protein sequences. It is reported that multiple pattern matching using the most widely used Aho-Corasick algorithm for different applications has been carried out on graphics processing units and field programmable gate arrays to accelerate the matching process. Commentz-Walter algorithm, is a multiple pattern matching algorithm and more complex than Aho-Corasick. There are no reports of it being directly implemented in any hardware platform except as software implementations on general purpose processors. In this work, a specific architecture for our target application using CommentzWalter algorithm has been developed and tested with a simulator for hardware description languages. This architecture can match multiple patterns of proteins efficiently when implemented on a Field Programmable Gate Array. Finally, we compare a previously developed hardware architecture of bit-split Aho-Corasick with our bit-split Commentz-Walter architecture. Using the Intel Stratix IV GX EP4SGX230KF40C2 FPGA chip as the target device, the compilation results with Quartus II show that the synthesis logic utilization is 5% with 2203 total number of registers, 64896 FPGA block memory bits and 4 DSP block 18-bit elements. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the Commentz-Walter algorithm.",
            "authors": [
                "Sugandima M. Vidanagamachchi",
                "Shirley D. Dewasurendra"
            ],
            "doi": "https://doi.org/10.1109/ICter53630.2021.9774805",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Software algorithms",
                "Computer architecture",
                "Logic gates",
                "Hardware",
                "Software",
                "Registers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICter53630.2021.9774805/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICter53630.2021.9774805/index.json"
        },
        {
            "title": "To use or not to use: Graphics processing units (GPUs) for pattern matching algorithms",
            "venue": "7th International Conference on Information and Automation for Sustainability",
            "year": "2014",
            "abstract": "String matching is an important part in today's computer applications and Aho-Corasick algorithm is one of the main string matching algorithms used to accomplish this. This paper discusses that when can the GPUs be used for string matching applications using the Aho-Corasick algorithm as a benchmark We have to identify the best unit to run our string matching algorithm according to the performance of our devices and the applications. Sometimes CPU gives better performance than GPU and sometimes GPU gives better performance than CPU. Therefore, identifying this critical point is significant task for researchers who are using GPUs to improve the performance of their string matching applications based on string matching algorithms.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2014.7069585",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms/links/54e48fc30cf2dbf60696ea10/To-Use-or-Not-to-Use-Graphics-Processing-Units-for-Pattern-Matching-Algorithms.pdf",
            "pdf": "https://ieeexplore.ieee.org/abstract/document/7069585",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Graphics processing units",
                "Central Processing Unit",
                "Pattern matching",
                "Parallel processing",
                "Algorithm design and analysis",
                "Performance evaluation",
                "Software algorithms"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2014.7069585/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2014.7069585/index.json"
        }
    ],
    "Space exploration": [
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        }
    ],
    "Sports equipment": [
        {
            "title": " Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
            "authors": [
                "Pranavan Somaskandhan",
                "Gihan Wijesinghe",
                "Leshan Bashitha Wijegunawardana",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300399",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Sports equipment",
                "Data mining",
                "Measurement",
                "Support vector machines",
                "Statistical analysis",
                "Games",
                "Relational databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300399/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300399/index.json"
        }
    ],
    "Standards": [
        {
            "title": "A Study on Instruction-set Selection Using Multi-application Based Application Specific Instruction-set Processors",
            "venue": "2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems",
            "year": "2013",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analyzing the instructions for inter-domain and intra-domain designs. Metrics analyzed are the reusable instructions and the extra cost to add a certain application, together with the hardware synthesis numbers, such as area, timing and delay. A wide range of applications from various application benchmarks (BioPerf, CommBench, MediaBench, MiBench and SPEC2006) and domains are analyzed for three different architectures (LEON2, PISA and ARM-Thumb). Processors are generated for these architectures for different configurations to analyze and synthesize. Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless the kind of architecture (and therefore the ISA).",
            "authors": [
                "Roshan G. Ragel",
                "Swarnalatha Radhakrishnan",
                "Jude Angelo Ambrose",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/VLSID.2013.154",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/261501995_A_Study_on_Instruction-set_Selection_Using_Multi-application_Based_Application_Specific_Instruction-set_Processors/links/54e48faf0cf2dbf60696e9b4/A-Study-on-Instruction-set-Selection-Using-Multi-application-Based-Application-Specific-Instruction-set-Processors.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Thumb",
                "Embedded systems",
                "Benchmark testing",
                "Standards",
                "Instruction sets"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/VLSID.2013.154/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/VLSID.2013.154/index.json"
        }
    ],
    "Statistical analysis": [
        {
            "title": " Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
            "authors": [
                "Pranavan Somaskandhan",
                "Gihan Wijesinghe",
                "Leshan Bashitha Wijegunawardana",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300399",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Sports equipment",
                "Data mining",
                "Measurement",
                "Support vector machines",
                "Statistical analysis",
                "Games",
                "Relational databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300399/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300399/index.json"
        },
        {
            "title": "Data Mining System for Predicting a Winning Cricket Team",
            "venue": "2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2021",
            "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u00e2\u0080\u0099 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
            "authors": [
                "Dinithi Hasanika",
                "Roshani Dilhara",
                "Dulanjali Liyanage",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Uncertainty",
                "Statistical analysis",
                "Conferences",
                "Games",
                "Machine learning",
                "Data mining",
                "Australia"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS53135.2021.9660702/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS53135.2021.9660702/index.json"
        }
    ],
    "Steganography": [
        {
            "title": "Loop unrolling in multi-pipeline ASIP design",
            "venue": "2009 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2009",
            "abstract": "Application Specific Instruction-set Processor (ASIP) is one of the popular processor design techniques for embedded systems which allow customizability in processor design without overly hindering design flexibility. Multi-pipeline ASIPs were proposed to improve the performance of such systems by compromising between speed and processor area. One of the problems in the multi-pipeline design is the limited inherent instruction level parallelism (ILP) available in applications. The ILP of application programs can be improved via a compiler optimization technique known as loop unrolling. In this paper, we present the impact of loop unrolling on the performance (speed) of multi-pipeline ASIPs. The improvement in speed averages around 15% for a number of benchmark applications with the maximum improvement of around 30%. In addition, we report the variation of performance against the loop unrolling factor - the amount of unrolling performed on an application.",
            "authors": [
                "HMRDB Navarathna",
                "Swarnalatha Radhakrishnan",
                "Roshan G Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2009.5429845",
            "preprint": "https://arxiv.org/pdf/1402.0671",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Application specific processors",
                "Authentication",
                "Computer science",
                "Steganography",
                "Image analysis",
                "Algorithm design and analysis",
                "Computer industry",
                "Information systems",
                "Postal services",
                "Entropy"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2009.5429845/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2009.5429845/index.json"
        }
    ],
    "Streaming media": [
        {
            "title": "Heterogeneous processor pipeline for a product cipher application",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "Processing data received as a stream is a task commonly performed by modern embedded devices, in a wide range of applications such as multimedia (encoding/decoding/ playing media), networking (switching and routing), digital security, scientific data processing, etc. Such processing normally tends to be calculation intensive and therefore requiring significant processing power. Therefore, hardware acceleration methods to increase the performance of such applications constitute an important area of study. In this paper, we present an evaluation of one such method to process streaming data, namely multi-processor pipeline architecture. The hardware is based on a Multiple-Processor System on Chip (MPSoC), using a data encryption algorithm as a case study. The algorithm is partitioned on a coarse grained level and mapped on to an MPSoC with five processor cores in a pipeline, using specifically configured Xtensa LX3 cores. The system is then selectively optimized by strengthening and pruning the resources of each processor core. The optimized system is evaluated and compared against an optimal single-processor System on Chip (SoC) for the same application. The multiple-processor pipeline system for data encryption algorithms used was observed to provide significant speed ups, up to 4.45 times that of the single-processor system, which is close to the ideal speed up from a five-stage pipeline.",
            "authors": [
                "Isuru B. Nawinne",
                "Mahanama S. Wickramasinghe",
                "Roshan G. Ragel",
                "Member",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038036",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7299.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Pipelines",
                "Encryption",
                "Algorithm design and analysis",
                "Partitioning algorithms",
                "Streaming media",
                "Computer architecture"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038036/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038036/index.json"
        }
    ],
    "Support vector machines": [
        {
            "title": " Identifying the optimal set of attributes that impose high impact on the end results of a cricket match using machine learning",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Indian Premier League (IPL) is a franchise system based, annual cricket tournament. IPL deals with millions of dollars. The amount of money spent on the IPL teams imposes high pressure on owners to search victories, which depends on team performance. Essentially, it is critical to find the right set of metrics that would lead to assemble a team with the highest chance of winning. This study attempts to identify the optimal set of attributes, which impose the high impact on the results of a cricket match. Determining an optimal set of attributes will help team owners to look for players with these attributes to form a team by which they can enhance the winnability of a cricket team. Several efforts have already been taken to address this problem without much success. Most of the existing works focused on identifying different performance metrics based on their domain knowledge of cricket. The proposed solution relies on statistical analysis and machine learning while minimizing the use of domain knowledge. Ball by ball data for all past IPL matches were collected, aggregated to innings level details for the analysis and the problem is modeled as a classification problem. The data set contained a set of features based on the innings level data and win/lose/draw class labels. Different machine learning algorithms were employed, and Support Vector Machine (SVM) achieved the best accuracy in the evaluation. Then, we examined all possible feature combinations using SVM by using separate training and testing sets. Finally, the attribute set that yields the highest accuracy in the evaluation is identified, which will be the optimal set of attributes that impose the high impact on the end results of a cricket match.",
            "authors": [
                "Pranavan Somaskandhan",
                "Gihan Wijesinghe",
                "Leshan Bashitha Wijegunawardana",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300399",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Sports equipment",
                "Data mining",
                "Measurement",
                "Support vector machines",
                "Statistical analysis",
                "Games",
                "Relational databases"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300399/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300399/index.json"
        }
    ],
    "Synthetic aperture sonar": [
        {
            "title": "SAS-3: A polynomial based strong password authentication protocol",
            "venue": "2007 International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2007",
            "abstract": "As the Internet and mobile applications have been increasing in the recent past, the need for authentication over remote servers and telephones have become very important. The need of authentication is essential as the private data sent over the Internet has risk of being wiretapped. Existing password authentication schemes can be divided into two types, one that requires only the weak password and the other that requires the strong password. The main objective of this paper is to present a review on the strong password protocols and propose a new protocol with enhanced security features. In addition, we have proved that our SAS-3 (simple and secure) protocol is secure against replay, denial of service, impersonation and password guessing attacks with minimized computational and transmission overheads.",
            "authors": [
                "N. S. Weragama",
                "M. Sandirigama"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2007.4579145",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Polynomials",
                "Authentication",
                "Protocols",
                "Computer crime",
                "Synthetic aperture sonar",
                "Information systems",
                "Internet",
                "Security",
                "Computer industry",
                "Mobile communication"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2007.4579145/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2007.4579145/index.json"
        }
    ],
    "Testing": [
        {
            "title": "Model in the loop testing of complex reactive systems",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Currently there is a new trend in the design of Complex Reactive Systems (CRS) towards model based development. Software components are no longer hard written in C or Assembler code but modeled with MATLAB/Simulink, Statemate or similar tools. Model based designs allow development of high level models that can be used for simulations in very early stages of the design process. However the quality assurance of model based developments, specially testing is still poorly supported [1]. In this paper we discuss the characteristics of model based design process and the need of quality assurance methods throughout the design process. We have selected a fully functional prototype passenger elevator as the CRS. A model based design approach is followed throughout the design phase. Model-in-the loop (MiL) testing is carried out as the quality assurance technique and the results are presented. Then the translation of the MiL test into a Hardware-in the-loop (HiL) test is presented.",
            "authors": [
                "A. Vidanapathirana",
                "S. D. Dewasurendra",
                "S. G. Abeyaratne"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6731950",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Mathematical model",
                "Induction motors",
                "Testing",
                "MATLAB",
                "Elevators",
                "Floors"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6731950/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6731950/index.json"
        },
        {
            "title": "To use or not to use: CPUs' cache optimization techniques on GPGPUs",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU's best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946534",
            "preprint": "https://arxiv.org/pdf/1810.04063",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Arrays",
                "Optimization",
                "Merging",
                "Cache memory",
                "Testing",
                "Kernel",
                "Throughput"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946534/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946534/index.json"
        }
    ],
    "Throughput": [
        {
            "title": "To use or not to use: CPUs' cache optimization techniques on GPGPUs",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "General Purpose Graphic Processing Unit(GPGPU) is used widely for achieving high performance or high throughput in parallel programming. This capability of GPGPUs is very famous in the new era and mostly used for scientific computing which requires more processing power than normal personal computers. Therefore, most of the programmers, researchers and industry use this new concept for their work. However, achieving high-performance or high-throughput using GPGPUs are not an easy task compared with conventional programming concepts in the CPU side. In this research, the CPUs cache memory optimization techniques have been adopted to the GPGPUs cache memory to identify rare performance improvement techniques compared to GPGPU's best practices. The cache optimization techniques of blocking, loop fusion, array merging and array transpose were tested on GPGPUs for finding suitability of these techniques. Finally, we identified that some of the CPU cache optimization techniques go well with the cache memory system of the GPGPU and shows performance improvements while some others show the opposite effect on the GPGPUs compared with the CPUs.",
            "authors": [
                "DRVLB Thambawita",
                "Roshan G Ragel",
                "Dhammike Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946534",
            "preprint": "https://arxiv.org/pdf/1810.04063",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Arrays",
                "Optimization",
                "Merging",
                "Cache memory",
                "Testing",
                "Kernel",
                "Throughput"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946534/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946534/index.json"
        }
    ],
    "Thumb": [
        {
            "title": "A Study on Instruction-set Selection Using Multi-application Based Application Specific Instruction-set Processors",
            "venue": "2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems",
            "year": "2013",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analyzing the instructions for inter-domain and intra-domain designs. Metrics analyzed are the reusable instructions and the extra cost to add a certain application, together with the hardware synthesis numbers, such as area, timing and delay. A wide range of applications from various application benchmarks (BioPerf, CommBench, MediaBench, MiBench and SPEC2006) and domains are analyzed for three different architectures (LEON2, PISA and ARM-Thumb). Processors are generated for these architectures for different configurations to analyze and synthesize. Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless the kind of architecture (and therefore the ISA).",
            "authors": [
                "Roshan G. Ragel",
                "Swarnalatha Radhakrishnan",
                "Jude Angelo Ambrose",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/VLSID.2013.154",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/261501995_A_Study_on_Instruction-set_Selection_Using_Multi-application_Based_Application_Specific_Instruction-set_Processors/links/54e48faf0cf2dbf60696e9b4/A-Study-on-Instruction-set-Selection-Using-Multi-application-Based-Application-Specific-Instruction-set-Processors.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Thumb",
                "Embedded systems",
                "Benchmark testing",
                "Standards",
                "Instruction sets"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/VLSID.2013.154/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/VLSID.2013.154/index.json"
        }
    ],
    "Tiles": [
        {
            "title": "Tile optimization for area in FPGA based hardware acceleration of peptide identification",
            "venue": "2011 6th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2011",
            "abstract": "Advances in life sciences over the last few decades have lead to the generation of a huge amount of biological data. Computing research has become a vital part in driving biological discovery where analysis and categorization of biological data are involved. String matching algorithms can be applied for protein/gene sequence matching and with the phenomenal increase in the size of string databases to be analyzed, software implementations of these algorithms seems to have hit a hard limit and hardware acceleration is increasingly being sought. Several hardware platforms such as Field Programmable Gate Arrays (FPGA), Graphics Processing Units (GPU) and Chip Multi Processors (CMP) are being explored as hardware platforms. In this paper, we give a comprehensive overview of the literature on hardware acceleration of string matching algorithms, we take an FPGA hardware exploration and expedite the design time by a design automation technique. Further, our design automation is also optimized for better hardware utilization through optimizing the number of peptides that can be represented in an FPGA tile. The results indicate significant improvements in design time and hardware utilization which are reported in this paper.",
            "authors": [
                "SM Vidanagamachchi",
                "SD Dewasurendra",
                "Roshan G Ragel",
                "M Niranjan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038056",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7296.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Peptides",
                "Field programmable gate arrays",
                "Tiles",
                "Hardware",
                "Software algorithms",
                "Proteins",
                "Software"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038056/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038056/index.json"
        },
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        }
    ],
    "Time factors": [
        {
            "title": "CSER: HW/SW configurable soft-error resiliency for application specific instruction-set processors",
            "venue": "2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)",
            "year": "2013",
            "abstract": "Soft error has been identified as one of the major challenges to CMOS technology based computing systems. To mitigate this problem, error recovery is a key component, which usually accounts for a substantial cost, since they must introduce redundancies in either time or space. Consequently, using state-of-art recovery techniques could heavily worsen the design constraint, which is fairly stringent for embedded system design. In this paper, we propose a HW/SW methodology that generates the processor, which performs finely configured error recovery functionality targeting the given design constraints (e.g., performance, area and power). Our methodology employs three application-specific optimization heuristics, which generate the optimized composition and configuration based on the two primitive error recovery techniques. The resultant processor is composed of selected primitive techniques at corresponding instruction execution, and configured to perform error recovery at run-time accordingly to the scheme determined at design time. The experiment results have shown that our methodology can at best achieve nine times reliability while maintaining the given constraints, in comparison to the state of the art.",
            "authors": [
                "Tuo Li",
                "Muhammad Shafique",
                "Semeen Rehman",
                "Swarnalatha Radhakrishnan",
                "Roshan Ragel",
                "Jude Angelo Ambrose",
                "J\u00c3\u00b6rg Henkel",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.7873/DATE.2013.152",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Redundancy",
                "Time factors",
                "Runtime",
                "Integrated circuits",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7873/DATE.2013.152/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7873/DATE.2013.152/index.json"
        }
    ],
    "Timing": [
        {
            "title": "Constant time encryption as a countermeasure against remote cache timing attacks",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Rijndael was standardized in 2001 by National Institute of Standard and Technology as the Advanced Encryption Standard (AES). AES is still being used to encrypt financial, military and even government confidential data. In 2005, Bernstein illustrated a remote cache timing attack on AES using the client-server architecture and therefore proved a side channel in its software implementation. Over the years, a number of countermeasures have been proposed against cache timing attacks both using hardware and software. Although the software based countermeasures are flexible and easy to deploy, most of such countermeasures are vulnerable to statistical analysis. In this paper, we propose a novel software based countermeasure against cache timing attacks, known as constant time encryption, which we believe is secure against statistical analysis. The countermeasure we proposed performs rescheduling of instructions such that the encryption rounds will consume constant time independent of the cache hits and misses. Through experiments, we prove that our countermeasure is secure against Bernstein's cache timing attack.",
            "authors": [
                "Darshana Jayasinghe",
                "Roshan Ragel",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419893",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.7293.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Encryption",
                "Timing",
                "Software",
                "Hardware",
                "Clocks",
                "Computers"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419893/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419893/index.json"
        }
    ],
    "Transform coding": [
        {
            "title": "Instruction-set selection for multi-application based ASIP design: An instruction-level study",
            "venue": "2012 IEEE 6th International Conference on Information and Automation for Sustainability",
            "year": "2012",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analysing the instructions for inter-domain and intra-domain designs. Metrics analysed are the reusable instructions and the extra cost to add a certain application. A wide range of applications from various application benchmarks (MiBench, MediaBench and SPEC2006) and domains are analysed for two different architectures (ARM-Thumb and PISA). Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless of the architecture (and therefore the ISA).",
            "authors": [
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Angelo Ambrose"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2012.6419895",
            "preprint": "https://arxiv.org/pdf/1403.7291.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "GSM",
                "Engines",
                "Integrated circuits",
                "Transform coding"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2012.6419895/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2012.6419895/index.json"
        }
    ],
    "USA Councils": [
        {
            "title": "Using microkernel based virtualization for Byzantine fault tolerance",
            "venue": "2011 6th International Conference on Industrial and Information Systems",
            "year": "2011",
            "abstract": "A Byzantine fault is a failure that cannot be identified by observing the output of a component; the component produces a wrong result as opposed to not producing a result at all or producing a result that can be identified as wrong. Such faults may be caused by a number of causes including software bugs and malicious attacks. Tolerating such faults is essential for a critical system. Isolated replication and majority voting is a well established technique to tolerate Byzantine faults. Current implementations of such systems either uses replicated hardware or software virtualization-using virtual machine monitors-to get the illusion of hardware replication to tolerate Byzantine faults. In this paper, we investigate the possibility of using microkernel technology to achieve the isolated replication and discuss the features of a microkernel API suitable for such a deployment. The advantage of our approach is that it reduces the cost of additional hardware or avoid the complexity of virtualization required to mimic hardware replication. We used a single machine, running the L4 microkernel to provide the isolation required for the replicas. All replicas run in parallel and majority voting is performed to obtain the correct result in the presence of Byzantine faults. We selected the AES encryption algorithms for our case study and faults were deliberately injected to replicas to mimic Byzantine behavior. Our experiments show that it is feasible to use microkernels technology for this purpose.",
            "authors": [
                "Asanka Senevirathna",
                "Bhathiya Wasala",
                "Buddhika Ranaweera",
                "Dhammika Elkaduwe"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2011.6038037",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Kernel",
                "Computer bugs",
                "Information systems",
                "USA Councils",
                "Fault tolerant systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2011.6038037/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2011.6038037/index.json"
        }
    ],
    "Ubiquitous and mobile computing": [
        {
            "title": "DeepLight: Robust & Unobtrusive Real-time Screen-Camera Communication for Real-World Displays",
            "venue": "2021 20th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)",
            "year": "2021",
            "abstract": "The paper introduces a novel, holistic approach for robust Screen-Camera Communication (SCC), where video content on a screen is visually encoded in a human-imperceptible fashion and decoded by a camera capturing images of such screen content. We first show that state-of-the-art SCC techniques have two key limitations for in-the-wild deployment: (a) the decoding accuracy drops rapidly under even modest screen extraction errors from the captured images, and (b) they generate perceptible flickers on common refresh rate screens even with minimal modulation of pixel intensity. To overcome these challenges, we introduce DeepLight, a system that incorporates machine learning (ML) models in the decoding pipeline to achieve humanly-imperceptible, moderately high SCC rates under diverse real-world conditions. DeepLight's key innovation is the design of a Deep Neural Network (DNN) based decoder that collectively decodes all the bits spatially encoded in a display frame, without attempting to precisely isolate the pixels associated with each encoded bit. In addition, DeepLight supports imperceptible encoding by selectively modulating the intensity of only the Blue channel, and provides reasonably accurate screen extraction (IoU values \u00e2\u0089\u00a5 83%) by using state-of-the-art object detection DNN pipelines. We show that a fully functional DeepLight system is able to robustly achieve high decoding accuracy (frame error rate < 0.2) and moderately-high data goodput (\u00e2\u0089\u00a50.95 Kbps) using a human-held smartphone camera, even over larger screen-camera distances (~ 2m).",
            "authors": [
                "Vu Tran",
                "Gihan Jayatilaka",
                "Ashwin Ashok",
                "Archan Misra"
            ],
            "doi": "https://doi.org/10.1145/3412382.3458269",
            "preprint": "https://arxiv.org/pdf/2105.05092",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/deeplight/presentation.pdf",
            "project": "#",
            "codebase": "https://github.com/gihanjayatilaka/deeplight",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Human-centered computing",
                "Ubiquitous and mobile computing",
                "Computer systems organization",
                "Embedded and cyber-physical systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/3412382.3458269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/3412382.3458269/index.json"
        }
    ],
    "Uncertainty": [
        {
            "title": "Data Mining System for Predicting a Winning Cricket Team",
            "venue": "2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2021",
            "abstract": "Cricket is a two-team outdoor game that originated in England around the 19th century. This is played in 3 forms as twenty20, ODI, and Test matches. Due to the availability of data, researchers have been able to do statistical analysis of data for pattern recognition, to find factors affecting the game, and for outcome prediction. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model. The outcome model also depends on the number of overs, match type, time period, and player combination among many other factors. This research focuses only on the ODI matches that were played between ICC full members; Australia, West Indies, Sri Lanka, Bangladesh, New Zealand, Ireland, India, Zimbabwe, Afghanistan, England, South Africa, and Pakistan. This outcome prediction is based on players\u00e2\u0080\u0099 performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers, and fielders are analyzed separately considering all-time ODI data. The combined performance of batsmen and bowlers was analyzed, and compared with individual performances using statistical methods. Association rule mining was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we used data mining and machine learning techniques.",
            "authors": [
                "Dinithi Hasanika",
                "Roshani Dilhara",
                "Dulanjali Liyanage",
                "Asitha Bandaranayake",
                "Sampath Deegalla"
            ],
            "doi": "https://doi.org/10.1109/ICIIS53135.2021.9660702",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Uncertainty",
                "Statistical analysis",
                "Conferences",
                "Games",
                "Machine learning",
                "Data mining",
                "Australia"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS53135.2021.9660702/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS53135.2021.9660702/index.json"
        }
    ],
    "Video processing": [
        {
            "title": "Non-contact Infant Sleep Apnea Detection",
            "venue": "IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2019",
            "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for the detection of sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
            "authors": [
                "Gihan Jayatilaka",
                "Harshana Weligampola",
                "Suren Sritharan",
                "Pankayaraj Pathmanathan",
                "Roshan Ragel",
                "Isuru Nawinne"
            ],
            "doi": "https://doi.org/10.1109/ICIIS47346.2019.9063269",
            "preprint": "https://arxiv.org/pdf/1910.04725.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering",
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Sleep apnea",
                "Video processing",
                "Bio medical engineering",
                "Pattern recognition"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS47346.2019.9063269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS47346.2019.9063269/index.json"
        }
    ],
    "Visualization": [
        {
            "title": "Visual Design Platform for Wireless Sensor Network",
            "venue": "2018 Moratuwa Engineering Research Conference (MERCon)",
            "year": "2018",
            "abstract": "Wireless Sensor Networks (WSN) are being widely used for sensing physical parameters in a broad geographical area. The person who needs WSN will have a pictorial idea of the sensor network. The problem in the traditional method is that the person who needs the WSN should explain the pictorial view of the sensor network to a commercial vendor and buy it from them or they should design it from the scratch. What we proposed in our solution is to develop a platform so that the person who needs the WSN can directly draw the pictorial view on a canvas and then it can automatically generate all the required firmware for the microcontrollers and wiring diagrams. The user is then required only to follow a few instructions to complete the real world implementation of WSNs. This paper is about developing a visual platform to design WSNs. The WSN designing platform was built as a web application, so it can manage a large number of supported sensors and microcontrollers. This means that if one user adds the device driver for any sensor or a microcontroller the other users can directly use it from the WSN design platform without worrying about hardware programming. Further, if anyone needs a new sensor or microcontroller to be supported by this visual design platform, this design tool will have interfaces to directly add new sensors and microcontrollers. The proposed method is affordable for developing custom wireless sensor networks.",
            "authors": [
                "Rosen Silva",
                "Asela Dasanayaka",
                "Roshan Ragel",
                "Asitha Bandaranayake"
            ],
            "doi": "https://doi.org/10.1109/MERCon.2018.8421896",
            "preprint": "https://www.researchgate.net/profile/Asitha-Bandaranayake-3/publication/327517623_Visual_Design_Platform_for_Wireless_Sensor_Network/links/5f98da03458515b7cfa4013c/Visual-Design-Platform-for-Wireless-Sensor-Network.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Wireless sensor networks",
                "Microcontrollers",
                "Databases",
                "Skeleton",
                "Visualization",
                "Hardware",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon.2018.8421896/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon.2018.8421896/index.json"
        }
    ],
    "Web services": [
        {
            "title": "Axis2UNO: Web Services Enabled Openoffice.org",
            "venue": "2008 4th International Conference on Information and Automation for Sustainability",
            "year": "2008",
            "abstract": "Openoffice.org is a popular, free and open source office product. This product is used by millions of people and developed, maintained and extended by thousands of developers worldwide. Playing a dominant role in the Web, Web services technology is serving millions of people every day. Axis2 is one of the most popular, free and open source Web service engines. The framework presented in this paper, Axis2UNO, a combination of such two technologies is capable of making a new era in office environment. Two other attempts to enhance Web services functionality in office products are Excel Web services and UNO Web service proxy. Excel Web services is combined with Microsoft SharePoint technology and exposes information sharing in a different perspective within the proprietary Microsoft office products. UNO Web service proxy is implemented with Java Web services developer pack and enables basic Web services related functionality in Openoffice.org. However, the work presented here is the first one to combine Openoffice.org and Axis2 and we expect it to outperform the other efforts with the community involvement and feature richness in those products.",
            "authors": [
                "BANM Bambarasinghe",
                "HMS Huruggamuwa",
                "Roshan G Ragel",
                "Swarnalatha Radhakrishnan"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2008.4783956",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "pdf": "https://arxiv.org/ftp/arxiv/papers/1402/1402.0670.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Web services",
                "Search engines",
                "Computer networks",
                "Maintenance engineering",
                "Java",
                "Data security",
                "Packaging",
                "Office automation",
                "Information technology",
                "Resource management"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2008.4783956/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2008.4783956/index.json"
        }
    ],
    "Wind power generation": [
        {
            "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
            "authors": [
                "AH Wijethunge",
                "JV Wijekulasooriya",
                "Janaka B Ekanayake",
                "KB Samarakoon",
                "A Polpitiya"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300374",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Schedules",
                "Genetic algorithms",
                "Optimization",
                "Wind power generation",
                "Power demand",
                "Wind turbines",
                "Mathematical model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300374/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300374/index.json"
        }
    ],
    "Wind turbines": [
        {
            "title": "Genetic algorithm based cost optimization to integrate a community based wind turbine while considering smart appliances scheduling",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "A coordinated approach capable of optimal scheduling of the responsive residential appliances to minimize the total cost of a community based scheme comprises a wind farm is suggested in this study. Here demand side loads are managed by optimizing smart appliances' operating time to minimize the cost to the community using a genetic algorithm based method. The cost optimization is obtained for different test cases using the algorithm implemented and results are discussed.",
            "authors": [
                "AH Wijethunge",
                "JV Wijekulasooriya",
                "Janaka B Ekanayake",
                "KB Samarakoon",
                "A Polpitiya"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300374",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Schedules",
                "Genetic algorithms",
                "Optimization",
                "Wind power generation",
                "Power demand",
                "Wind turbines",
                "Mathematical model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300374/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300374/index.json"
        }
    ],
    "Wireless sensor networks": [
        {
            "title": "Visual Design Platform for Wireless Sensor Network",
            "venue": "2018 Moratuwa Engineering Research Conference (MERCon)",
            "year": "2018",
            "abstract": "Wireless Sensor Networks (WSN) are being widely used for sensing physical parameters in a broad geographical area. The person who needs WSN will have a pictorial idea of the sensor network. The problem in the traditional method is that the person who needs the WSN should explain the pictorial view of the sensor network to a commercial vendor and buy it from them or they should design it from the scratch. What we proposed in our solution is to develop a platform so that the person who needs the WSN can directly draw the pictorial view on a canvas and then it can automatically generate all the required firmware for the microcontrollers and wiring diagrams. The user is then required only to follow a few instructions to complete the real world implementation of WSNs. This paper is about developing a visual platform to design WSNs. The WSN designing platform was built as a web application, so it can manage a large number of supported sensors and microcontrollers. This means that if one user adds the device driver for any sensor or a microcontroller the other users can directly use it from the WSN design platform without worrying about hardware programming. Further, if anyone needs a new sensor or microcontroller to be supported by this visual design platform, this design tool will have interfaces to directly add new sensors and microcontrollers. The proposed method is affordable for developing custom wireless sensor networks.",
            "authors": [
                "Rosen Silva",
                "Asela Dasanayaka",
                "Roshan Ragel",
                "Asitha Bandaranayake"
            ],
            "doi": "https://doi.org/10.1109/MERCon.2018.8421896",
            "preprint": "https://www.researchgate.net/profile/Asitha-Bandaranayake-3/publication/327517623_Visual_Design_Platform_for_Wireless_Sensor_Network/links/5f98da03458515b7cfa4013c/Visual-Design-Platform-for-Wireless-Sensor-Network.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "Wireless sensor networks",
                "Microcontrollers",
                "Databases",
                "Skeleton",
                "Visualization",
                "Hardware",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon.2018.8421896/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon.2018.8421896/index.json"
        }
    ],
    "application specific integrated circuits": [
        {
            "title": "Strategy to Design Formally Verified hardware/software implementation of Network Protocols on Reconfigurable Hardware",
            "venue": "2015 IEEE 10th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2015",
            "abstract": "Kernel-based network protocol implementation has led to major performance limitations in high-performance networking owing to excessive transaction latencies. Designing such protocols in reconfigurable hardware such as FPGA has been attempted to overcome these limitations. The use of reconfigurable hardware is needed in the development phase and could eventually lead to ASICs for better performance. However, mission critical nature of such applications needs a performance guarantee on design. This paper proposes a strategy to design formally verified reconfigurable hardware/software based implementation of network protocols in a compositional manner.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S.D. Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2015.7398980",
            "preprint": "https://www.academia.edu/download/53590902/Abeyrathne.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "application specific integrated circuits",
                "computer networks",
                "field programmable gate arrays",
                "financial data processing",
                "hardware-software codesign",
                "protocols",
                "reconfigurable architectures"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2015.7398980/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2015.7398980/index.json"
        }
    ],
    "automata": [
        {
            "title": "Model-based fault diagnosis and prognosis of dynamic systems: a review",
            "venue": "Procedia Manufacturing",
            "year": "2019",
            "abstract": "In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.",
            "authors": [
                "Thushara Ekanayakea",
                "Devapriya Dewasurendra",
                "Sunil Abeyratne",
                "Lin Ma",
                "Prasad Yarlagadda"
            ],
            "doi": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "preprint": "#",
            "pdf": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "model-based systems",
                "fault diagnosis",
                "fault prognosis",
                "automata",
                "Petri nets",
                "bond graphs",
                "Bayesian networks"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1016/j.promfg.2019.02.060/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1016/j.promfg.2019.02.060/index.json"
        }
    ],
    "bond graphs": [
        {
            "title": "Model-based fault diagnosis and prognosis of dynamic systems: a review",
            "venue": "Procedia Manufacturing",
            "year": "2019",
            "abstract": "In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.",
            "authors": [
                "Thushara Ekanayakea",
                "Devapriya Dewasurendra",
                "Sunil Abeyratne",
                "Lin Ma",
                "Prasad Yarlagadda"
            ],
            "doi": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "preprint": "#",
            "pdf": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "model-based systems",
                "fault diagnosis",
                "fault prognosis",
                "automata",
                "Petri nets",
                "bond graphs",
                "Bayesian networks"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1016/j.promfg.2019.02.060/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1016/j.promfg.2019.02.060/index.json"
        }
    ],
    "computer networks": [
        {
            "title": "Strategy to Design Formally Verified hardware/software implementation of Network Protocols on Reconfigurable Hardware",
            "venue": "2015 IEEE 10th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2015",
            "abstract": "Kernel-based network protocol implementation has led to major performance limitations in high-performance networking owing to excessive transaction latencies. Designing such protocols in reconfigurable hardware such as FPGA has been attempted to overcome these limitations. The use of reconfigurable hardware is needed in the development phase and could eventually lead to ASICs for better performance. However, mission critical nature of such applications needs a performance guarantee on design. This paper proposes a strategy to design formally verified reconfigurable hardware/software based implementation of network protocols in a compositional manner.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S.D. Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2015.7398980",
            "preprint": "https://www.academia.edu/download/53590902/Abeyrathne.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "application specific integrated circuits",
                "computer networks",
                "field programmable gate arrays",
                "financial data processing",
                "hardware-software codesign",
                "protocols",
                "reconfigurable architectures"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2015.7398980/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2015.7398980/index.json"
        }
    ],
    "f5c": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "fault diagnosis": [
        {
            "title": "Model-based fault diagnosis and prognosis of dynamic systems: a review",
            "venue": "Procedia Manufacturing",
            "year": "2019",
            "abstract": "In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.",
            "authors": [
                "Thushara Ekanayakea",
                "Devapriya Dewasurendra",
                "Sunil Abeyratne",
                "Lin Ma",
                "Prasad Yarlagadda"
            ],
            "doi": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "preprint": "#",
            "pdf": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "model-based systems",
                "fault diagnosis",
                "fault prognosis",
                "automata",
                "Petri nets",
                "bond graphs",
                "Bayesian networks"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1016/j.promfg.2019.02.060/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1016/j.promfg.2019.02.060/index.json"
        }
    ],
    "fault prognosis": [
        {
            "title": "Model-based fault diagnosis and prognosis of dynamic systems: a review",
            "venue": "Procedia Manufacturing",
            "year": "2019",
            "abstract": "In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.",
            "authors": [
                "Thushara Ekanayakea",
                "Devapriya Dewasurendra",
                "Sunil Abeyratne",
                "Lin Ma",
                "Prasad Yarlagadda"
            ],
            "doi": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "preprint": "#",
            "pdf": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "model-based systems",
                "fault diagnosis",
                "fault prognosis",
                "automata",
                "Petri nets",
                "bond graphs",
                "Bayesian networks"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1016/j.promfg.2019.02.060/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1016/j.promfg.2019.02.060/index.json"
        }
    ],
    "feature extraction": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "field programmable gate arrays": [
        {
            "title": "Strategy to Design Formally Verified hardware/software implementation of Network Protocols on Reconfigurable Hardware",
            "venue": "2015 IEEE 10th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2015",
            "abstract": "Kernel-based network protocol implementation has led to major performance limitations in high-performance networking owing to excessive transaction latencies. Designing such protocols in reconfigurable hardware such as FPGA has been attempted to overcome these limitations. The use of reconfigurable hardware is needed in the development phase and could eventually lead to ASICs for better performance. However, mission critical nature of such applications needs a performance guarantee on design. This paper proposes a strategy to design formally verified reconfigurable hardware/software based implementation of network protocols in a compositional manner.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S.D. Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2015.7398980",
            "preprint": "https://www.academia.edu/download/53590902/Abeyrathne.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "application specific integrated circuits",
                "computer networks",
                "field programmable gate arrays",
                "financial data processing",
                "hardware-software codesign",
                "protocols",
                "reconfigurable architectures"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2015.7398980/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2015.7398980/index.json"
        }
    ],
    "financial data processing": [
        {
            "title": "Strategy to Design Formally Verified hardware/software implementation of Network Protocols on Reconfigurable Hardware",
            "venue": "2015 IEEE 10th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2015",
            "abstract": "Kernel-based network protocol implementation has led to major performance limitations in high-performance networking owing to excessive transaction latencies. Designing such protocols in reconfigurable hardware such as FPGA has been attempted to overcome these limitations. The use of reconfigurable hardware is needed in the development phase and could eventually lead to ASICs for better performance. However, mission critical nature of such applications needs a performance guarantee on design. This paper proposes a strategy to design formally verified reconfigurable hardware/software based implementation of network protocols in a compositional manner.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S.D. Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2015.7398980",
            "preprint": "https://www.academia.edu/download/53590902/Abeyrathne.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "application specific integrated circuits",
                "computer networks",
                "field programmable gate arrays",
                "financial data processing",
                "hardware-software codesign",
                "protocols",
                "reconfigurable architectures"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2015.7398980/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2015.7398980/index.json"
        }
    ],
    "hardware-software codesign": [
        {
            "title": "Strategy to Design Formally Verified hardware/software implementation of Network Protocols on Reconfigurable Hardware",
            "venue": "2015 IEEE 10th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2015",
            "abstract": "Kernel-based network protocol implementation has led to major performance limitations in high-performance networking owing to excessive transaction latencies. Designing such protocols in reconfigurable hardware such as FPGA has been attempted to overcome these limitations. The use of reconfigurable hardware is needed in the development phase and could eventually lead to ASICs for better performance. However, mission critical nature of such applications needs a performance guarantee on design. This paper proposes a strategy to design formally verified reconfigurable hardware/software based implementation of network protocols in a compositional manner.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S.D. Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2015.7398980",
            "preprint": "https://www.academia.edu/download/53590902/Abeyrathne.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "application specific integrated circuits",
                "computer networks",
                "field programmable gate arrays",
                "financial data processing",
                "hardware-software codesign",
                "protocols",
                "reconfigurable architectures"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2015.7398980/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2015.7398980/index.json"
        }
    ],
    "hierarchical classification": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "hyperspectral imagery": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "linear discriminant analysis": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "model-based systems": [
        {
            "title": "Model-based fault diagnosis and prognosis of dynamic systems: a review",
            "venue": "Procedia Manufacturing",
            "year": "2019",
            "abstract": "In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.",
            "authors": [
                "Thushara Ekanayakea",
                "Devapriya Dewasurendra",
                "Sunil Abeyratne",
                "Lin Ma",
                "Prasad Yarlagadda"
            ],
            "doi": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "preprint": "#",
            "pdf": "https://doi.org/10.1016/j.promfg.2019.02.060",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "model-based systems",
                "fault diagnosis",
                "fault prognosis",
                "automata",
                "Petri nets",
                "bond graphs",
                "Bayesian networks"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1016/j.promfg.2019.02.060/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1016/j.promfg.2019.02.060/index.json"
        }
    ],
    "protocols": [
        {
            "title": "Strategy to Design Formally Verified hardware/software implementation of Network Protocols on Reconfigurable Hardware",
            "venue": "2015 IEEE 10th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2015",
            "abstract": "Kernel-based network protocol implementation has led to major performance limitations in high-performance networking owing to excessive transaction latencies. Designing such protocols in reconfigurable hardware such as FPGA has been attempted to overcome these limitations. The use of reconfigurable hardware is needed in the development phase and could eventually lead to ASICs for better performance. However, mission critical nature of such applications needs a performance guarantee on design. This paper proposes a strategy to design formally verified reconfigurable hardware/software based implementation of network protocols in a compositional manner.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S.D. Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2015.7398980",
            "preprint": "https://www.academia.edu/download/53590902/Abeyrathne.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "application specific integrated circuits",
                "computer networks",
                "field programmable gate arrays",
                "financial data processing",
                "hardware-software codesign",
                "protocols",
                "reconfigurable architectures"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2015.7398980/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2015.7398980/index.json"
        }
    ],
    "reconfigurable architectures": [
        {
            "title": "Strategy to Design Formally Verified hardware/software implementation of Network Protocols on Reconfigurable Hardware",
            "venue": "2015 IEEE 10th International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2015",
            "abstract": "Kernel-based network protocol implementation has led to major performance limitations in high-performance networking owing to excessive transaction latencies. Designing such protocols in reconfigurable hardware such as FPGA has been attempted to overcome these limitations. The use of reconfigurable hardware is needed in the development phase and could eventually lead to ASICs for better performance. However, mission critical nature of such applications needs a performance guarantee on design. This paper proposes a strategy to design formally verified reconfigurable hardware/software based implementation of network protocols in a compositional manner.",
            "authors": [
                "Pabudi T Abeyrathne",
                "S.D. Dewasurendra",
                "Dhammika Elkaduwa"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2015.7398980",
            "preprint": "https://www.academia.edu/download/53590902/Abeyrathne.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "application specific integrated circuits",
                "computer networks",
                "field programmable gate arrays",
                "financial data processing",
                "hardware-software codesign",
                "protocols",
                "reconfigurable architectures"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2015.7398980/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2015.7398980/index.json"
        }
    ],
    "remote sensing": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "self-organise": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "spectral clustering": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "umbrella clustering": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ],
    "unsupervised": [
        {
            "title": "Adaptive hierarchical clustering for hyperspectral image classification: Umbrella Clustering",
            "venue": "Journal of Spectral Imaging",
            "year": "2019",
            "abstract": "Hyperspectral Imaging (HSI) utilises the reflectance information of a large number of contiguous spectral bands to solve various problems. However, the relative proximity of spectral signatures among classes can be exploited to generate an adaptive hierarchical structure for HSI classification. This enables a level by level optimisation for clustering at each stage of the hierarchy. The Umbrella Clustering algorithm, introduced in this work, utilises this premise to significantly improve performance compared to non-hierarchical algorithms which attempt to optimise clustering globally. The key feature of the proposed methodology is that, unlike existing hierarchical algorithms which rely on fixed or supervised structures, the proposed method exploits a mechanism in spectral clustering to generate a self-organised hierarchy. The algorithm gradually zooms into the feature space to identify levels of clustering at each stage of the hierarchy. The results further demonstrate that the generated structure tallies with human perception. In addition, an improvement to Linear Discriminant Analysis (LDA) is also introduced to further improve performance. This modification maximises the pairwise class separation in the feature space. The entire algorithm includes this modified LDA step which requires a certain amount of class information in terms of features, at the training phase. The classification algorithm which incorporates all novel concepts was tested on the HSI data set of Pavia University as well the database of Common Sri Lankan Spices and Adulterants in order to assess the versatility of the algorithm.",
            "authors": [
                "S.S.P. Vithana",
                "E.M.M.B. Ekanayake",
                "E.M.H.E.B. Ekanayake",
                "A.R.M.A.N. Rathnayake",
                "G.C. Jayatilaka",
                "H.M.V.R. Herath",
                "G.M.R.I. Godaliyadda",
                "M.P.B. Ekanayake"
            ],
            "doi": "https://doi.org/10.1255/jsi.2019.a11",
            "preprint": "#",
            "pdf": "https://www.impopen.com/download.php?code=I08_a11",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                ""
            ],
            "funding": "",
            "tags": [
                "hyperspectral imagery",
                "spectral clustering",
                "hierarchical classification",
                "umbrella clustering",
                "feature extraction",
                "remote sensing",
                "linear discriminant analysis",
                "self-organise",
                "unsupervised"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1255/jsi.2019.a11/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1255/jsi.2019.a11/index.json"
        }
    ]
}