{
    "Accelerated and High-Performance Computing (FPGA / GPU)": [
        {
            "title": "GPU accelerated adaptive banded event alignment for rapid comparative nanopore signal analysis",
            "venue": "BMC Bioinformatics",
            "year": "2020",
            "abstract": "[BACKGROUND:] Nanopore sequencing enables portable, real-time sequencing applications, including point-of-care diagnostics and in-the-field genotyping. Achieving these outcomes requires efficient bioinformatic algorithms for the analysis of raw nanopore signal data. However, comparing raw nanopore signals to a biological reference sequence is a computationally complex task. The dynamic programming algorithm called Adaptive Banded Event Alignment (ABEA) is a crucial step in polishing sequencing data and identifying non-standard nucleotides, such as measuring DNA methylation. Here, we parallelise and optimise an implementation of the ABEA algorithm (termed f5c) to efficiently run on heterogeneous CPU-GPU architectures. [RESULTS:] By optimising memory, computations and load balancing between CPU and GPU, we demonstrate how f5c can perform \u00e2\u0088\u00bc3-5 \u00c3\u0097 faster than an optimised version of the original CPU-only implementation of ABEA in the Nanopolish software package. We also show that f5c enables DNA methylation detection on-the-fly using an embedded System on Chip (SoC) equipped with GPUs. [CONCLUSIONS:] Our work not only demonstrates that complex genomics analyses can be performed on lightweight computing systems, but also benefits High-Performance Computing (HPC). The associated source code for f5c along with GPU optimised ABEA is available at https://github.com/hasindu2008/f5c.",
            "authors": [
                "Hasindu Gamaarachchi",
                "Chun Wai Lam",
                "Gihan Jayatilaka",
                "Hiruna Samarakoon",
                "Jared T. Simpson",
                "Martin A. Smith",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1186/s12859-020-03697-x",
            "preprint": "https://www.biorxiv.org/content/10.1101/756122v1.full.pdf",
            "pdf": "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03697-x.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "https://github.com/hasindu2008/f5c",
            "researchgroups": [
                "Accelerated and High-Performance Computing (FPGA / GPU)"
            ],
            "funding": "Jared T. Simpson is supported by the Ontario Institute for Cancer Research through funds provided by the Government of Ontario and the Government of Canada through Genome Canada and Ontario Genomics (OGI-136).",
            "tags": [
                "Nanopore",
                "Signal alignment",
                "Event alignment",
                "Methylation",
                "GPU",
                "GPU acceleration",
                "Optimisation",
                "SoC",
                "Nanopolish",
                "f5c"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1186/s12859-020-03697-x/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1186/s12859-020-03697-x/index.json"
        }
    ],
    "Computational BioEngineering": [
        {
            "title": "Non-contact Infant Sleep Apnea Detection",
            "venue": "IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2019",
            "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for the detection of sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
            "authors": [
                "Gihan Jayatilaka",
                "Harshana Weligampola",
                "Suren Sritharan",
                "Pankayaraj Pathmanathan",
                "Roshan Ragel",
                "Isuru Nawinne"
            ],
            "doi": "https://doi.org/10.1109/ICIIS47346.2019.9063269",
            "preprint": "https://arxiv.org/pdf/1910.04725.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering",
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Sleep apnea",
                "Video processing",
                "Bio medical engineering",
                "Pattern recognition"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS47346.2019.9063269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS47346.2019.9063269/index.json"
        },
        {
            "title": "Genopo: a nanopore sequencing analysis toolkit for portable Android devices",
            "venue": "Communications Biology",
            "year": "2020",
            "abstract": "The advent of portable nanopore sequencing devices has enabled DNA and RNA sequencing to be performed in the field or the clinic. However, advances in in situ genomics require parallel development of portable, offline solutions for the computational analysis of sequencing data. Here we introduce Genopo, a mobile toolkit for nanopore sequencing analysis. Genopo compacts popular bioinformatics tools to an Android application, enabling fully portable computation. To demonstrate its utility for in situ genome analysis, we use Genopo to determine the complete genome sequence of the human coronavirus SARS-CoV-2 in nine patient isolates sequenced on a nanopore device, with Genopo executing this workflow in less than 30\u00e2\u0080\u0089min per sample on a range of popular smartphones. We further show how Genopo can be used to profile DNA methylation in a human genome sample, illustrating a flexible, efficient architecture that is suitable to run many popular bioinformatics tools and accommodate small or large genomes. As the first ever smartphone application for nanopore sequencing analysis, Genopo enables the genomics community to harness this cheap, ubiquitous computational resource.",
            "authors": [
                "Hiruna Samarakoon",
                "Sanoj Punchihewa",
                "Anjana Senanayake",
                "Jillian M. Hammond",
                "Igor Stevanovski",
                "James M. Ferguson",
                "Roshan Ragel",
                "Hasindu Gamaarachchi",
                "Ira W. Deveson"
            ],
            "doi": "https://doi.org/10.1038/s42003-020-01270-z",
            "preprint": "#",
            "pdf": "https://www.nature.com/articles/s42003-020-01270-z.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering"
            ],
            "funding": "MRFF grant APP1173594 (to I.W.D.), Cancer Institute NSW Early Career Fellowship 2018/ECF013 (to I.W.D.) and philanthropic support from The Kinghorn Foundation (to I.W.D. and H.G.).",
            "tags": [
                "Genopo",
                "Nanopore Sequencing"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1038/s42003-020-01270-z/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1038/s42003-020-01270-z/index.json"
        }
    ],
    "Computer Vision": [
        {
            "title": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for Enhancing Low Light Images",
            "venue": "MERcon",
            "year": "2020",
            "abstract": "Low light image enhancement is an important challenge for the development of robust computer vision algorithms. The machine learning approaches to this have been either unsupervised, supervised based on paired dataset or supervised based on unpaired dataset. This paper presents a novel deep learning pipeline that can learn from both paired and unpaired datasets. Convolution Neural Networks (CNNs) that are optimized to minimize standard loss, and Generative Adversarial Networks (GANs) that are optimized to minimize the adversarial loss are used to achieve different steps of the low light image enhancement process. Cycle consistency loss and a patched discriminator are utilized to further improve the performance. The paper also analyses the functionality and the performance of different components, hidden layers, and the entire pipeline.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Roshan Goldaliyadda",
                "Parakrama Ekanayeka",
                "Roshan Ragel",
                "Vijitha Herath"
            ],
            "doi": "https://doi.org/10.1109/MERCon50084.2020.9185373",
            "preprint": "https://arxiv.org/pdf/2006.15304.pdf",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/mercon-2020-presentation.pdf",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Low-light image enhancement",
                "Retinex theory",
                "Generative adversarial networks",
                "Cycle consistency",
                "Computer Vision"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MERCon50084.2020.9185373/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MERCon50084.2020.9185373/index.json"
        },
        {
            "title": "Non-contact Infant Sleep Apnea Detection",
            "venue": "IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2019",
            "abstract": "Sleep apnea is a breathing disorder where a person repeatedly stops breathing in sleep. Early detection is crucial for infants because it might bring long term adversities. The existing accurate detection mechanism (pulse oximetry) is a skin contact measurement. The existing non-contact mechanisms (acoustics, video processing) are not accurate enough. This paper presents a novel algorithm for the detection of sleep apnea with video processing. The solution is non-contact, accurate and lightweight enough to run on a single board computer. The paper discusses the accuracy of the algorithm on real data, advantages of the new algorithm, its limitations and suggests future improvements.",
            "authors": [
                "Gihan Jayatilaka",
                "Harshana Weligampola",
                "Suren Sritharan",
                "Pankayaraj Pathmanathan",
                "Roshan Ragel",
                "Isuru Nawinne"
            ],
            "doi": "https://doi.org/10.1109/ICIIS47346.2019.9063269",
            "preprint": "https://arxiv.org/pdf/1910.04725.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computational BioEngineering",
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Sleep apnea",
                "Video processing",
                "Bio medical engineering",
                "Pattern recognition"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIIS47346.2019.9063269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIIS47346.2019.9063269/index.json"
        },
        {
            "title": "An optical physics inspired CNN approach for intrinsic image decomposition",
            "venue": "2021 IEEE International Conference on Image Processing (ICIP)",
            "year": "2021",
            "abstract": "Intrinsic Image Decomposition is an open problem of generating the constituents of an image. Generating reflectance and shading from a single image is a challenging task specifically when there is no ground truth. There is a lack of unsupervised learning approaches for decomposing an image into reflectance and shading using a single image. We propose a neural network architecture capable of this decomposition using physics-based parameters derived from the image. Through experimental results, we show that (a) the proposed methodology outperforms the existing deep learning-based IID techniques and (b) the derived parameters improve the efficacy significantly. We conclude with a closer analysis of the results (numerical and example images) showing several avenues for improvement.",
            "authors": [
                "Harshana Weligampola",
                "Gihan Jayatilaka",
                "Suren Sritharan",
                "Parakrama Ekanayake",
                "Roshan Ragel",
                "Vijitha Herath",
                "Roshan Godaliyadda"
            ],
            "doi": "https://doi.org/10.1109/ICIP42928.2021.9506375",
            "preprint": "https://arxiv.org/pdf/2105.10076",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/fyp/icip-2021-presentation.pdf",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e14/dark-arts-algorithms-for-low-light-image-enhancement-and-interpretation/",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Reflectivity",
                "Neural networks",
                "Optical fiber networks",
                "Optical imaging",
                "Image decomposition",
                "Numerical models",
                "Optical reflection"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIP42928.2021.9506375/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIP42928.2021.9506375/index.json"
        },
        {
            "title": "DeepLight: Robust & Unobtrusive Real-time Screen-Camera Communication for Real-World Displays",
            "venue": "2021 20th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)",
            "year": "2021",
            "abstract": "The paper introduces a novel, holistic approach for robust Screen-Camera Communication (SCC), where video content on a screen is visually encoded in a human-imperceptible fashion and decoded by a camera capturing images of such screen content. We first show that state-of-the-art SCC techniques have two key limitations for in-the-wild deployment: (a) the decoding accuracy drops rapidly under even modest screen extraction errors from the captured images, and (b) they generate perceptible flickers on common refresh rate screens even with minimal modulation of pixel intensity. To overcome these challenges, we introduce DeepLight, a system that incorporates machine learning (ML) models in the decoding pipeline to achieve humanly-imperceptible, moderately high SCC rates under diverse real-world conditions. DeepLight's key innovation is the design of a Deep Neural Network (DNN) based decoder that collectively decodes all the bits spatially encoded in a display frame, without attempting to precisely isolate the pixels associated with each encoded bit. In addition, DeepLight supports imperceptible encoding by selectively modulating the intensity of only the Blue channel, and provides reasonably accurate screen extraction (IoU values \u00e2\u0089\u00a5 83%) by using state-of-the-art object detection DNN pipelines. We show that a fully functional DeepLight system is able to robustly achieve high decoding accuracy (frame error rate < 0.2) and moderately-high data goodput (\u00e2\u0089\u00a50.95 Kbps) using a human-held smartphone camera, even over larger screen-camera distances (~ 2m).",
            "authors": [
                "Vu Tran",
                "Gihan Jayatilaka",
                "Ashwin Ashok",
                "Archan Misra"
            ],
            "doi": "https://doi.org/10.1145/3412382.3458269",
            "preprint": "https://arxiv.org/pdf/2105.05092",
            "pdf": "#",
            "presentation": "https://www.cs.umd.edu/~gihan/projects/deeplight/presentation.pdf",
            "project": "#",
            "codebase": "https://github.com/gihanjayatilaka/deeplight",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Human-centered computing",
                "Ubiquitous and mobile computing",
                "Computer systems organization",
                "Embedded and cyber-physical systems"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/3412382.3458269/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/3412382.3458269/index.json"
        },
        {
            "title": "Objectively Measure Player Performance on Olympic Weightlifting",
            "venue": "2021 10th International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2021",
            "abstract": "In Olympic-style weightlifting athlete attempts to lift the weight plates on a barbell and scores are determined by a combination of the successful highest weight achieved in snatch and the clean-and-jerk actions. However, the current method does not objectively measure the player techniques. In this paper, we introduce a novel method to objectively measure player performance on weightlifting using human action recognition in videos. We introduce a method to assess player techniques in weightlifting by using skeleton-based human action recognition. In order to achieve our goal, we further introduce a new video dataset for action recognition in weightlifting which is annotated to frame level and introduce an automated scoring system through action recognition. We conclude our paper with qualitative and quantitative experimental results using non-Olympic players and 2016 Gold, Silver, and Bronze medalists in different weight categories (both men and women).",
            "authors": [
                "Anandi Karunaratne",
                "Chamin Jayasooriya",
                "Sampath Deegalla",
                "Rajitha Navarathna"
            ],
            "doi": "https://doi.org/10.1109/ICIAfS52090.2021.9605963",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Computer Vision"
            ],
            "funding": "",
            "tags": [
                "Weight measurement",
                "Silver",
                "Gold",
                "Automation",
                "Current measurement",
                "Sustainable development",
                "Videos"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAfS52090.2021.9605963/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAfS52090.2021.9605963/index.json"
        }
    ],
    "ESCAL: Computer Systems (Embedded Systems / Robotics )": [
        {
            "title": "Hardware software co-design of the Aho-Corasick algorithm: Scalable for protein identification?",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Pattern matching is commonly required in many application areas and bioinformatics is a major area of interest that requires both exact and approximate pattern matching. Much work has been done in this area, yet there is still a significant space for improvement in efficiency, flexibility, and throughput. This paper presents a hardware software co-design of Aho-Corasick algorithm in Nios II soft-processor and a study on its scalability for a pattern matching application. A software only approach is used to compare the throughput and the scalability of the hardware software co-design approach. According to the results we obtained, we conclude that the hardware software co-design implementation shows a maximum of 10 times speed up for pattern size of 1200 peptides compared to the software only implementation. The results also show that the hardware software co-design approach scales well for increasing data size compared to the software only approach.",
            "authors": [
                "S.M. Vidanagamachchi",
                "S.D. Dewasurendra",
                "",
                "R.G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732003",
            "preprint": "https://arxiv.org/ftp/arxiv/papers/1403/1403.1317.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Proteins",
                "Peptides",
                "Software algorithms",
                "Program processors",
                "Algorithm design and analysis"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732003/index.json"
        },
        {
            "title": "Hardware accelerated protein inference framework",
            "venue": "2013 IEEE 8th International Conference on Industrial and Information Systems",
            "year": "2013",
            "abstract": "Protein inference plays a vital role in the proteomics study. Two major approaches could be used to handle the problem of protein inference; top-down and bottom-up. This paper presents a framework for protein inference, which uses hardware accelerated protein inference framework for handling the most important step in a bottom-up approach, viz. peptide identification during the assembling process. In our framework, identified peptides and their probabilities are used to predict the most suitable reference protein cluster for a given input amino acid sequence with the probability of identified peptides. The framework is developed on an FPGA where hardware software co-design techniques are used to accelerate the computationally intensive parts of the protein inference process. In the paper we have measured, compared and reported the time taken for the protein inference process in our framework against a pure software implementation.",
            "authors": [
                "S. M. Vidanagamachchi",
                "S. D. Dewasurendra",
                "R. G. Ragel"
            ],
            "doi": "https://doi.org/10.1109/ICIInfS.2013.6732061",
            "preprint": "https://arxiv.org/pdf/1403.1319",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Proteins",
                "Peptides",
                "Hardware",
                "Tiles",
                "Software",
                "Field programmable gate arrays",
                "Acceleration"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIInfS.2013.6732061/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIInfS.2013.6732061/index.json"
        },
        {
            "title": "A Study on Instruction-set Selection Using Multi-application Based Application Specific Instruction-set Processors",
            "venue": "2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems",
            "year": "2013",
            "abstract": "Efficiency in embedded systems is paramount to achieve high performance while consuming less area and power. Processors in embedded systems have to be designed carefully to achieve such design constraints. Application Specific Instruction set Processors (ASIPs) exploit the nature of applications to design an optimal instruction set. Despite being not general to execute any application, ASIPs are highly preferred in the embedded systems industry where the devices are produced to satisfy a certain type of application domain/s (either intra-domain or inter-domain). Typically, ASIPs are designed from a base-processor and functionalities are added for applications. This paper studies the multi-application ASIPs and their instruction sets, extensively analyzing the instructions for inter-domain and intra-domain designs. Metrics analyzed are the reusable instructions and the extra cost to add a certain application, together with the hardware synthesis numbers, such as area, timing and delay. A wide range of applications from various application benchmarks (BioPerf, CommBench, MediaBench, MiBench and SPEC2006) and domains are analyzed for three different architectures (LEON2, PISA and ARM-Thumb). Processors are generated for these architectures for different configurations to analyze and synthesize. Our study shows that the intra-domain applications contain larger number of common instructions, whereas the inter-domain applications have very less common instructions, regardless the kind of architecture (and therefore the ISA).",
            "authors": [
                "Roshan G. Ragel",
                "Swarnalatha Radhakrishnan",
                "Jude Angelo Ambrose",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/VLSID.2013.154",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/261501995_A_Study_on_Instruction-set_Selection_Using_Multi-application_Based_Application_Specific_Instruction-set_Processors/links/54e48faf0cf2dbf60696e9b4/A-Study-on-Instruction-set-Selection-Using-Multi-application-Based-Application-Specific-Instruction-set-Processors.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Hardware",
                "Thumb",
                "Embedded systems",
                "Benchmark testing",
                "Standards",
                "Instruction sets"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/VLSID.2013.154/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/VLSID.2013.154/index.json"
        },
        {
            "title": "CSER: HW/SW configurable soft-error resiliency for application specific instruction-set processors",
            "venue": "2013 Design, Automation & Test in Europe Conference & Exhibition (DATE)",
            "year": "2013",
            "abstract": "Soft error has been identified as one of the major challenges to CMOS technology based computing systems. To mitigate this problem, error recovery is a key component, which usually accounts for a substantial cost, since they must introduce redundancies in either time or space. Consequently, using state-of-art recovery techniques could heavily worsen the design constraint, which is fairly stringent for embedded system design. In this paper, we propose a HW/SW methodology that generates the processor, which performs finely configured error recovery functionality targeting the given design constraints (e.g., performance, area and power). Our methodology employs three application-specific optimization heuristics, which generate the optimized composition and configuration based on the two primitive error recovery techniques. The resultant processor is composed of selected primitive techniques at corresponding instruction execution, and configured to perform error recovery at run-time accordingly to the scheme determined at design time. The experiment results have shown that our methodology can at best achieve nine times reliability while maintaining the given constraints, in comparison to the state of the art.",
            "authors": [
                "Tuo Li",
                "Muhammad Shafique",
                "Semeen Rehman",
                "Swarnalatha Radhakrishnan",
                "Roshan Ragel",
                "Jude Angelo Ambrose",
                "J\u00c3\u00b6rg Henkel",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.7873/DATE.2013.152",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Redundancy",
                "Time factors",
                "Runtime",
                "Integrated circuits",
                "Programming"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.7873/DATE.2013.152/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.7873/DATE.2013.152/index.json"
        },
        {
            "title": "DRMA: dynamically reconfigurable MPSoC architecture",
            "venue": "GLSVLSI '13: Proceedings of the 23rd ACM international conference on Great lakes symposium on VLSI",
            "year": "2013",
            "abstract": "Embedded systems are ubiquitous and are deployed in a large range of applications. Designing and fabricating Integrated Circuits (ICs) targeting such different range of applications is expensive. Designers seek flexible processors which efficiently execute a multitude of applications. FPGAs are considered affordable, but design cost, high reconfiguration delay and power consumption are all prohibitive. In this paper, we propose a novel ASIC based flexible MPSoC architecture, which can execute separate tasks in parallel, and it can be configured to execute single task with wide data widths or execute multiple tasks with varying data widths. The architecture presented, called Dynamically Reconfigurable MPSoC Architecture (DRMA), can be rapidly reconfigured through instructions. We present applications as case studies to showcase the flexibility and efficacy of DRMA. Results show for an additional area overhead of about 5%, the system is capable of working as four 32-bit processors, a single 128 bit processor or as a pipelined processing system.",
            "authors": [
                "Lawrance Zhang",
                "Jude Angelo Ambrose",
                "Jorgen Peddersen",
                "Sri Parameswaran",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Kewal K. Saluja"
            ],
            "doi": "https://doi.org/10.1145/2483028.2483101",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Computer systems organization",
                "Architectures",
                "Serial architectures",
                "Pipeline computing",
                "Hardware"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1145/2483028.2483101/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1145/2483028.2483101/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        },
        {
            "title": "Exploring multilevel cache hierarchies in application specific mpsocs",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "year": "2015",
            "abstract": "Multiprocessor systems make use of multilevel cache hierarchies to improve overall memory access speed. Embedded systems typically use configurable processors, where the caches in the system can be customized for a given application or a set of applications. Finding the optimal or a near-optimal set size, block size, and associativity of each of the caches in a multilevel cache hierarchy is a challenging task due to the presence of billions or even trillions of design points. This paper presents an iterative exploration method to find suitable configurations for all the caches in the hierarchy of an application specific multiprocessor system-on-chip, to improve memory access speed. We propose an algorithm and combine it with the use of specialized hardware for parallel cache simulation to enable multiple back-and-forth iterations through the cache levels. In every iteration, our algorithm explores selected portions of the entire design space to quickly converge upon the final design point. We demonstrate our methodology on two- and three-level cache hierarchies with private and shared caches in a quad-core system, respectively, consisting of 5.4 billion and 10.4 trillion design points. Our method was able to find design points with up to 18.9% lower average memory access time while reducing total cache size by up to 74.15%, compared to a state-of-the-art noniterative method. The number of design points explored was 4\u00c3\u0097 higher in our method, which is still a mere 3.6 \u00c3\u0097 10 -5 % of the entire design space, and took 6.08 h.",
            "authors": [
                "Isuru Nawinne",
                "Haris Javaid",
                "Roshan Ragel",
                "Swarnalatha Radhakrishnan",
                "Sri Parameswaran"
            ],
            "doi": "https://doi.org/10.1109/TCAD.2015.2445736",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "ESCAL: Computer Systems (Embedded Systems / Robotics )"
            ],
            "funding": "",
            "tags": [
                "Algorithm design and analysis",
                "Hardware",
                "Program processors",
                "Space exploration",
                "Integrated circuit modeling",
                "Mathematical model",
                "Optimization"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TCAD.2015.2445736/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TCAD.2015.2445736/index.json"
        }
    ],
    "Machine Learning and Data Mining": [
        {
            "title": "Chronic kidney disease prediction using machine learning methods",
            "venue": "2020 Moratuwa Engineering Research Conference (MERCon) - IEEE",
            "year": "2020",
            "abstract": "Chronic Kidney Disease (CKD) or chronic renal disease has become a major issue with a steady growth rate. A person can only survive without kidneys for an average time of 18 days, which makes a huge demand for a kidney transplant and Dialysis. It is important to have effective methods for early prediction of CKD. Machine learning methods are effective in CKD prediction. This work proposes a workflow to predict CKD status based on clinical data, incorporating data prepossessing, a missing value handling method with collaborative filtering and attributes selection. Out of the 11 machine learning methods considered, the extra tree classifier and random forest classifier are shown to result in the highest accuracy and minimal bias to the attributes. The research also considers the practical aspects of data collection and highlights the importance of incorporating domain knowledge when using machine learning for CKD status prediction.",
            "authors": [
                "Imesh Udara Ekanayake; Damayanthi Herath"
            ],
            "doi": " https://doi.org/10.1109/MERCon50084.2020.9185249",
            "preprint": "#",
            "pdf": "https://www.researchgate.net/profile/Imesh-Ekanayake/publication/344319206_Chronic_Kidney_Disease_Prediction_Using_Machine_Learning_Methods/links/5f672571458515b7cf418d5b/Chronic-Kidney-Disease-Prediction-Using-Machine-Learning-Methods.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Machine Learning and Data Mining"
            ],
            "funding": "",
            "tags": [
                "Kidney",
                "Diseases",
                "Machine learning",
                "Red blood cells",
                "Hypertension"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/ 10.1109/MERCon50084.2020.9185249/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/ 10.1109/MERCon50084.2020.9185249/index.json"
        }
    ],
    "Nextgen Networks": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        }
    ],
    "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)": [
        {
            "title": "Security weaknesses of WEP protocol IEEE 802.11b and enhancing the security with dynamic keys",
            "venue": "2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH)",
            "year": "2009",
            "abstract": "In wireless data communication, security has become an important measure. In this paper, we reveal vulnerabilities and weaknesses of WEP protocol which is used in IEEE 802.11b. The major issue of WEP protocol is the lack of a proper key management technique. We propose a method to overcome above by introducing a dynamic key for authentication and data transmission on per data frame basis.",
            "authors": [
                "Manjula Sandirigama",
                "Rasika Idamekorala"
            ],
            "doi": "https://doi.org/10.1109/TIC-STH.2009.5444462",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)",
                "Nextgen Networks"
            ],
            "funding": "",
            "tags": [
                "Authentication",
                "Cryptography",
                "Data security",
                "Random number generation",
                "Computer security",
                "Communication system security",
                "Data communication",
                "Access protocols",
                "Computer hacking",
                "Information security"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/TIC-STH.2009.5444462/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/TIC-STH.2009.5444462/index.json"
        },
        {
            "title": "On implementing a client-server setting to prevent the Browser Reconnaissance and Exfiltration via Adaptive Compression of Hypertext (BREACH) attacks",
            "venue": "2016 Manufacturing & Industrial Engineering Symposium (MIES)",
            "year": "2016",
            "abstract": "Compression is desirable for network applications as it saves bandwidth. Differently, when data is compressed before being encrypted, the amount of compression leaks information about the amount of redundancy in the plaintext. This side channel has led to the \u00e2\u0080\u009cBrowser Reconnaissance and Exfiltration via Adaptive Compression of Hypertext (BREACH)\u00e2\u0080\u009d attack on web traffic protected by the TLS protocol. The general guidance to prevent this attack is to disable HTTP compression, preserving confidentiality but sacrificing bandwidth. As a more sophisticated countermeasure, fixed-dictionary compression was introduced in 2015 enabling compression while protecting high-value secrets, such as cookies, from attacks. The fixed-dictionary compression method is a cryptographically sound countermeasure against the BREACH attack, since it is proven secure in a suitable security model. In this project, we integrate the fixed-dictionary compression method as a countermeasure for BREACH attack, for real-world client-server setting. Further, we measure the performance of the fixed-dictionary compression algorithm against the DEFLATE compression algorithm. The results evident that, it is possible to save some amount of bandwidth, with reasonable compression/decompression time compared to DEFLATE operations. The countermeasure is easy to implement and deploy, hence, this would be a possible direction to mitigate the BREACH attack efficiently, rather than stripping off the HTTP compression entirely.",
            "authors": [
                "Isuru Sankalpa",
                "Tharindu Dhanushka",
                "Nadeesha Amarasinghe",
                "Janaka Alawathugoda",
                "Roshan Ragel"
            ],
            "doi": "https://doi.org/10.1109/MIES.2016.7780263",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Dictionaries",
                "Servers",
                "Compression algorithms",
                "Cryptography",
                "Browsers",
                "Encoding",
                "Bandwidth"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/MIES.2016.7780263/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/MIES.2016.7780263/index.json"
        },
        {
            "title": "Leakage-resilient storage scheme for cryptographic applications",
            "venue": "2016 IEEE International Conference on Information and Automation for Sustainability (ICIAfS)",
            "year": "2016",
            "abstract": "Since the side-channel attacks arise as a huge threat for cryptographic schemes than previously realized, it is necessary to implement proven-secure leakage-resilient cryptographic schemes and use them for real-world purposes. In this work our effort is to implement two leakage-resilient cryptographic schemes, a leakage-resilient storage scheme and a refreshing protocol, which have been proven-secure and accepted by the cryptographic community since 2011 (ASIACRYPT 2011). Our aim is to open up the direction for implementing the useful leakage-resilient cryptographic schemes for future usage.",
            "authors": [
                "Janaka Alawatugoda",
                "Roshan Ragel",
                "Danushka Eranga",
                "Nalaka Jayanath",
                "Chinthaka Somathilaka"
            ],
            "doi": "https://doi.org/10.1109/ICIAFS.2016.7946548",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Side-channel attacks",
                "Protocols",
                "Computational modeling",
                "Timing",
                "Encryption"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIAFS.2016.7946548/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIAFS.2016.7946548/index.json"
        },
        {
            "title": "Generic construction of an  eCK -secure key exchange protocol in the standard model",
            "venue": "International Journal of Information Security",
            "year": "2017",
            "abstract": "",
            "authors": [
                "Janaka Alawatugoda"
            ],
            "doi": "https://doi.org/10.1007/s10207-016-0346-9",
            "preprint": "#",
            "pdf": "https://link.springer.com/content/pdf/10.1007/s10207-016-0346-9.pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Public-key cryptography",
                "Key exchange protocols",
                "eCK model",
                "Standard model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1007/s10207-016-0346-9/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1007/s10207-016-0346-9/index.json"
        },
        {
            "title": "Leakage-resilient non-interactive key exchange in the continuous-memory leakage setting",
            "venue": "International Conference on Provable Security",
            "year": "2017",
            "abstract": "Recently, Chakraborty et al. (Cryptoeprint:2017:441) showed a novel approach of constructing several leakage-resilient cryptographic primitives by introducing a new primitive called leakage-resilient non-interactive key exchange (LR-NIKE). Their construction of LR-NIKE was only in the bounded-memory leakage model, and they left open the construction of LR-NIKE in continuous-memory leakage model. In this paper we address that open problem. Moreover, we extend the continuous-memory leakage model by addressing more realistic after-the-fact leakage. The main ingredients of our construction are a leakage-resilient storage scheme and a refreshing protocol (Dziembowski and Faust, Asiacrypt 2011) and a (standard) chameleon hash function (CHF), equipped with an additional property of oblivious sampling, which we introduce. We observe that the present constructions of CHF already satisfies our new notion. Further, our protocol can be used as a building block to construct leakage-resilient public-key encryption schemes, interactive key exchange and low-latency key exchange protocols in the continuous-memory leakage model, following the approach of Chakraborty et al. (Cryptoeprint:2017:441).",
            "authors": [
                "Suvradip Chakraborty",
                "Janaka Alawatugoda",
                "C Pandu Rangan"
            ],
            "doi": "https://doi.org/10.1007/978-3-319-68637-0_10",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Leakage-resilient",
                "Key exchange protocols",
                "After-the-fact leakage",
                "Continuous-memory leakage"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1007/978-3-319-68637-0_10/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1007/978-3-319-68637-0_10/index.json"
        },
        {
            "title": "On the leakage-resilient key exchange",
            "venue": "Journal of Mathematical Cryptology",
            "year": "2017",
            "abstract": "Typically, secure channels are constructed from an authenticated key exchange (AKE) protocol, which authenticates the communicating parties based on long-term public keys and establishes secret session keys. In this paper we address the partial leakage of long-term secret keys of key exchange protocol participants due to various side-channel attacks. Security models for two-party authenticated key exchange protocols have been developed over time to provide security even when the adversary learns certain secret values. This paper combines and extends the advances of security modelling for AKE protocols addressing more granular partial leakage of long-term secrets of protocol participants. Further, we fix some flaws in security proofs of previous leakage-resilient key exchange protocols.",
            "authors": [
                "https://doi.org/10.1515/jmc-2016-0003"
            ],
            "doi": "https://doi.org/10.1515/jmc-2016-0003",
            "preprint": "#",
            "pdf": "https://www.degruyter.com/document/doi/10.1515/jmc-2016-0003/pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Key exchange protocols",
                "security models",
                "leakage-resilient cryptography"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1515/jmc-2016-0003/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1515/jmc-2016-0003/index.json"
        },
        {
            "title": "Implementing a proven-secure and cost-effective countermeasure against the compression ratio info-leak mass exploitation (CRIME) attack",
            "venue": "2017 IEEE International Conference on Industrial and Information Systems (ICIIS)",
            "year": "2017",
            "abstract": "Header compression is desirable for network applications as it saves bandwidth and reduces latency. However, when data is compressed before being encrypted, the amount of compression leaks information about the amount of redundancy in the plaintext. In web requests, headers contain secret web cookies. Therefore, compression of headers before encryption will reveal the information about the secret web cookies. This side-channel has led to Compression Ratio Info-leak Made Easy (CRIME) attack on web traffic protected by the SSL/TLS protocols. In order to mitigate the CRIME attack, compression is completely disabled at the TLS/SSL layer, which in return increases the bandwidth consumption and latency. In a previous work (Financial Cryptography and Data Security 2015), two countermeasures are presented with formal security proofs, against compression side-channel attacks, namely (l)-separating secret cookies from user inputs and (2)-using a static compression dictionary. In this work we create a test environment to replicate the CRIME attack and verify the attack. Moreover, we implement a proven-secure countermeasure against the CRIME attack, in a real world client/server setup, following the aforementioned two countermeasures. Our implementation achieves better compression ratio (closer to the original TLS/SSL compression), and hence reduces the bandwidth usage and latency significantly (therefore cost-effective). To the best of our knowledge, this is the first proven-secure and cost-effective countermeasure implementation against the CRIME attack.",
            "authors": [
                "Jayamine Alupotha",
                "Sanduni Prasadi",
                "Janaka Alawatugoda",
                "Roshan Ragel",
                "Mohamed Fawsan"
            ],
            "doi": "https://doi.org/10.1109/ICIINFS.2017.8300359",
            "preprint": "https://www.researchgate.net/profile/Roshan-Ragel/publication/323352314_Implementing_a_proven-secure_and_cost-effective_countermeasure_against_the_compression_ratio_info-leak_mass_exploitation_CRIME_attack/links/61c959beb8305f7c4b0421bc/Implementing-a-proven-secure-and-cost-effective-countermeasure-against-the-compression-ratio-info-leak-mass-exploitation-CRIME-attack.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Bandwidth",
                "Side-channel attacks",
                "Dictionaries",
                "Servers",
                "Data compression"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1109/ICIINFS.2017.8300359/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1109/ICIINFS.2017.8300359/index.json"
        },
        {
            "title": "Review on leakage resilient key exchange security models",
            "venue": "International Journal of Communication Networks and Information Security",
            "year": "2019",
            "abstract": "In leakage resilient cryptography, leakage resilient key exchange protocols are constructed to defend against leakage attacks. Then, the key exchange protocol is proved with leakage resilient security model to determine whether its security proof can provide the security properties it claimed or to find out any unexamined flaw during protocol building. It is an interesting work to review the meaningful security properties provided by these security models. This work review how a leakage resilient security model for a key exchange protocol has been evolved over years according to the increasing security requirement which covers a different range of attacks. The relationship on how an adversary capability in the leakage resilient security model can be related to real-world attack scenarios is studied. The analysis work for each leakage resilient security model here enables a better knowledge on how an adversary query addresses different leakage attacks setting, thereby understand the motive of design for a cryptographic primitive in the security model.",
            "authors": [
                "Clement Chan Zheng Wei",
                "Chuah Chai Wen",
                "Janaka Alawatugoda\\"
            ],
            "doi": "https://doi.org/10.17762/ijcnis.v11i1.3790",
            "preprint": "https://www.researchgate.net/profile/Clement-Zheng-Wei/publication/332671720_Review_on_Leakage_Resilient_Key_Exchange_Security_Model/links/5cc2c6e1a6fdcc1d49af2c1a/Review-on-Leakage-Resilient-Key-Exchange-Security-Model.pdf",
            "pdf": "https://www.ijcnis.org/index.php/ijcnis/article/view/3790/705",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Leakage-resilient cryptography",
                "Key exchange protocol",
                "Security models",
                "Leakage attacks",
                "Side-channel attacks",
                "Leakage resilience"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.17762/ijcnis.v11i1.3790/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.17762/ijcnis.v11i1.3790/index.json"
        },
        {
            "title": "New approach to practical leakage-resilient public-key cryptography",
            "venue": "Journal of Mathematical Cryptology",
            "year": "2020",
            "abstract": "We present a new approach to construct several leakage-resilient cryptographic primitives, including leakage-resilient public-key encryption (PKE) schemes, authenticated key exchange (AKE) protocols and low-latency key exchange (LLKE) protocols. To this end, we introduce a new primitive called leakage-resilient non-interactive key exchange (LR-NIKE) protocol. We introduce an appropriate security model for LR-NIKE protocols in the bounded memory leakage (BML) settings. We then show a secure construction of the LR-NIKE protocol in the BML setting that achieves an optimal leakage rate, i.e., 1 \u00e2\u0080\u0093 o(1). Our construction of LR-NIKE requires a minimal use of a leak-free hardware component. We argue that the use of such a leak-free hardware component seems to be unavoidable in any construction of an LR-NIKE protocol, even in the BML setting. Finally, we show how to construct the aforementioned leakage-resilient primitives from such an LR-NIKE protocol as summarized below. All these primitives also achieve the same (optimal) leakage rate as the underlying LR-NIKE protocol. We show how to construct a leakage-resilient (LR) IND-CCA-2-secure PKE scheme in the BML model generically from a bounded LR-NIKE (BLR-NIKE) protocol. Our construction of LR-IND-CCA-2 secure PKE differs significantly from the state-of-the-art constructions of these primitives, which mainly use hash proof techniques to achieve leakage resilience. Moreover, our transformation preserves the leakage-rate of the underlying BLR-NIKE protocol. We introduce a new leakage model for AKE protocols, in the BML setting, and present a leakage-resilient AKE protocol construction from the LR-NIKE protocol. We introduce the first-ever leakage model for LLKE protocols in the BML setting and the first construction of such a leakage-resilient LLKE from the LR-NIKE protocol.",
            "authors": [
                "Suvradip Chakraborty",
                "Janaka Alawatugoda",
                "Chandrasekaran Pandu Rangan"
            ],
            "doi": "https://doi.org/10.1515/jmc-2019-0014",
            "preprint": "#",
            "pdf": "https://www.degruyter.com/document/doi/10.1515/jmc-2019-0014/pdf",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Leakage-resilient cryptography",
                "public-key cryptography",
                "non-interactive key exchange",
                "authenticated key exchange",
                "low-latency key exchange"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1515/jmc-2019-0014/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1515/jmc-2019-0014/index.json"
        },
        {
            "title": "Public-key encryption in the standard model against strong leakage adversary",
            "venue": "The Computer Journal",
            "year": "2020",
            "abstract": "Over the years, security against adaptively chosen-ciphertext attacks (CCA2) is considered as the strongest security definition for public-key encryption schemes. With the uprise of side-channel attacks, new security definitions are proposed, addressing leakage of secret keys together with the standard CCA2 definition. Among the new security definitions, security against continuous and after-the-fact leakage-resilient CCA2 can be considered as the strongest security definition, which is called as security against (continuous) adaptively chosen-ciphertext leakage attacks (continuous CCLA2). In this paper, we present a construction of a public-key encryption scheme, namely LR-PKE, which satisfies the aforementioned security definition. The security of our public-key encryption scheme is proven in the standard model, under decision BDH assumption. Thus, we emphasize that our public-key encryption scheme LR-PKE is (continuous) CCLA2-secure in the standard model. For our construction of LR-PKE, we have used a strong one-time signature scheme and a leakage-resilient refreshing protocol as underlying building blocks. The leakage bound is 0.15nlogp\u00e2\u0088\u00921 bits per leakage query, for a security parameter k and a statistical security parameter n\u00e2\u0081\u00a0, such that logp\u00e2\u0089\u00a5k and n is a function of k\u00e2\u0081\u00a0. It is possible to see that LR-PKE is efficient enough to be used for real-world usage.",
            "authors": [
                "Janaka Alawatugoda"
            ],
            "doi": "https://doi.org/10.1093/comjnl/bxaa055",
            "preprint": "https://research-repository.griffith.edu.au/bitstream/handle/10072/414338/Alawatugoda522794-Accepted.pdf?sequence=2",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                ""
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1093/comjnl/bxaa055/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1093/comjnl/bxaa055/index.json"
        },
        {
            "title": "On power analysis attacks against hardware stream ciphers",
            "venue": "International Journal of Information and Computer Security",
            "year": "2022",
            "abstract": "Power analysis attacks are a type of attack which measures and analyses the power consumption of electronic circuits to extract secret information, particularly the secret encryption key. These attacks have become a huge threat for embedded systems, in which the security depends on the secret encryption key for the ciphers. Hence, many researchers try to find vulnerabilities of cryptosystems against power analysis attacks, so that they can develop countermeasures to ensure the security of such systems. In this paper, we review some of the recent power analysis attacks on modern hardware stream ciphers such as Trivium, Grain and MICKEY.",
            "authors": [
                "Rangana De Silva",
                "Iranga Navaratna",
                "Malitha Kumarasiri",
                "Janaka Alawatugoda",
                "Chuah Chai Wen"
            ],
            "doi": "https://doi.org/10.1504/ijics.2022.121289",
            "preprint": "#",
            "pdf": "#",
            "presentation": "#",
            "project": "https://projects.ce.pdn.ac.lk/4yp/e13/power-analysis-attack-on-trivium-stream-cipher",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "differential power analysis",
                "correlation power analysis",
                "simple power analysis",
                "power analysis attack",
                "stream cipher",
                "Trivium",
                "Grain",
                "MICKEY"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1504/ijics.2022.121289/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1504/ijics.2022.121289/index.json"
        },
        {
            "title": "Standard model leakage-resilient authenticated key exchange using inner-product extractors",
            "venue": "Designs, Codes and Cryptography",
            "year": "2022",
            "abstract": "With the development of side-channel attacks, a necessity arises to invent authenticated key exchange protocols in a leakage-resilient manner. Constructing authenticated key exchange protocols using existing cryptographic schemes is an effective method, as such construction can be instantiated with any appropriate scheme in a way that the formal security argument remains valid. In parallel, constructing authenticated key exchange protocols that are proven to be secure in the standard model is more preferred as they rely on real-world assumptions. In this paper, we present a Diffie\u00e2\u0080\u0093Hellman-style construction of a leakage-resilient authenticated key exchange protocol, that can be instantiated with any CCLA2-secure public-key encryption scheme and a function from the pseudo-random function family. Our protocol is proven to be secure in the standard model assuming the hardness of the decisional Diffie\u00e2\u0080\u0093Hellman problem. Furthermore, it is resilient to continuous partial leakage of long-term secret keys, that happens even after the session key is established, while satisfying the security features defined by the eCK security model.",
            "authors": [
                "Janaka Alawatugoda",
                "Tatsuaki Okamoto"
            ],
            "doi": "https://doi.org/10.1007/s10623-022-01028-0",
            "preprint": "https://eprint.iacr.org/2021/861.pdf",
            "pdf": "#",
            "presentation": "#",
            "project": "#",
            "codebase": "#",
            "researchgroups": [
                "Secure and Reliable Computing (Formal Verification / Cryptography / Blockchain)"
            ],
            "funding": "",
            "tags": [
                "Leakage-resilient cryptography",
                "Authenticated key exchange",
                "eCK model",
                "CAFL-eCK model",
                "Standard model"
            ],
            "api_url": "https://api.ce.pdn.ac.lk/publications/v1/10.1007/s10623-022-01028-0/",
            "edit_url": "https://github.com/cepdnaclk/api.ce.pdn.ac.lk/blob/main/publications/v1/10.1007/s10623-022-01028-0/index.json"
        }
    ]
}